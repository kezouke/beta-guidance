{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de789ee-53a3-4294-91bd-f7b00dc9f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c26d729-c3ee-4ee8-9a8f-92785b202014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from copy import deepcopy\n",
    "from typing import List, Tuple\n",
    "import time\n",
    "import re\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d590378-da78-4647-a1c3-1109fd98d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    A class representing a node in a tree structure. Each node contains information about its token ID, its parent node,\n",
    "    its children nodes, its depth in the tree, and its cumulative log probability.\n",
    "\n",
    "    Attributes:\n",
    "        token_id (int): The ID of the token associated with this node.\n",
    "        parent_node (Node): The parent node of this node. None if this is the root node.\n",
    "        children (list): A list of child nodes.\n",
    "        depth (int): The depth of this node in the tree.\n",
    "        cum_log_probability (float): The cumulative log probability of this node.\n",
    "        token_sequence (torch.Tensor): A tensor representing the sequence of tokens from the root to this node.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, token_id: int, parent_node: 'Node', depth: int):\n",
    "        \"\"\"\n",
    "        Initializes a new Node instance.\n",
    "\n",
    "        Args:\n",
    "            token_id (int): The ID of the token associated with this node.\n",
    "            parent_node (Node): The parent node of this node. None if this is the root node.\n",
    "            depth (int): The depth of this node in the tree.\n",
    "        \"\"\"\n",
    "        self.token_id = token_id\n",
    "        self.parent_node = parent_node\n",
    "        self.children = []\n",
    "        self.depth = depth\n",
    "        self.cum_log_probability = None\n",
    "\n",
    "        # Initialize the token_sequence based on the parent node's token_sequence and the current token_id\n",
    "        if depth:\n",
    "            self.token_sequence = torch.cat((parent_node.token_sequence, torch.tensor([self.token_id], dtype=torch.long)))\n",
    "        else:\n",
    "            self.token_sequence = torch.tensor([], dtype=torch.long)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns a string representation of the node, including its token sequence.\n",
    "\n",
    "        Returns:\n",
    "            str: A string representation of the node.\n",
    "        \"\"\"\n",
    "        return f\"Nodes: {self.token_sequence}, {self.cum_log_probability}\"\n",
    "\n",
    "    def __eq__(self, other) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if this node is equal to another node or a tensor.\n",
    "\n",
    "        Args:\n",
    "            other (Node or torch.Tensor): The other node or tensor to compare with.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the nodes are equal, False otherwise.\n",
    "        \"\"\"\n",
    "        if isinstance(other, Node):\n",
    "            return torch.equal(self.token_sequence, other.token_sequence)\n",
    "        return False\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\"\n",
    "        Return the hash based on an immutable attribute. Here, we use the string representation of the token_sequence\n",
    "        because tensors themselves are not hashable and should not be used directly in hash computations if their content\n",
    "        may change.\n",
    "        \"\"\"\n",
    "        return hash(tuple(self.token_sequence.tolist()))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7054b53e-3e47-4037-a42d-4f0e81a979bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import SamplingParams\n",
    "\n",
    "class SubstringEngine:\n",
    "    def __init__(self, llm, tokenizer, mode=False):\n",
    "        self.llm = llm\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = min(len(sorted(list(self.tokenizer.vocab.keys()),\n",
    "                                        key=lambda x: len(x), reverse=True)[0]),\n",
    "                                 10)\n",
    "        self.mode = mode\n",
    "\n",
    "    def _expand_tree(self, parent: Node,\n",
    "                    tokenized_candidates: List[torch.Tensor],\n",
    "                    height: int,\n",
    "                    position: int = 0,\n",
    "                    special_ids: List[int] = []) -> Node:\n",
    "        \"\"\"\n",
    "        Expands the tree from a given parent node by adding child nodes based on the tokenized context.\n",
    "    \n",
    "        Args:\n",
    "            parent (Node): The parent node from which to expand the tree.\n",
    "            tokenized_candidates (List[torch.Tensor]): The tokenized context for the prompt.\n",
    "            height (int): The height of the tree to expand to.\n",
    "            position (int, optional): The current position in the tokenized context. Defaults to 0.\n",
    "            special_ids (List[int], optional): A list of special token IDs to exclude from the tree. Defaults to an empty list.\n",
    "    \n",
    "        Returns:\n",
    "            Node: The parent node with its children expanded.\n",
    "        \"\"\"\n",
    "        # Iterate over each context in the tokenized context\n",
    "        for candidate in tokenized_candidates:\n",
    "            # Get the token at the current position\n",
    "            if position < len(candidate):\n",
    "                token = candidate[position].item()\n",
    "                # Check if the token is not a special token and if it's not already a child of the parent\n",
    "                if (torch.equal(candidate[:position], parent.token_sequence) and \n",
    "                    all(token != child.token_id for child in parent.children) and\n",
    "                    token not in special_ids):\n",
    "                    \n",
    "                    # Create a new node with the current token and add it as a child to the parent\n",
    "                    new_node = Node(token, parent, parent.depth + 1)\n",
    "                    parent.children.append(new_node)\n",
    "        \n",
    "                    # Recursively expand the tree if the current position is less than the height\n",
    "                    if new_node.depth < height:\n",
    "                        self._expand_tree(new_node, tokenized_candidates, height, position + 1, special_ids)\n",
    "        # Return the parent node with its children expanded\n",
    "        return parent\n",
    "\n",
    "    \n",
    "    def _build_tree(self, tokenized_context: List[torch.Tensor]) -> Tuple[Node, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Builds the entire tree for a given prompt using the tokenized context.\n",
    "    \n",
    "        Args:\n",
    "            promt (str): The prompt for which the tree is being built.\n",
    "            tokenized_context (List[torch.Tensor]): The tokenized context for the prompt.    \n",
    "        Returns:\n",
    "            Tuple[Node, torch.Tensor]: The root node of the tree and the tokenized prompt.\n",
    "        \"\"\"\n",
    "        \n",
    "        s = time.time()\n",
    "        \n",
    "        # Initialize the root node and tokenize the prompt\n",
    "        root = Node(-1, None, 0)\n",
    "        # Expand the tree from the root node to the specified height, excluding special tokens\n",
    "        root = self._expand_tree(root,\n",
    "                           tokenized_context,\n",
    "                           len(tokenized_context[0]),\n",
    "                           special_ids = self.tokenizer.all_special_ids)\n",
    "        # Set the cumulative log probability of the root node to 0\n",
    "        root.cum_log_probability = 0\n",
    "        \n",
    "        if self.mode:\n",
    "            print(f\"build tree for first tokens: {time.time() - s}\")\n",
    "        \n",
    "        # Return the root node and the tokenized prompt\n",
    "        return root\n",
    "\n",
    "\n",
    "    def _candidate_sequences(self, context, max_token_length, prompt=''):\n",
    "        \"\"\"\n",
    "        Generates a set of candidate sequences from the given context by considering all\n",
    "        possible substrings within a specified length limit.\n",
    "        \n",
    "        These candidates are then prefixed with the provided prompt to form complete sequences.\n",
    "    \n",
    "        Args:\n",
    "            context (str): The input context from which to generate candidate sequences.\n",
    "            max_token_length (int): The maximum length of a candidate sequence in terms of tokens.\n",
    "            prompt (str, optional): A prefix to be added to each candidate sequence. Defaults to an empty string.\n",
    "    \n",
    "        Returns:\n",
    "            list: A list of candidate sequences, each starting with the provided prompt.\n",
    "    \n",
    "        The function first calculates the restriction based on the length of the context and the maximum token length.\n",
    "        It then iterates over the text to generate all possible substrings within this restriction.\n",
    "        These substrings are added to a set to ensure uniqueness. The set is then sorted for reproducibility,\n",
    "        and each candidate is prefixed with the prompt to form complete\n",
    "        sequences. These sequences are returned as a list.\n",
    "        \"\"\"\n",
    "        s = time.time()\n",
    "        # Calculate the restriction based on the length of the text and the maximum token length\n",
    "        restriction = min(len(context) + 1, max_token_length)\n",
    "        # Initialize an empty set to store unique substring candidates\n",
    "        substring_candidates = set()\n",
    "        # Iterate over the text to generate all possible substrings within the restriction\n",
    "        for i in range(len(context)):\n",
    "            for j in range(i+1, i+restriction):\n",
    "                substring_candidates.add(context[i:j])\n",
    "        \n",
    "        # Sort the set of substring candidates for reproducibility\n",
    "        substring_candidates = sorted(substring_candidates)\n",
    "        # Prefix each candidate with the prompt to form complete sequences\n",
    "        sequences = [prompt + candidate for candidate in substring_candidates]\n",
    "\n",
    "        if self.mode:\n",
    "            print(f\"get candidates: last 2 tokens + all substring candidates {time.time() - s}\")\n",
    "            \n",
    "        return sequences\n",
    "\n",
    "    \n",
    "    def _compute_logprob(self, common_part, nodes):\n",
    "        \"\"\"\n",
    "        Computes the cumulative log probabilities for each node in the tree structure,\n",
    "        given a common part of the text (user prompt wihtout last 2 tokens) and a list of nodes.\n",
    "    \n",
    "        This function is crucial for evaluating the likelihood of each candidate sequence generated from the context text.\n",
    "        It does so by leveraging the transformer model to predict the next token in the sequence and then calculating\n",
    "        the log probability of each token. \n",
    "        \n",
    "        Args:\n",
    "            common_part (str): A common part of the text (user prompt wihtout last 2 tokens) that is shared by all\n",
    "                               nodes in the tree. This is used to ensure that the model's predictions are relevant\n",
    "                               to the context of the input prompt.\n",
    "            nodes (List[Node]): A list of nodes for which the cumulative log probabilities are to be computed.\n",
    "    \n",
    "        Returns:\n",
    "            None: The function modifies the nodes in-place, updating their cumulative log probabilities.\n",
    "    \n",
    "        The function begins by initializing an empty list for the input batch and two empty lists for mapping nodes\n",
    "        to their corresponding log probabilities and input sequences. It then iterates over each node, checking if\n",
    "        its cumulative log probability has been set. If not, it constructs the input sequence for the model by \n",
    "        concatenating the common part of the text with the token sequence of the node. This input sequence is then\n",
    "        added to the input batch and the node is mapped to its corresponding log probability.\n",
    "    \n",
    "        Once all nodes have been processed, the function tokenizes the input batch using the tokenizer and feeds\n",
    "        it into the model to get the logits. The log probabilities are then calculated using the log_softmax function.\n",
    "    \n",
    "        Finally, the function iterates over the nodes again, this time updating their cumulative log probabilities\n",
    "        based on the log probabilities of their tokens and the cumulative log probabilities of their parent nodes.\n",
    "        \n",
    "        This process ensures that each node's cumulative log probability reflects the likelihood\n",
    "        of the sequence of tokens leading up to it.\n",
    "        \"\"\"\n",
    "        def process_log_probs(token_ids, logits):\n",
    "            for token_id in nodes_to_gather:\n",
    "                log_probs_mapping[token_id] = logits[token_id.token_id]\n",
    "            return logits\n",
    "   \n",
    "        if self.mode:\n",
    "            print(\"log prob nodes: \")\n",
    "            print(len(nodes))\n",
    "            for node in nodes:\n",
    "                print(self.tokenizer.decode(node.token_sequence))\n",
    "            print()\n",
    "\n",
    "        s = time.time()\n",
    "        \n",
    "        # Calculate the number of tokens in the common part of the text\n",
    "        skip_logits = len(self.tokenizer.encode(common_part))\n",
    "        log_probs_mapping = {}\n",
    "        inputs_map = {}\n",
    "        common_part_encoded = self.tokenizer.encode(common_part)\n",
    "    \n",
    "        # Iterate over each node\n",
    "        for node in nodes:\n",
    "            # Check if the node's cumulative log probability has been set\n",
    "            if node.cum_log_probability is None:\n",
    "                # Construct the input sequence for the model\n",
    "                # we get tokens of the parent, since we need only\n",
    "                # them for getting log probability for current considered node token\n",
    "                inp = common_part_encoded + node.parent_node.token_sequence.tolist()\n",
    "                inputs_map.setdefault(tuple(inp), []).append(node)\n",
    "    \n",
    "        # If there are no nodes to process, return\n",
    "        if not inputs_map:\n",
    "            return\n",
    "    \n",
    "        sampling_params_for_leafs = SamplingParams(max_tokens=1,\n",
    "                                         prompt_logprobs=1,\n",
    "                                         logits_processors=[process_log_probs])\n",
    "        \n",
    "        sampling_params_for_empty_parents = SamplingParams(max_tokens=1,\n",
    "                                                           prompt_logprobs=1)\n",
    "\n",
    "        # Feed the input into the model to get the logits\n",
    "        with torch.no_grad():            \n",
    "            for inp in inputs_map:\n",
    "                nodes_to_gather = inputs_map[inp]\n",
    "                self.llm.generate(prompts=None,\n",
    "                                  prompt_token_ids=[list(inp)],\n",
    "                                  sampling_params=sampling_params_for_leafs)\n",
    "            \n",
    "        # Iterate over the nodes again to update their cumulative log probabilities\n",
    "        for idx, inp in enumerate(inputs_map):\n",
    "            for node in inputs_map[inp]:\n",
    "                # if self.mode:\n",
    "                #     print(\"seq:\")\n",
    "                #     print(node.token_sequence)\n",
    "                #     print()\n",
    "                    \n",
    "                # It is possible, that parent node cum_log_probability is not calculated yet\n",
    "                # Thus, if it is a such situation, we will calculate log_probability for parent nodes also\n",
    "                \n",
    "                # Initialize lists for the parent nodes and their log probabilities\n",
    "                parents_log_probs = []\n",
    "                parents_sequence_without_logprob = []\n",
    "                # Iterate over the parent nodes\n",
    "                parent_tmp = node.parent_node\n",
    "                while parent_tmp.cum_log_probability is None:\n",
    "                    parents_sequence_without_logprob.append(parent_tmp)\n",
    "                    parent_tmp = parent_tmp.parent_node\n",
    "\n",
    "\n",
    "                if parents_sequence_without_logprob:\n",
    "                    prompt_input_ids = common_part_encoded + parents_sequence_without_logprob[0].token_sequence.tolist()\n",
    "                    outputs = self.llm.generate(prompts=None,\n",
    "                                                prompt_token_ids=[prompt_input_ids],\n",
    "                                                sampling_params=sampling_params_for_empty_parents)[0]\n",
    "                \n",
    "                # Calculate the cumulative log probability for each parent node\n",
    "                number_of_parents_without_logbrob = len(parents_sequence_without_logprob)\n",
    "                for n_id in range(number_of_parents_without_logbrob - 1, -1, -1):\n",
    "                    t_id = parents_sequence_without_logprob[n_id].token_id\n",
    "                    # print(outputs.prompt_logprobs[-1 - n_id])\n",
    "                    parents_sequence_without_logprob[n_id].cum_log_probability = (outputs.prompt_logprobs[-1 - n_id][t_id].logprob + \n",
    "                                                                                  parents_sequence_without_logprob[n_id].parent_node.cum_log_probability)\n",
    "                   \n",
    "                # Update the node's cumulative log probability                \n",
    "                # if self.mode:\n",
    "                #     print(\"children: \")\n",
    "                #     print(node.token_id)\n",
    "                    \n",
    "                node.cum_log_probability = log_probs_mapping[node] + node.parent_node.cum_log_probability\n",
    "\n",
    "        if self.mode:\n",
    "            print(f\"compute log_probs call {time.time() - s}\")\n",
    "            \n",
    "    \n",
    "    def _get_topk_nodes(self, nodes, k):\n",
    "        \"\"\"\n",
    "        Selects the top `k` nodes from a given list of nodes based on their cumulative log probabilities, normalized by their depth.\n",
    "    \n",
    "        This function is used to prune the tree and focus on the most promising candidates for further evaluation or output.\n",
    "        By normalizing the cumulative log probabilities by the depth of each node,\n",
    "        it ensures that nodes deeper in the tree are not overly favored simply because they are longer.\n",
    "    \n",
    "        Args:\n",
    "            nodes (List[Node]): A list of nodes from which to select the top `k` nodes.\n",
    "            k (int): The number of top nodes to select.\n",
    "    \n",
    "        Returns:\n",
    "            List[Node]: A list of the top `k` nodes, sorted by their normalized cumulative log probabilities.\n",
    "    \n",
    "        The function begins by calculating the normalized scores for each node.\n",
    "        This is done by dividing the cumulative log probability of each node by its depth.\n",
    "        The scores are then converted into a tensor and the indices of the top `k` scores \n",
    "        are determined using the `torch.topk` function. These indices are used to select \n",
    "        the corresponding nodes from the original list.\n",
    "    \n",
    "        The selected nodes are returned as a list, which can then be used for further processing\n",
    "        or output. This function is particularly useful in scenarios where the tree is large and \n",
    "        contains many nodes, allowing the script to efficiently focus on the most likely candidates.\n",
    "        \"\"\"\n",
    "        s = time.time()\n",
    "        # Calculate the normalized scores for each node\n",
    "        scores = torch.tensor([node.cum_log_probability/node.depth for node in nodes])\n",
    "        # Determine the indices of the top k scores\n",
    "        top_k_indices = torch.topk(scores, k=k, largest=True, sorted=True).indices\n",
    "        \n",
    "        if self.mode:\n",
    "            print(f\"get top k nodes call: {time.time() - s}\")\n",
    "        # Select the top k nodes using the indices\n",
    "        return [nodes[i] for i in top_k_indices]\n",
    "\n",
    "\n",
    "    def _candidate_sequences_exp(self, context, chosen_options, max_candidate_length, prompt=''):\n",
    "        \"\"\"\n",
    "        Generates a set of candidate sequences from the given context,\n",
    "        with each candidate starting with one of the chosen options.\n",
    "    \n",
    "        This function is useful for scenarios where the context or the prompt suggests\n",
    "        specific starting points for the sequences, allowing for more targeted generation.\n",
    "        \n",
    "        It iterates over the text to generate all possible substrings within a specified length\n",
    "        limit and checks if each candidate starts with one of the chosen options. Only those \n",
    "        candidates that meet this condition are added to the set of substring candidates.\n",
    "    \n",
    "        Args:\n",
    "            context (str): The input context from which to generate candidate sequences.\n",
    "            chosen_options (List[str]): A list of options that each candidate sequence must start with.\n",
    "            max_candidate_length (int): The maximum length of a candidate sequence in terms of tokens.\n",
    "            prompt (str, optional): A prefix to be added to each candidate sequence. Defaults to an empty string.\n",
    "    \n",
    "        Returns:\n",
    "            list: A list of candidate sequences, each starting with one of the chosen options and prefixed with the provided prompt.\n",
    "    \n",
    "        The function first calculates the restriction based on the length of the text and the maximum candidate length. It then iterates over the text to generate all possible substrings within this restriction. For each substring, it checks if the substring starts with one of the chosen options. If so, the substring is added to the set of substring candidates. The set is then sorted for reproducibility, and each candidate is prefixed with the prompt to form complete sequences. These sequences are returned as a list.\n",
    "        \"\"\"\n",
    "        s = time.time()\n",
    "        # Calculate the restriction based on the length of the text and the maximum candidate length\n",
    "        restriction = min(len(context) + 1, max_candidate_length)\n",
    "        # Initialize an empty set to store unique substring candidates\n",
    "        substring_candidates = set()\n",
    "        # Iterate over the text to generate all possible substrings within the restriction\n",
    "        for i in range(len(context)):\n",
    "            for j in range(i+1, i+restriction):\n",
    "                candidate = prompt + context[i:j]\n",
    "                tokenized_candidate = self.tokenizer.encode(candidate, return_tensors=\"pt\", add_special_tokens=False)[0]\n",
    "                # Check if the candidate starts with one of the chosen options\n",
    "                if any(torch.equal(tokenized_candidate[:len(option)], option) for option in chosen_options):\n",
    "                    substring_candidates.add(candidate)\n",
    "        \n",
    "        # Sort the set of substring candidates for reproducibility\n",
    "        sequences = sorted(list(substring_candidates))\n",
    "\n",
    "        if self.mode:\n",
    "            print(f\"get expanded candidates starts with top k first tokens: {time.time() - s}\")\n",
    "        return sequences\n",
    "\n",
    "    \n",
    "    def _get_nodes_seq_before_branch(self, node):\n",
    "        \"\"\"\n",
    "        Traverses the tree structure from a given node and returns the node that is just before a branching point.\n",
    "    \n",
    "        Args:\n",
    "            node (Node): The starting node from which to traverse the tree.\n",
    "    \n",
    "        Returns:\n",
    "            Node: The node that is just before a branching point in the tree.\n",
    "    \n",
    "        The function begins by entering a loop that continues until it finds a node with more than one child.\n",
    "        It starts with the given node and checks its children. If the node has exactly one child, the function \n",
    "        moves to that child and continues the process. This ensures that the function traverses down the tree \n",
    "        until it reaches a node that is about to branch into multiple paths.\n",
    "    \n",
    "        Once the branching point is found, the function breaks out of the loop and returns the node that led to \n",
    "        this branching. This node is the one just before the branching point, and it can be used for further \n",
    "        processing or analysis.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            children = node.children\n",
    "            # If the node has exactly one child, move to that child\n",
    "            if len(children) == 1:\n",
    "                node = children[0]\n",
    "            else:\n",
    "                # If the node has more than one child, it's a branching point\n",
    "                break\n",
    "        # Return the node just before the branching point\n",
    "        return node\n",
    "\n",
    "\n",
    "    def _iteration(self, working_list, common_part, k):\n",
    "        \"\"\"\n",
    "        Performs an iteration of the sequence generation process by computing the cumulative log probabilities\n",
    "        of the nodes in the working list and selecting the top `k` nodes.\n",
    "    \n",
    "        Args:\n",
    "            working_list (List[Node]): The list of nodes for which the cumulative log probabilities are to be computed\n",
    "                                       and from which the top `k` nodes are to be selected.\n",
    "            common_part (str): A common part of the text that is shared by all nodes in the tree. This is used to ensure\n",
    "                               that the model's predictions are relevant to the context of the input text.\n",
    "            k (int): The number of top nodes to select.\n",
    "    \n",
    "        Returns:\n",
    "            List[Node]: The top `k` nodes from the working list, sorted by their normalized cumulative log probabilities.\n",
    "        \"\"\"\n",
    "        # Add children to wotking list for every node in it\n",
    "        working_list = self._update_working_list_with_children(working_list)\n",
    "        \n",
    "        # Compute the cumulative log probabilities for each node in the working list\n",
    "        self._compute_logprob(common_part, working_list)\n",
    "        # Select the top k nodes from the working list based on their cumulative log probabilities\n",
    "        return self._get_topk_nodes(working_list, k)\n",
    "\n",
    "\n",
    "    def _update_working_list_with_children(self, working_list):\n",
    "        \"\"\"\n",
    "        Updates the working list of nodes by adding the children of each node in the list,\n",
    "        specifically those that are just before a branching point in the tree.\n",
    "    \n",
    "        Args:\n",
    "            working_list (List[Node]): The current working list of nodes to be updated.\n",
    "    \n",
    "        Returns:\n",
    "            List[Node]: The updated working list of nodes, including the children of each node in the original list.\n",
    "        \"\"\"\n",
    "        s = time.time()\n",
    "        for node in working_list:\n",
    "            for c in node.children:\n",
    "                candidate_to_add = self._get_nodes_seq_before_branch(c)\n",
    "                if candidate_to_add not in working_list:\n",
    "                    working_list.append(candidate_to_add)\n",
    "\n",
    "        if self.mode:\n",
    "            print(f\"add children sequences before found branch into working list: {time.time() - s}\")\n",
    "        return working_list\n",
    "\n",
    "    \n",
    "    def substring(self, prompt, context, k, max_substring_length, return_full_text=False):\n",
    "        \"\"\"\n",
    "        Generates and evaluates candidate sequences based on a given prompt and context, selecting the top `k` nodes.\n",
    "    \n",
    "        Args:\n",
    "            prompt (str): The prompt for which the tree is being built and from which the last part and the common part are extracted.\n",
    "            context (str): The context from which candidate sequences are generated.\n",
    "            k (int): The number of top nodes to select.\n",
    "            max_substring_length (int): The maximum length of a candidate sequence in terms of tokens.\n",
    "    \n",
    "        Returns:\n",
    "            Tuple[List[Node], Node]: The top `k` nodes from the working list and the initial root node of the tree.\n",
    "        \"\"\"\n",
    "        # Tokenize the prompt and extract the last part and the common part\n",
    "        tokenized_prompt = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, add_special_tokens=False)['input_ids']\n",
    "        last_part = self.tokenizer.decode(tokenized_prompt[0, -2:])\n",
    "        common_part = self.tokenizer.decode(tokenized_prompt[0, :-2])\n",
    "\n",
    "        if len(context) == 1:\n",
    "            if return_full_text:\n",
    "                return prompt + context\n",
    "            return context\n",
    "        \n",
    "        # Generate candidate sequences from the context\n",
    "        substring_candidates = self._candidate_sequences(context, self.max_token_len, last_part)\n",
    "        tokenized_s_cand = self.tokenizer(substring_candidates, return_tensors=\"pt\", padding=True, add_special_tokens=False)['input_ids']\n",
    "\n",
    "        print(substring_candidates)\n",
    "    \n",
    "        # Build the tree structure from the tokenized candidate sequences\n",
    "        initial_root = self._build_tree(tokenized_s_cand)\n",
    "\n",
    "        # Expand the tree from the root node\n",
    "        node_before_branch = self._get_nodes_seq_before_branch(initial_root)\n",
    "        first_branch_children = node_before_branch.children\n",
    "        \n",
    "        if not first_branch_children:\n",
    "            first_branch_children = [node_before_branch]\n",
    "            \n",
    "        # Last token of the prompt can be changed\n",
    "        # Therefore, we have to capture not tokens before first branch, but all its children after branch    \n",
    "        \n",
    "        working_list = []\n",
    "        for node in first_branch_children:\n",
    "            wl_len = len(working_list)\n",
    "            \n",
    "            for c in node.children:\n",
    "                candidate_to_add = self._get_nodes_seq_before_branch(c)\n",
    "                if candidate_to_add not in working_list:\n",
    "                    working_list.append(candidate_to_add)  \n",
    "                    \n",
    "            if wl_len == len(working_list):\n",
    "                working_list.append(node)\n",
    "                   \n",
    "        self._compute_logprob(common_part, working_list)\n",
    "        working_list = self._get_topk_nodes(working_list, k)\n",
    "    \n",
    "        # Generate expanded candidate sequences based on the chosen candidates\n",
    "        chosen_candidates = list(map(lambda x: x.token_sequence, working_list))\n",
    "\n",
    "        # if self.mode:\n",
    "        #     print(\"chosen_candidates for explansion: \")\n",
    "        #     for c in chosen_candidates:\n",
    "        #         print(self.tokenizer.decode(c))\n",
    "        #     print()\n",
    "        \n",
    "        expanded_candidates = self._candidate_sequences_exp(context, chosen_candidates, max_substring_length, last_part)\n",
    "        \n",
    "        tokenized_expanded_candidates = self.tokenizer(expanded_candidates, return_tensors=\"pt\", padding=True, add_special_tokens=False)['input_ids']\n",
    "    \n",
    "        # Update the working list with children nodes\n",
    "        working_list[0].parent_node.children = working_list\n",
    "    \n",
    "        # Expand the tree with the expanded candidate sequences\n",
    "        for node in working_list:\n",
    "            self._expand_tree(node,\n",
    "                        tokenized_expanded_candidates,\n",
    "                        len(tokenized_expanded_candidates[0]),\n",
    "                        position = node.depth,\n",
    "                        special_ids=self.tokenizer.all_special_ids)\n",
    "    \n",
    "        # Iteratively refine the set of candidate sequences based on their likelihood\n",
    "        while True:\n",
    "            prev_w_l = deepcopy(working_list)\n",
    "            working_list = self._iteration(working_list, common_part, k)\n",
    "            if prev_w_l == working_list:\n",
    "                break\n",
    "    \n",
    "        res_text = []\n",
    "        for node in working_list:\n",
    "            substirng_choice = self.tokenizer.decode(node.token_sequence)\n",
    "            \n",
    "            if return_full_text:\n",
    "                res_text.append(common_part + substirng_choice)\n",
    "            else:\n",
    "                res_text.append(substirng_choice[len(last_part):])\n",
    "        \n",
    "        return res_text, working_list, initial_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8da1ed9f-a16d-4918-8b23-3118d069a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria\n",
    "\n",
    "class EosListStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, eos_sequence, len_tokenized_eos_sequence, tokenizer):\n",
    "        self.eos_sequence = eos_sequence\n",
    "        self.len_tokenized_eos_sequence = len_tokenized_eos_sequence\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self,\n",
    "                 input_ids: torch.LongTensor,\n",
    "                 scores: torch.FloatTensor,\n",
    "                 **kwargs) -> bool:\n",
    "        \n",
    "        # Check each batch item if the sequence ends with the specified eos_sequence\n",
    "        last_ids = self.tokenizer.decode(input_ids[:,-self.len_tokenized_eos_sequence:])\n",
    "        # Check if all elements in eos_sequence match for any item in the batch\n",
    "        return self.eos_sequence == last_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f2f130-2976-4f4d-8a15-25d94c3170d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuidanceBeta:\n",
    "    \"\"\"\n",
    "    Class for generating guidance using a pretrained language model.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Pretrained model identifier from Hugging Face model hub.\n",
    "        mode (bool): Mode for the guidance generation (whether to print log messages or not).\n",
    "        model_kwargs (dict): Additional keyword arguments to pass to the model initialization.\n",
    "        tokenizer_kwargs (dict): Additional keyword arguments to pass to the tokenizer initialization.\n",
    "\n",
    "    Attributes:\n",
    "        model (AutoModelForCausalLM): Pretrained model for generating guidance.\n",
    "        tokenizer (AutoTokenizer): Tokenizer for tokenizing inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 llm,\n",
    "                 mode=True):\n",
    "        \n",
    "        self.llm = llm\n",
    "        \n",
    "        if hasattr(llm, \"get_tokenizer\"):\n",
    "            self.tokenizer = self.llm.get_tokenizer()\n",
    "        elif hasattr(llm, \"tokenizer\"):\n",
    "            if hasattr(llm.tokenizer, \"tokenizer\"):\n",
    "                self.tokenizer = self.llm.tokenizer.tokenizer\n",
    "            else:\n",
    "                self.tokenizer = self.llm.tokenizer\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"The provided LLM instance in RegexLogitsProcessor neither has a \"\n",
    "                \"`tokenizer` attribute or a get_tokenizer method.\"\n",
    "            )\n",
    "\n",
    "        if not self.tokenizer.pad_token:\n",
    "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            \n",
    "        self.mode = mode\n",
    "\n",
    "    def substring(self, input_text, context:str, k=1, max_substring_length=35):\n",
    "        substring_engine = SubstringEngine(self.llm, self.tokenizer, mode=self.mode)\n",
    "        # return res_text, working_list, initial_root\n",
    "        result = substring_engine.substring(input_text, context, k, max_substring_length)\n",
    "        \n",
    "        return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ed5651-9aa4-48a4-8f40-1475e05f78e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-02 07:42:29,294\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "/home/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_TOKEN=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\n",
      "INFO 06-02 07:42:30 llm_engine.py:161] Initializing an LLM engine (v0.4.3) with config: model='meta-llama/Meta-Llama-3-8B', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=meta-llama/Meta-Llama-3-8B)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[W CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-02 07:42:35 weight_utils.py:207] Using model weights format ['*.safetensors']\n",
      "INFO 06-02 07:42:38 model_runner.py:146] Loading model weights took 14.9595 GB\n",
      "INFO 06-02 07:42:39 gpu_executor.py:83] # GPU blocks: 16011, # CPU blocks: 2048\n",
      "INFO 06-02 07:42:41 model_runner.py:854] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 06-02 07:42:41 model_runner.py:858] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 06-02 07:42:44 model_runner.py:924] Graph capturing finished in 3 secs.\n",
      "INFO 06-02 07:42:44 block_manager_v1.py:247] Automatic prefix caching is enabled.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from vllm import LLM\n",
    "\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "access_token = \"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\"\n",
    "\n",
    "%env HF_TOKEN=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\n",
    "\n",
    "# Specify the primary GPU to use (GPU 0, which has more available memory)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Setting PyTorch environment variable for better memory management\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "\n",
    "llm = LLM(\n",
    "    model=model_name,\n",
    "    tensor_parallel_size=1,  # Consider adjusting if still facing issues\n",
    "    gpu_memory_utilization=0.6,\n",
    "    enable_prefix_caching=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dcbe3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt_ids = [\n",
    "    [128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 12],\n",
    "    [128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 12, 304],\n",
    "    [128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 12, 304, 5208],\n",
    "    [128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 4110],\n",
    "    [128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 4110, 264],\n",
    "    [128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 4110, 264, 3465],\n",
    "    [128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 4110, 264, 3465, 311],\n",
    "    [128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 64],\n",
    "    [128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 64, 3465],\n",
    "    [128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 64, 3465, 311]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7892f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import SamplingParams\n",
    "\n",
    "sampling_params = SamplingParams(max_tokens=1, prompt_logprobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e745555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 10/10 [00:00<00:00, 69.19it/s, Generation Speed: 69.22 toks/s]\n"
     ]
    }
   ],
   "source": [
    "res = llm.generate(prompts=None, sampling_params=sampling_params, prompt_token_ids=input_prompt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb40de78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RequestOutput(request_id=0, prompt=None, prompt_token_ids=[128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 12], prompt_logprobs=[None, {3947: Logprob(logprob=-6.435123443603516, rank=47, decoded_token='There'), 14924: Logprob(logprob=-1.1851236820220947, rank=1, decoded_token='Question')}, {374: Logprob(logprob=-1.4751518964767456, rank=2, decoded_token=' is'), 527: Logprob(logprob=-0.8501518964767456, rank=1, decoded_token=' are')}, {264: Logprob(logprob=-1.1288176774978638, rank=1, decoded_token=' a')}, {1715: Logprob(logprob=-9.066563606262207, rank=886, decoded_token=' request'), 2763: Logprob(logprob=-2.441563844680786, rank=1, decoded_token=' lot')}, {505: Logprob(logprob=-2.4557113647460938, rank=3, decoded_token=' from'), 369: Logprob(logprob=-1.2057112455368042, rank=1, decoded_token=' for')}, {279: Logprob(logprob=-1.100795030593872, rank=1, decoded_token=' the')}, {1217: Logprob(logprob=-4.3608503341674805, rank=5, decoded_token=' user'), 20214: Logprob(logprob=-3.7983505725860596, rank=1, decoded_token=' Ministry')}, {311: Logprob(logprob=-0.796364963054657, rank=1, decoded_token=' to')}, {1893: Logprob(logprob=-3.0459389686584473, rank=2, decoded_token=' create'), 923: Logprob(logprob=-2.5459389686584473, rank=1, decoded_token=' add')}, {264: Logprob(logprob=-0.46096619963645935, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-5.938747882843018, rank=49, decoded_token=' task'), 502: Logprob(logprob=-2.3137478828430176, rank=1, decoded_token=' new')}, {304: Logprob(logprob=-2.125389575958252, rank=1, decoded_token=' in')}, {3465: Logprob(logprob=-5.396354675292969, rank=19, decoded_token=' task'), 279: Logprob(logprob=-1.1463544368743896, rank=1, decoded_token=' the')}, {6373: Logprob(logprob=-2.1754069328308105, rank=2, decoded_token=' management'), 6783: Logprob(logprob=-1.4254070520401, rank=1, decoded_token=' manager')}, {1887: Logprob(logprob=-1.9005897045135498, rank=1, decoded_token=' system')}, {13: Logprob(logprob=-1.4818499088287354, rank=1, decoded_token='.')}, {5321: Logprob(logprob=-4.812841415405273, rank=22, decoded_token=' Please'), 578: Logprob(logprob=-1.3128414154052734, rank=1, decoded_token=' The')}, {11: Logprob(logprob=-4.180384159088135, rank=13, decoded_token=','), 1893: Logprob(logprob=-2.0553841590881348, rank=1, decoded_token=' create')}, {8819: Logprob(logprob=-9.274468421936035, rank=367, decoded_token=' extract'), 1893: Logprob(logprob=-1.7119686603546143, rank=1, decoded_token=' create')}, {279: Logprob(logprob=-0.7036926746368408, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-7.863875865936279, rank=202, decoded_token=' status'), 3465: Logprob(logprob=-1.9888757467269897, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-1.0321611166000366, rank=1, decoded_token=' of')}, {420: Logprob(logprob=-2.7303802967071533, rank=3, decoded_token=' this'), 279: Logprob(logprob=-0.48038020730018616, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.3501986265182495, rank=1, decoded_token=' task')}, {430: Logprob(logprob=-5.973194122314453, rank=32, decoded_token=' that'), 505: Logprob(logprob=-1.2856942415237427, rank=1, decoded_token=' from')}, {690: Logprob(logprob=-2.394989490509033, rank=2, decoded_token=' will'), 374: Logprob(logprob=-1.2699893712997437, rank=1, decoded_token=' is')}, {387: Logprob(logprob=-0.4832521080970764, rank=1, decoded_token=' be')}, {9277: Logprob(logprob=-6.0560383796691895, rank=65, decoded_token=' placed'), 1511: Logprob(logprob=-2.4310383796691895, rank=1, decoded_token=' used')}, {304: Logprob(logprob=-0.4673547148704529, rank=1, decoded_token=' in')}, {5546: Logprob(logprob=-5.113916873931885, rank=13, decoded_token=' Task'), 279: Logprob(logprob=-0.7389167547225952, rank=1, decoded_token=' the')}, {9744: Logprob(logprob=-2.8428988456726074, rank=4, decoded_token=' Management'), 2583: Logprob(logprob=-1.7178988456726074, rank=1, decoded_token='Status')}, {744: Logprob(logprob=-0.3768121898174286, rank=1, decoded_token=' System')}, {627: Logprob(logprob=-1.5596171617507935, rank=2, decoded_token='.\\n'), 13: Logprob(logprob=-1.3096171617507935, rank=1, decoded_token='.')}, {13617: Logprob(logprob=-6.20838737487793, rank=54, decoded_token='Example'), 791: Logprob(logprob=-2.1458871364593506, rank=1, decoded_token='The')}, {220: Logprob(logprob=-3.4441070556640625, rank=4, decoded_token=' '), 25: Logprob(logprob=-0.881607174873352, rank=1, decoded_token=':')}, {16: Logprob(logprob=-0.14433923363685608, rank=1, decoded_token='1')}, {25: Logprob(logprob=-0.7279500961303711, rank=1, decoded_token=':')}, {5666: Logprob(logprob=-8.02212142944336, rank=207, decoded_token=' Update'), 578: Logprob(logprob=-2.209620952606201, rank=1, decoded_token=' The')}, {279: Logprob(logprob=-1.2828420400619507, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.7792110443115234, rank=1, decoded_token=' status')}, {315: Logprob(logprob=-0.4747336208820343, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.8814727663993835, rank=1, decoded_token=' the')}, {20801: Logprob(logprob=-14.885658264160156, rank=10594, decoded_token=' pent'), 3465: Logprob(logprob=-0.31119504570961, rank=1, decoded_token=' task')}, {478: Logprob(logprob=-0.6689746975898743, rank=1, decoded_token='est')}, {3465: Logprob(logprob=-1.3443454504013062, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-1.3653672933578491, rank=1, decoded_token=' to')}, {8308: Logprob(logprob=-3.6275477409362793, rank=8, decoded_token=' completed'), 330: Logprob(logprob=-1.5025477409362793, rank=1, decoded_token=' \"')}, {627: Logprob(logprob=-0.7991341352462769, rank=1, decoded_token='.\\n')}, {16533: Logprob(logprob=-8.74571418762207, rank=330, decoded_token='Answer'), 13617: Logprob(logprob=-0.7457138895988464, rank=1, decoded_token='Example')}, {25: Logprob(logprob=-0.736219048500061, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-5.012274742126465, rank=29, decoded_token=' “'), 578: Logprob(logprob=-2.574774742126465, rank=1, decoded_token=' The')}, {35835: Logprob(logprob=-4.9084882736206055, rank=18, decoded_token='completed'), 791: Logprob(logprob=-2.4709880352020264, rank=1, decoded_token='The')}, {7663: Logprob(logprob=-4.7869415283203125, rank=6, decoded_token='”\\n\\n'), 863: Logprob(logprob=-0.5994415283203125, rank=1, decoded_token='”')}, {13617: Logprob(logprob=-0.2548457384109497, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.009654378518462181, rank=1, decoded_token=' ')}, {17: Logprob(logprob=-0.011736157350242138, rank=1, decoded_token='2')}, {25: Logprob(logprob=-0.015942253172397614, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-6.879785060882568, rank=31, decoded_token=' “'), 5666: Logprob(logprob=-0.2547852396965027, rank=1, decoded_token=' Update')}, {4110: Logprob(logprob=-3.7120201587677, rank=6, decoded_token='Create'), 4387: Logprob(logprob=-2.1495201587677, rank=1, decoded_token='Update')}, {264: Logprob(logprob=-0.7378871440887451, rank=1, decoded_token=' a')}, {2082: Logprob(logprob=-8.1116304397583, rank=92, decoded_token=' code'), 3465: Logprob(logprob=-0.7366300225257874, rank=1, decoded_token=' task')}, {2098: Logprob(logprob=-5.940270900726318, rank=17, decoded_token=' ref'), 3477: Logprob(logprob=-0.3152711093425751, rank=1, decoded_token=' review')}, {76507: Logprob(logprob=-0.037638068199157715, rank=1, decoded_token='actoring')}, {3465: Logprob(logprob=-0.1042257770895958, rank=1, decoded_token=' task')}, {369: Logprob(logprob=-2.0150020122528076, rank=1, decoded_token=' for')}, {650: Logprob(logprob=-7.882807731628418, rank=255, decoded_token=' V'), 279: Logprob(logprob=-1.3203076124191284, rank=1, decoded_token=' the')}, {25041: Logprob(logprob=-8.758981704711914, rank=550, decoded_token='anya'), 6546: Logprob(logprob=-2.415231227874756, rank=1, decoded_token='CS')}, {13: Logprob(logprob=-2.7198758125305176, rank=4, decoded_token='.'), 753: Logprob(logprob=-2.1573758125305176, rank=1, decoded_token='’s')}, {1628: Logprob(logprob=-5.055873394012451, rank=22, decoded_token=' And'), 578: Logprob(logprob=-1.9308732748031616, rank=1, decoded_token=' The')}, {743: Logprob(logprob=-2.0640695095062256, rank=2, decoded_token=' set'), 2713: Logprob(logprob=-1.9390695095062256, rank=1, decoded_token=' update')}, {279: Logprob(logprob=-0.9005088806152344, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.32777857780456543, rank=1, decoded_token=' status')}, {311: Logprob(logprob=-0.701461136341095, rank=1, decoded_token=' to')}, {1054: Logprob(logprob=-2.182943344116211, rank=2, decoded_token=' “'), 304: Logprob(logprob=-1.495443344116211, rank=1, decoded_token=' in')}, {258: Logprob(logprob=-0.8141452670097351, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.26366332173347473, rank=1, decoded_token=' progress')}, {89874: Logprob(logprob=-2.47843074798584, rank=4, decoded_token='”\\n'), 863: Logprob(logprob=-0.8534306287765503, rank=1, decoded_token='”')}, {16533: Logprob(logprob=-0.06133502349257469, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.02162671647965908, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.15431392192840576, rank=1, decoded_token=' “')}, {258: Logprob(logprob=-0.1300429254770279, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.048629116266965866, rank=1, decoded_token=' progress')}, {15397: Logprob(logprob=-4.23609733581543, rank=4, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.23609726130962372, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.7214919328689575, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.011189330369234085, rank=1, decoded_token=' ')}, {18: Logprob(logprob=-0.01031437423080206, rank=1, decoded_token='3')}, {25: Logprob(logprob=-0.03739602863788605, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.6135650277137756, rank=1, decoded_token=' “')}, {7968: Logprob(logprob=-7.384041786193848, rank=78, decoded_token='Show'), 4110: Logprob(logprob=-0.8215418457984924, rank=1, decoded_token='Create')}, {757: Logprob(logprob=-1.0606498718261719, rank=2, decoded_token=' me'), 279: Logprob(logprob=-0.9981498718261719, rank=1, decoded_token=' the')}, {279: Logprob(logprob=-0.4350700080394745, rank=1, decoded_token=' the')}, {3969: Logprob(logprob=-12.134038925170898, rank=1135, decoded_token=' exec'), 2704: Logprob(logprob=-0.3527887463569641, rank=1, decoded_token=' status')}, {9663: Logprob(logprob=-0.593633234500885, rank=1, decoded_token='utors')}, {315: Logprob(logprob=-0.8525809049606323, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.5535013675689697, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.8704282641410828, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-5.152504920959473, rank=20, decoded_token=' of'), 449: Logprob(logprob=-0.6525049209594727, rank=1, decoded_token=' with')}, {9676: Logprob(logprob=-12.550848960876465, rank=5540, decoded_token=' chart'), 279: Logprob(logprob=-1.6133490800857544, rank=1, decoded_token=' the')}, {287: Logprob(logprob=-1.6783087253570557, rank=1, decoded_token='ing')}, {113068: Logprob(logprob=-3.9072160720825195, rank=8, decoded_token='”.\\n'), 279: Logprob(logprob=-1.407216191291809, rank=1, decoded_token=' the')}, {16533: Logprob(logprob=-0.0446050763130188, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.013074620626866817, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.2659088969230652, rank=1, decoded_token=' “')}, {2994: Logprob(logprob=-6.747637748718262, rank=115, decoded_token='null'), 53: Logprob(logprob=-2.0601377487182617, rank=1, decoded_token='V')}, {15397: Logprob(logprob=-1.2456005811691284, rank=2, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.8706005811691284, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.5773501396179199, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.00530478497967124, rank=1, decoded_token=' ')}, {19: Logprob(logprob=-0.00842292234301567, rank=1, decoded_token='4')}, {25: Logprob(logprob=-0.022363845258951187, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.161273792386055, rank=1, decoded_token=' “')}, {4110: Logprob(logprob=-2.079286575317383, rank=3, decoded_token='Create'), 7968: Logprob(logprob=-1.5792866945266724, rank=1, decoded_token='Show')}, {264: Logprob(logprob=-0.15873757004737854, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-0.6506558656692505, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-2.053983688354492, rank=3, decoded_token=' to'), 315: Logprob(logprob=-1.3664836883544922, rank=1, decoded_token=' of')}, {3780: Logprob(logprob=-5.3355817794799805, rank=45, decoded_token=' buy'), 2713: Logprob(logprob=-2.7105817794799805, rank=1, decoded_token=' update')}, {32656: Logprob(logprob=-6.8495988845825195, rank=74, decoded_token=' candy'), 264: Logprob(logprob=-1.0995988845825195, rank=1, decoded_token=' a')}, {11: Logprob(logprob=-3.291595220565796, rank=5, decoded_token=','), 369: Logprob(logprob=-1.041595220565796, rank=1, decoded_token=' for')}, {2704: Logprob(logprob=-3.4165704250335693, rank=6, decoded_token=' status'), 323: Logprob(logprob=-1.2290704250335693, rank=1, decoded_token=' and')}, {482: Logprob(logprob=-3.429025650024414, rank=8, decoded_token=' -'), 374: Logprob(logprob=-1.6165255308151245, rank=1, decoded_token=' is')}, {304: Logprob(logprob=-2.184178113937378, rank=2, decoded_token=' in'), 1054: Logprob(logprob=-1.121678113937378, rank=1, decoded_token=' “')}, {5208: Logprob(logprob=-0.12029757350683212, rank=1, decoded_token=' progress')}, {113068: Logprob(logprob=-1.1144096851348877, rank=1, decoded_token='”.\\n')}, {16533: Logprob(logprob=-0.01982516422867775, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.006080462131649256, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.057018738240003586, rank=1, decoded_token=' “')}, {12: Logprob(logprob=-9.538674354553223, rank=42, decoded_token='-'), 258: Logprob(logprob=-0.03867468610405922, rank=1, decoded_token='in')}], outputs=[CompletionOutput(index=0, text='error', token_ids=[850], cumulative_logprob=-7.360598564147949, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1717314192.6507704, last_token_time=1717314192.6507704, first_scheduled_time=1717314192.6585464, first_token_time=1717314192.7902024, time_in_queue=0.007776021957397461, finished_time=1717314192.8003154), lora_request=None),\n",
       " RequestOutput(request_id=1, prompt=None, prompt_token_ids=[128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 12, 304], prompt_logprobs=[None, {3947: Logprob(logprob=-6.435123443603516, rank=47, decoded_token='There'), 14924: Logprob(logprob=-1.1851236820220947, rank=1, decoded_token='Question')}, {374: Logprob(logprob=-1.4751518964767456, rank=2, decoded_token=' is'), 527: Logprob(logprob=-0.8501518964767456, rank=1, decoded_token=' are')}, {264: Logprob(logprob=-1.1288176774978638, rank=1, decoded_token=' a')}, {1715: Logprob(logprob=-9.066563606262207, rank=886, decoded_token=' request'), 2763: Logprob(logprob=-2.441563844680786, rank=1, decoded_token=' lot')}, {505: Logprob(logprob=-2.4557113647460938, rank=3, decoded_token=' from'), 369: Logprob(logprob=-1.2057112455368042, rank=1, decoded_token=' for')}, {279: Logprob(logprob=-1.100795030593872, rank=1, decoded_token=' the')}, {1217: Logprob(logprob=-4.3608503341674805, rank=5, decoded_token=' user'), 20214: Logprob(logprob=-3.7983505725860596, rank=1, decoded_token=' Ministry')}, {311: Logprob(logprob=-0.796364963054657, rank=1, decoded_token=' to')}, {1893: Logprob(logprob=-3.0459389686584473, rank=2, decoded_token=' create'), 923: Logprob(logprob=-2.5459389686584473, rank=1, decoded_token=' add')}, {264: Logprob(logprob=-0.46096619963645935, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-5.938747882843018, rank=49, decoded_token=' task'), 502: Logprob(logprob=-2.3137478828430176, rank=1, decoded_token=' new')}, {304: Logprob(logprob=-2.125389575958252, rank=1, decoded_token=' in')}, {3465: Logprob(logprob=-5.396354675292969, rank=19, decoded_token=' task'), 279: Logprob(logprob=-1.1463544368743896, rank=1, decoded_token=' the')}, {6373: Logprob(logprob=-2.1754069328308105, rank=2, decoded_token=' management'), 6783: Logprob(logprob=-1.4254070520401, rank=1, decoded_token=' manager')}, {1887: Logprob(logprob=-1.9005897045135498, rank=1, decoded_token=' system')}, {13: Logprob(logprob=-1.4818499088287354, rank=1, decoded_token='.')}, {5321: Logprob(logprob=-4.812841415405273, rank=22, decoded_token=' Please'), 578: Logprob(logprob=-1.3128414154052734, rank=1, decoded_token=' The')}, {11: Logprob(logprob=-4.180384159088135, rank=13, decoded_token=','), 1893: Logprob(logprob=-2.0553841590881348, rank=1, decoded_token=' create')}, {8819: Logprob(logprob=-9.274468421936035, rank=367, decoded_token=' extract'), 1893: Logprob(logprob=-1.7119686603546143, rank=1, decoded_token=' create')}, {279: Logprob(logprob=-0.7036926746368408, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-7.863875865936279, rank=202, decoded_token=' status'), 3465: Logprob(logprob=-1.9888757467269897, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-1.0321611166000366, rank=1, decoded_token=' of')}, {420: Logprob(logprob=-2.7303802967071533, rank=3, decoded_token=' this'), 279: Logprob(logprob=-0.48038020730018616, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.3501986265182495, rank=1, decoded_token=' task')}, {430: Logprob(logprob=-5.973194122314453, rank=32, decoded_token=' that'), 505: Logprob(logprob=-1.2856942415237427, rank=1, decoded_token=' from')}, {690: Logprob(logprob=-2.394989490509033, rank=2, decoded_token=' will'), 374: Logprob(logprob=-1.2699893712997437, rank=1, decoded_token=' is')}, {387: Logprob(logprob=-0.4832521080970764, rank=1, decoded_token=' be')}, {9277: Logprob(logprob=-6.0560383796691895, rank=65, decoded_token=' placed'), 1511: Logprob(logprob=-2.4310383796691895, rank=1, decoded_token=' used')}, {304: Logprob(logprob=-0.4673547148704529, rank=1, decoded_token=' in')}, {5546: Logprob(logprob=-5.113916873931885, rank=13, decoded_token=' Task'), 279: Logprob(logprob=-0.7389167547225952, rank=1, decoded_token=' the')}, {9744: Logprob(logprob=-2.8428988456726074, rank=4, decoded_token=' Management'), 2583: Logprob(logprob=-1.7178988456726074, rank=1, decoded_token='Status')}, {744: Logprob(logprob=-0.3768121898174286, rank=1, decoded_token=' System')}, {627: Logprob(logprob=-1.5596171617507935, rank=2, decoded_token='.\\n'), 13: Logprob(logprob=-1.3096171617507935, rank=1, decoded_token='.')}, {13617: Logprob(logprob=-6.20838737487793, rank=54, decoded_token='Example'), 791: Logprob(logprob=-2.1458871364593506, rank=1, decoded_token='The')}, {220: Logprob(logprob=-3.4441070556640625, rank=4, decoded_token=' '), 25: Logprob(logprob=-0.881607174873352, rank=1, decoded_token=':')}, {16: Logprob(logprob=-0.14433923363685608, rank=1, decoded_token='1')}, {25: Logprob(logprob=-0.7279500961303711, rank=1, decoded_token=':')}, {5666: Logprob(logprob=-8.02212142944336, rank=207, decoded_token=' Update'), 578: Logprob(logprob=-2.209620952606201, rank=1, decoded_token=' The')}, {279: Logprob(logprob=-1.2828420400619507, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.7792110443115234, rank=1, decoded_token=' status')}, {315: Logprob(logprob=-0.4747336208820343, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.8814727663993835, rank=1, decoded_token=' the')}, {20801: Logprob(logprob=-14.885658264160156, rank=10594, decoded_token=' pent'), 3465: Logprob(logprob=-0.31119504570961, rank=1, decoded_token=' task')}, {478: Logprob(logprob=-0.6689746975898743, rank=1, decoded_token='est')}, {3465: Logprob(logprob=-1.3443454504013062, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-1.3653672933578491, rank=1, decoded_token=' to')}, {8308: Logprob(logprob=-3.6275477409362793, rank=8, decoded_token=' completed'), 330: Logprob(logprob=-1.5025477409362793, rank=1, decoded_token=' \"')}, {627: Logprob(logprob=-0.7991341352462769, rank=1, decoded_token='.\\n')}, {16533: Logprob(logprob=-8.74571418762207, rank=330, decoded_token='Answer'), 13617: Logprob(logprob=-0.7457138895988464, rank=1, decoded_token='Example')}, {25: Logprob(logprob=-0.736219048500061, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-5.012274742126465, rank=29, decoded_token=' “'), 578: Logprob(logprob=-2.574774742126465, rank=1, decoded_token=' The')}, {35835: Logprob(logprob=-4.9084882736206055, rank=18, decoded_token='completed'), 791: Logprob(logprob=-2.4709880352020264, rank=1, decoded_token='The')}, {7663: Logprob(logprob=-4.7869415283203125, rank=6, decoded_token='”\\n\\n'), 863: Logprob(logprob=-0.5994415283203125, rank=1, decoded_token='”')}, {13617: Logprob(logprob=-0.2548457384109497, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.009654378518462181, rank=1, decoded_token=' ')}, {17: Logprob(logprob=-0.011736157350242138, rank=1, decoded_token='2')}, {25: Logprob(logprob=-0.015942253172397614, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-6.879785060882568, rank=31, decoded_token=' “'), 5666: Logprob(logprob=-0.2547852396965027, rank=1, decoded_token=' Update')}, {4110: Logprob(logprob=-3.7120201587677, rank=6, decoded_token='Create'), 4387: Logprob(logprob=-2.1495201587677, rank=1, decoded_token='Update')}, {264: Logprob(logprob=-0.7378871440887451, rank=1, decoded_token=' a')}, {2082: Logprob(logprob=-8.1116304397583, rank=92, decoded_token=' code'), 3465: Logprob(logprob=-0.7366300225257874, rank=1, decoded_token=' task')}, {2098: Logprob(logprob=-5.940270900726318, rank=17, decoded_token=' ref'), 3477: Logprob(logprob=-0.3152711093425751, rank=1, decoded_token=' review')}, {76507: Logprob(logprob=-0.037638068199157715, rank=1, decoded_token='actoring')}, {3465: Logprob(logprob=-0.1042257770895958, rank=1, decoded_token=' task')}, {369: Logprob(logprob=-2.0150020122528076, rank=1, decoded_token=' for')}, {650: Logprob(logprob=-7.882807731628418, rank=255, decoded_token=' V'), 279: Logprob(logprob=-1.3203076124191284, rank=1, decoded_token=' the')}, {25041: Logprob(logprob=-8.758981704711914, rank=550, decoded_token='anya'), 6546: Logprob(logprob=-2.415231227874756, rank=1, decoded_token='CS')}, {13: Logprob(logprob=-2.7198758125305176, rank=4, decoded_token='.'), 753: Logprob(logprob=-2.1573758125305176, rank=1, decoded_token='’s')}, {1628: Logprob(logprob=-5.055873394012451, rank=22, decoded_token=' And'), 578: Logprob(logprob=-1.9308732748031616, rank=1, decoded_token=' The')}, {743: Logprob(logprob=-2.0640695095062256, rank=2, decoded_token=' set'), 2713: Logprob(logprob=-1.9390695095062256, rank=1, decoded_token=' update')}, {279: Logprob(logprob=-0.9005088806152344, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.32777857780456543, rank=1, decoded_token=' status')}, {311: Logprob(logprob=-0.701461136341095, rank=1, decoded_token=' to')}, {1054: Logprob(logprob=-2.182943344116211, rank=2, decoded_token=' “'), 304: Logprob(logprob=-1.495443344116211, rank=1, decoded_token=' in')}, {258: Logprob(logprob=-0.8141452670097351, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.26366332173347473, rank=1, decoded_token=' progress')}, {89874: Logprob(logprob=-2.47843074798584, rank=4, decoded_token='”\\n'), 863: Logprob(logprob=-0.8534306287765503, rank=1, decoded_token='”')}, {16533: Logprob(logprob=-0.06133502349257469, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.02162671647965908, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.15431392192840576, rank=1, decoded_token=' “')}, {258: Logprob(logprob=-0.1300429254770279, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.048629116266965866, rank=1, decoded_token=' progress')}, {15397: Logprob(logprob=-4.23609733581543, rank=4, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.23609726130962372, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.7214919328689575, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.011189330369234085, rank=1, decoded_token=' ')}, {18: Logprob(logprob=-0.01031437423080206, rank=1, decoded_token='3')}, {25: Logprob(logprob=-0.03739602863788605, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.6135650277137756, rank=1, decoded_token=' “')}, {7968: Logprob(logprob=-7.384041786193848, rank=78, decoded_token='Show'), 4110: Logprob(logprob=-0.8215418457984924, rank=1, decoded_token='Create')}, {757: Logprob(logprob=-1.0606498718261719, rank=2, decoded_token=' me'), 279: Logprob(logprob=-0.9981498718261719, rank=1, decoded_token=' the')}, {279: Logprob(logprob=-0.4350700080394745, rank=1, decoded_token=' the')}, {3969: Logprob(logprob=-12.134038925170898, rank=1135, decoded_token=' exec'), 2704: Logprob(logprob=-0.3527887463569641, rank=1, decoded_token=' status')}, {9663: Logprob(logprob=-0.593633234500885, rank=1, decoded_token='utors')}, {315: Logprob(logprob=-0.8525809049606323, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.5535013675689697, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.8704282641410828, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-5.152504920959473, rank=20, decoded_token=' of'), 449: Logprob(logprob=-0.6525049209594727, rank=1, decoded_token=' with')}, {9676: Logprob(logprob=-12.550848960876465, rank=5540, decoded_token=' chart'), 279: Logprob(logprob=-1.6133490800857544, rank=1, decoded_token=' the')}, {287: Logprob(logprob=-1.6783087253570557, rank=1, decoded_token='ing')}, {113068: Logprob(logprob=-3.9072160720825195, rank=8, decoded_token='”.\\n'), 279: Logprob(logprob=-1.407216191291809, rank=1, decoded_token=' the')}, {16533: Logprob(logprob=-0.0446050763130188, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.013074620626866817, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.2659088969230652, rank=1, decoded_token=' “')}, {2994: Logprob(logprob=-6.747637748718262, rank=115, decoded_token='null'), 53: Logprob(logprob=-2.0601377487182617, rank=1, decoded_token='V')}, {15397: Logprob(logprob=-1.2456005811691284, rank=2, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.8706005811691284, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.5773501396179199, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.00530478497967124, rank=1, decoded_token=' ')}, {19: Logprob(logprob=-0.00842292234301567, rank=1, decoded_token='4')}, {25: Logprob(logprob=-0.022363845258951187, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.161273792386055, rank=1, decoded_token=' “')}, {4110: Logprob(logprob=-2.079286575317383, rank=3, decoded_token='Create'), 7968: Logprob(logprob=-1.5792866945266724, rank=1, decoded_token='Show')}, {264: Logprob(logprob=-0.15873757004737854, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-0.6506558656692505, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-2.053983688354492, rank=3, decoded_token=' to'), 315: Logprob(logprob=-1.3664836883544922, rank=1, decoded_token=' of')}, {3780: Logprob(logprob=-5.3355817794799805, rank=45, decoded_token=' buy'), 2713: Logprob(logprob=-2.7105817794799805, rank=1, decoded_token=' update')}, {32656: Logprob(logprob=-6.8495988845825195, rank=74, decoded_token=' candy'), 264: Logprob(logprob=-1.0995988845825195, rank=1, decoded_token=' a')}, {11: Logprob(logprob=-3.291595220565796, rank=5, decoded_token=','), 369: Logprob(logprob=-1.041595220565796, rank=1, decoded_token=' for')}, {2704: Logprob(logprob=-3.4165704250335693, rank=6, decoded_token=' status'), 323: Logprob(logprob=-1.2290704250335693, rank=1, decoded_token=' and')}, {482: Logprob(logprob=-3.429025650024414, rank=8, decoded_token=' -'), 374: Logprob(logprob=-1.6165255308151245, rank=1, decoded_token=' is')}, {304: Logprob(logprob=-2.184178113937378, rank=2, decoded_token=' in'), 1054: Logprob(logprob=-1.121678113937378, rank=1, decoded_token=' “')}, {5208: Logprob(logprob=-0.12029757350683212, rank=1, decoded_token=' progress')}, {113068: Logprob(logprob=-1.1144096851348877, rank=1, decoded_token='”.\\n')}, {16533: Logprob(logprob=-0.01982516422867775, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.006080462131649256, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.057018738240003586, rank=1, decoded_token=' “')}, {12: Logprob(logprob=-9.538674354553223, rank=42, decoded_token='-'), 258: Logprob(logprob=-0.03867468610405922, rank=1, decoded_token='in')}, {304: Logprob(logprob=-1.6105985641479492, rank=1, decoded_token=' in')}], outputs=[CompletionOutput(index=0, text=' progress', token_ids=[5208], cumulative_logprob=-0.02375708520412445, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1717314192.6511495, last_token_time=1717314192.6511495, first_scheduled_time=1717314192.6585464, first_token_time=1717314192.7902024, time_in_queue=0.0073969364166259766, finished_time=1717314192.800331), lora_request=None),\n",
       " RequestOutput(request_id=2, prompt=None, prompt_token_ids=[128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 12, 304, 5208], prompt_logprobs=[None, {3947: Logprob(logprob=-6.435123443603516, rank=47, decoded_token='There'), 14924: Logprob(logprob=-1.1851236820220947, rank=1, decoded_token='Question')}, {374: Logprob(logprob=-1.4751518964767456, rank=2, decoded_token=' is'), 527: Logprob(logprob=-0.8501518964767456, rank=1, decoded_token=' are')}, {264: Logprob(logprob=-1.1288176774978638, rank=1, decoded_token=' a')}, {1715: Logprob(logprob=-9.066563606262207, rank=886, decoded_token=' request'), 2763: Logprob(logprob=-2.441563844680786, rank=1, decoded_token=' lot')}, {505: Logprob(logprob=-2.4557113647460938, rank=3, decoded_token=' from'), 369: Logprob(logprob=-1.2057112455368042, rank=1, decoded_token=' for')}, {279: Logprob(logprob=-1.100795030593872, rank=1, decoded_token=' the')}, {1217: Logprob(logprob=-4.3608503341674805, rank=5, decoded_token=' user'), 20214: Logprob(logprob=-3.7983505725860596, rank=1, decoded_token=' Ministry')}, {311: Logprob(logprob=-0.796364963054657, rank=1, decoded_token=' to')}, {1893: Logprob(logprob=-3.0459389686584473, rank=2, decoded_token=' create'), 923: Logprob(logprob=-2.5459389686584473, rank=1, decoded_token=' add')}, {264: Logprob(logprob=-0.46096619963645935, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-5.938747882843018, rank=49, decoded_token=' task'), 502: Logprob(logprob=-2.3137478828430176, rank=1, decoded_token=' new')}, {304: Logprob(logprob=-2.125389575958252, rank=1, decoded_token=' in')}, {3465: Logprob(logprob=-5.396354675292969, rank=19, decoded_token=' task'), 279: Logprob(logprob=-1.1463544368743896, rank=1, decoded_token=' the')}, {6373: Logprob(logprob=-2.1754069328308105, rank=2, decoded_token=' management'), 6783: Logprob(logprob=-1.4254070520401, rank=1, decoded_token=' manager')}, {1887: Logprob(logprob=-1.9005897045135498, rank=1, decoded_token=' system')}, {13: Logprob(logprob=-1.4818499088287354, rank=1, decoded_token='.')}, {5321: Logprob(logprob=-4.812841415405273, rank=22, decoded_token=' Please'), 578: Logprob(logprob=-1.3128414154052734, rank=1, decoded_token=' The')}, {11: Logprob(logprob=-4.180384159088135, rank=13, decoded_token=','), 1893: Logprob(logprob=-2.0553841590881348, rank=1, decoded_token=' create')}, {8819: Logprob(logprob=-9.274468421936035, rank=367, decoded_token=' extract'), 1893: Logprob(logprob=-1.7119686603546143, rank=1, decoded_token=' create')}, {279: Logprob(logprob=-0.7036926746368408, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-7.863875865936279, rank=202, decoded_token=' status'), 3465: Logprob(logprob=-1.9888757467269897, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-1.0321611166000366, rank=1, decoded_token=' of')}, {420: Logprob(logprob=-2.7303802967071533, rank=3, decoded_token=' this'), 279: Logprob(logprob=-0.48038020730018616, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.3501986265182495, rank=1, decoded_token=' task')}, {430: Logprob(logprob=-5.973194122314453, rank=32, decoded_token=' that'), 505: Logprob(logprob=-1.2856942415237427, rank=1, decoded_token=' from')}, {690: Logprob(logprob=-2.394989490509033, rank=2, decoded_token=' will'), 374: Logprob(logprob=-1.2699893712997437, rank=1, decoded_token=' is')}, {387: Logprob(logprob=-0.4832521080970764, rank=1, decoded_token=' be')}, {9277: Logprob(logprob=-6.0560383796691895, rank=65, decoded_token=' placed'), 1511: Logprob(logprob=-2.4310383796691895, rank=1, decoded_token=' used')}, {304: Logprob(logprob=-0.4673547148704529, rank=1, decoded_token=' in')}, {5546: Logprob(logprob=-5.113916873931885, rank=13, decoded_token=' Task'), 279: Logprob(logprob=-0.7389167547225952, rank=1, decoded_token=' the')}, {9744: Logprob(logprob=-2.8428988456726074, rank=4, decoded_token=' Management'), 2583: Logprob(logprob=-1.7178988456726074, rank=1, decoded_token='Status')}, {744: Logprob(logprob=-0.3768121898174286, rank=1, decoded_token=' System')}, {627: Logprob(logprob=-1.5596171617507935, rank=2, decoded_token='.\\n'), 13: Logprob(logprob=-1.3096171617507935, rank=1, decoded_token='.')}, {13617: Logprob(logprob=-6.20838737487793, rank=54, decoded_token='Example'), 791: Logprob(logprob=-2.1458871364593506, rank=1, decoded_token='The')}, {220: Logprob(logprob=-3.4441070556640625, rank=4, decoded_token=' '), 25: Logprob(logprob=-0.881607174873352, rank=1, decoded_token=':')}, {16: Logprob(logprob=-0.14433923363685608, rank=1, decoded_token='1')}, {25: Logprob(logprob=-0.7279500961303711, rank=1, decoded_token=':')}, {5666: Logprob(logprob=-8.02212142944336, rank=207, decoded_token=' Update'), 578: Logprob(logprob=-2.209620952606201, rank=1, decoded_token=' The')}, {279: Logprob(logprob=-1.2828420400619507, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.7792110443115234, rank=1, decoded_token=' status')}, {315: Logprob(logprob=-0.4747336208820343, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.8814727663993835, rank=1, decoded_token=' the')}, {20801: Logprob(logprob=-14.885658264160156, rank=10594, decoded_token=' pent'), 3465: Logprob(logprob=-0.31119504570961, rank=1, decoded_token=' task')}, {478: Logprob(logprob=-0.6689746975898743, rank=1, decoded_token='est')}, {3465: Logprob(logprob=-1.3443454504013062, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-1.3653672933578491, rank=1, decoded_token=' to')}, {8308: Logprob(logprob=-3.6275477409362793, rank=8, decoded_token=' completed'), 330: Logprob(logprob=-1.5025477409362793, rank=1, decoded_token=' \"')}, {627: Logprob(logprob=-0.7991341352462769, rank=1, decoded_token='.\\n')}, {16533: Logprob(logprob=-8.74571418762207, rank=330, decoded_token='Answer'), 13617: Logprob(logprob=-0.7457138895988464, rank=1, decoded_token='Example')}, {25: Logprob(logprob=-0.736219048500061, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-5.012274742126465, rank=29, decoded_token=' “'), 578: Logprob(logprob=-2.574774742126465, rank=1, decoded_token=' The')}, {35835: Logprob(logprob=-4.9084882736206055, rank=18, decoded_token='completed'), 791: Logprob(logprob=-2.4709880352020264, rank=1, decoded_token='The')}, {7663: Logprob(logprob=-4.7869415283203125, rank=6, decoded_token='”\\n\\n'), 863: Logprob(logprob=-0.5994415283203125, rank=1, decoded_token='”')}, {13617: Logprob(logprob=-0.2548457384109497, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.009654378518462181, rank=1, decoded_token=' ')}, {17: Logprob(logprob=-0.011736157350242138, rank=1, decoded_token='2')}, {25: Logprob(logprob=-0.015942253172397614, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-6.879785060882568, rank=31, decoded_token=' “'), 5666: Logprob(logprob=-0.2547852396965027, rank=1, decoded_token=' Update')}, {4110: Logprob(logprob=-3.7120201587677, rank=6, decoded_token='Create'), 4387: Logprob(logprob=-2.1495201587677, rank=1, decoded_token='Update')}, {264: Logprob(logprob=-0.7378871440887451, rank=1, decoded_token=' a')}, {2082: Logprob(logprob=-8.1116304397583, rank=92, decoded_token=' code'), 3465: Logprob(logprob=-0.7366300225257874, rank=1, decoded_token=' task')}, {2098: Logprob(logprob=-5.940270900726318, rank=17, decoded_token=' ref'), 3477: Logprob(logprob=-0.3152711093425751, rank=1, decoded_token=' review')}, {76507: Logprob(logprob=-0.037638068199157715, rank=1, decoded_token='actoring')}, {3465: Logprob(logprob=-0.1042257770895958, rank=1, decoded_token=' task')}, {369: Logprob(logprob=-2.0150020122528076, rank=1, decoded_token=' for')}, {650: Logprob(logprob=-7.882807731628418, rank=255, decoded_token=' V'), 279: Logprob(logprob=-1.3203076124191284, rank=1, decoded_token=' the')}, {25041: Logprob(logprob=-8.758981704711914, rank=550, decoded_token='anya'), 6546: Logprob(logprob=-2.415231227874756, rank=1, decoded_token='CS')}, {13: Logprob(logprob=-2.7198758125305176, rank=4, decoded_token='.'), 753: Logprob(logprob=-2.1573758125305176, rank=1, decoded_token='’s')}, {1628: Logprob(logprob=-5.055873394012451, rank=22, decoded_token=' And'), 578: Logprob(logprob=-1.9308732748031616, rank=1, decoded_token=' The')}, {743: Logprob(logprob=-2.0640695095062256, rank=2, decoded_token=' set'), 2713: Logprob(logprob=-1.9390695095062256, rank=1, decoded_token=' update')}, {279: Logprob(logprob=-0.9005088806152344, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.32777857780456543, rank=1, decoded_token=' status')}, {311: Logprob(logprob=-0.701461136341095, rank=1, decoded_token=' to')}, {1054: Logprob(logprob=-2.182943344116211, rank=2, decoded_token=' “'), 304: Logprob(logprob=-1.495443344116211, rank=1, decoded_token=' in')}, {258: Logprob(logprob=-0.8141452670097351, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.26366332173347473, rank=1, decoded_token=' progress')}, {89874: Logprob(logprob=-2.47843074798584, rank=4, decoded_token='”\\n'), 863: Logprob(logprob=-0.8534306287765503, rank=1, decoded_token='”')}, {16533: Logprob(logprob=-0.06133502349257469, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.02162671647965908, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.15431392192840576, rank=1, decoded_token=' “')}, {258: Logprob(logprob=-0.1300429254770279, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.048629116266965866, rank=1, decoded_token=' progress')}, {15397: Logprob(logprob=-4.23609733581543, rank=4, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.23609726130962372, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.7214919328689575, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.011189330369234085, rank=1, decoded_token=' ')}, {18: Logprob(logprob=-0.01031437423080206, rank=1, decoded_token='3')}, {25: Logprob(logprob=-0.03739602863788605, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.6135650277137756, rank=1, decoded_token=' “')}, {7968: Logprob(logprob=-7.384041786193848, rank=78, decoded_token='Show'), 4110: Logprob(logprob=-0.8215418457984924, rank=1, decoded_token='Create')}, {757: Logprob(logprob=-1.0606498718261719, rank=2, decoded_token=' me'), 279: Logprob(logprob=-0.9981498718261719, rank=1, decoded_token=' the')}, {279: Logprob(logprob=-0.4350700080394745, rank=1, decoded_token=' the')}, {3969: Logprob(logprob=-12.134038925170898, rank=1135, decoded_token=' exec'), 2704: Logprob(logprob=-0.3527887463569641, rank=1, decoded_token=' status')}, {9663: Logprob(logprob=-0.593633234500885, rank=1, decoded_token='utors')}, {315: Logprob(logprob=-0.8525809049606323, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.5535013675689697, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.8704282641410828, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-5.152504920959473, rank=20, decoded_token=' of'), 449: Logprob(logprob=-0.6525049209594727, rank=1, decoded_token=' with')}, {9676: Logprob(logprob=-12.550848960876465, rank=5540, decoded_token=' chart'), 279: Logprob(logprob=-1.6133490800857544, rank=1, decoded_token=' the')}, {287: Logprob(logprob=-1.6783087253570557, rank=1, decoded_token='ing')}, {113068: Logprob(logprob=-3.9072160720825195, rank=8, decoded_token='”.\\n'), 279: Logprob(logprob=-1.407216191291809, rank=1, decoded_token=' the')}, {16533: Logprob(logprob=-0.0446050763130188, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.013074620626866817, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.2659088969230652, rank=1, decoded_token=' “')}, {2994: Logprob(logprob=-6.747637748718262, rank=115, decoded_token='null'), 53: Logprob(logprob=-2.0601377487182617, rank=1, decoded_token='V')}, {15397: Logprob(logprob=-1.2456005811691284, rank=2, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.8706005811691284, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.5773501396179199, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.00530478497967124, rank=1, decoded_token=' ')}, {19: Logprob(logprob=-0.00842292234301567, rank=1, decoded_token='4')}, {25: Logprob(logprob=-0.022363845258951187, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.161273792386055, rank=1, decoded_token=' “')}, {4110: Logprob(logprob=-2.079286575317383, rank=3, decoded_token='Create'), 7968: Logprob(logprob=-1.5792866945266724, rank=1, decoded_token='Show')}, {264: Logprob(logprob=-0.15873757004737854, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-0.6506558656692505, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-2.053983688354492, rank=3, decoded_token=' to'), 315: Logprob(logprob=-1.3664836883544922, rank=1, decoded_token=' of')}, {3780: Logprob(logprob=-5.3355817794799805, rank=45, decoded_token=' buy'), 2713: Logprob(logprob=-2.7105817794799805, rank=1, decoded_token=' update')}, {32656: Logprob(logprob=-6.8495988845825195, rank=74, decoded_token=' candy'), 264: Logprob(logprob=-1.0995988845825195, rank=1, decoded_token=' a')}, {11: Logprob(logprob=-3.291595220565796, rank=5, decoded_token=','), 369: Logprob(logprob=-1.041595220565796, rank=1, decoded_token=' for')}, {2704: Logprob(logprob=-3.4165704250335693, rank=6, decoded_token=' status'), 323: Logprob(logprob=-1.2290704250335693, rank=1, decoded_token=' and')}, {482: Logprob(logprob=-3.429025650024414, rank=8, decoded_token=' -'), 374: Logprob(logprob=-1.6165255308151245, rank=1, decoded_token=' is')}, {304: Logprob(logprob=-2.184178113937378, rank=2, decoded_token=' in'), 1054: Logprob(logprob=-1.121678113937378, rank=1, decoded_token=' “')}, {5208: Logprob(logprob=-0.12029757350683212, rank=1, decoded_token=' progress')}, {113068: Logprob(logprob=-1.1144096851348877, rank=1, decoded_token='”.\\n')}, {16533: Logprob(logprob=-0.01982516422867775, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.006080462131649256, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.057018738240003586, rank=1, decoded_token=' “')}, {12: Logprob(logprob=-9.538674354553223, rank=42, decoded_token='-'), 258: Logprob(logprob=-0.03867468610405922, rank=1, decoded_token='in')}, {304: Logprob(logprob=-1.6105985641479492, rank=1, decoded_token=' in')}, {5208: Logprob(logprob=-0.02375708520412445, rank=1, decoded_token=' progress')}], outputs=[CompletionOutput(index=0, text='”\\n\\n', token_ids=[7663], cumulative_logprob=-1.840372085571289, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1717314192.651378, last_token_time=1717314192.651378, first_scheduled_time=1717314192.6585464, first_token_time=1717314192.7902024, time_in_queue=0.00716853141784668, finished_time=1717314192.8003418), lora_request=None),\n",
       " RequestOutput(request_id=3, prompt=None, prompt_token_ids=[128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 4110], prompt_logprobs=[None, {3947: Logprob(logprob=-6.435123443603516, rank=47, decoded_token='There'), 14924: Logprob(logprob=-1.1851236820220947, rank=1, decoded_token='Question')}, {374: Logprob(logprob=-1.4751518964767456, rank=2, decoded_token=' is'), 527: Logprob(logprob=-0.8501518964767456, rank=1, decoded_token=' are')}, {264: Logprob(logprob=-1.1288176774978638, rank=1, decoded_token=' a')}, {1715: Logprob(logprob=-9.066563606262207, rank=886, decoded_token=' request'), 2763: Logprob(logprob=-2.441563844680786, rank=1, decoded_token=' lot')}, {505: Logprob(logprob=-2.4557113647460938, rank=3, decoded_token=' from'), 369: Logprob(logprob=-1.2057112455368042, rank=1, decoded_token=' for')}, {279: Logprob(logprob=-1.100795030593872, rank=1, decoded_token=' the')}, {1217: Logprob(logprob=-4.3608503341674805, rank=5, decoded_token=' user'), 20214: Logprob(logprob=-3.7983505725860596, rank=1, decoded_token=' Ministry')}, {311: Logprob(logprob=-0.796364963054657, rank=1, decoded_token=' to')}, {1893: Logprob(logprob=-3.0459389686584473, rank=2, decoded_token=' create'), 923: Logprob(logprob=-2.5459389686584473, rank=1, decoded_token=' add')}, {264: Logprob(logprob=-0.46096619963645935, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-5.938747882843018, rank=49, decoded_token=' task'), 502: Logprob(logprob=-2.3137478828430176, rank=1, decoded_token=' new')}, {304: Logprob(logprob=-2.125389575958252, rank=1, decoded_token=' in')}, {3465: Logprob(logprob=-5.396354675292969, rank=19, decoded_token=' task'), 279: Logprob(logprob=-1.1463544368743896, rank=1, decoded_token=' the')}, {6373: Logprob(logprob=-2.1754069328308105, rank=2, decoded_token=' management'), 6783: Logprob(logprob=-1.4254070520401, rank=1, decoded_token=' manager')}, {1887: Logprob(logprob=-1.9005897045135498, rank=1, decoded_token=' system')}, {13: Logprob(logprob=-1.4818499088287354, rank=1, decoded_token='.')}, {5321: Logprob(logprob=-4.812841415405273, rank=22, decoded_token=' Please'), 578: Logprob(logprob=-1.3128414154052734, rank=1, decoded_token=' The')}, {11: Logprob(logprob=-4.180384159088135, rank=13, decoded_token=','), 1893: Logprob(logprob=-2.0553841590881348, rank=1, decoded_token=' create')}, {8819: Logprob(logprob=-9.274468421936035, rank=367, decoded_token=' extract'), 1893: Logprob(logprob=-1.7119686603546143, rank=1, decoded_token=' create')}, {279: Logprob(logprob=-0.7036926746368408, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-7.863875865936279, rank=202, decoded_token=' status'), 3465: Logprob(logprob=-1.9888757467269897, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-1.0321611166000366, rank=1, decoded_token=' of')}, {420: Logprob(logprob=-2.7303802967071533, rank=3, decoded_token=' this'), 279: Logprob(logprob=-0.48038020730018616, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.3501986265182495, rank=1, decoded_token=' task')}, {430: Logprob(logprob=-5.973194122314453, rank=32, decoded_token=' that'), 505: Logprob(logprob=-1.2856942415237427, rank=1, decoded_token=' from')}, {690: Logprob(logprob=-2.394989490509033, rank=2, decoded_token=' will'), 374: Logprob(logprob=-1.2699893712997437, rank=1, decoded_token=' is')}, {387: Logprob(logprob=-0.4832521080970764, rank=1, decoded_token=' be')}, {9277: Logprob(logprob=-6.0560383796691895, rank=65, decoded_token=' placed'), 1511: Logprob(logprob=-2.4310383796691895, rank=1, decoded_token=' used')}, {304: Logprob(logprob=-0.4673547148704529, rank=1, decoded_token=' in')}, {5546: Logprob(logprob=-5.113916873931885, rank=13, decoded_token=' Task'), 279: Logprob(logprob=-0.7389167547225952, rank=1, decoded_token=' the')}, {9744: Logprob(logprob=-2.8428988456726074, rank=4, decoded_token=' Management'), 2583: Logprob(logprob=-1.7178988456726074, rank=1, decoded_token='Status')}, {744: Logprob(logprob=-0.3768121898174286, rank=1, decoded_token=' System')}, {627: Logprob(logprob=-1.5596171617507935, rank=2, decoded_token='.\\n'), 13: Logprob(logprob=-1.3096171617507935, rank=1, decoded_token='.')}, {13617: Logprob(logprob=-6.20838737487793, rank=54, decoded_token='Example'), 791: Logprob(logprob=-2.1458871364593506, rank=1, decoded_token='The')}, {220: Logprob(logprob=-3.4441070556640625, rank=4, decoded_token=' '), 25: Logprob(logprob=-0.881607174873352, rank=1, decoded_token=':')}, {16: Logprob(logprob=-0.14433923363685608, rank=1, decoded_token='1')}, {25: Logprob(logprob=-0.7279500961303711, rank=1, decoded_token=':')}, {5666: Logprob(logprob=-8.02212142944336, rank=207, decoded_token=' Update'), 578: Logprob(logprob=-2.209620952606201, rank=1, decoded_token=' The')}, {279: Logprob(logprob=-1.2828420400619507, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.7792110443115234, rank=1, decoded_token=' status')}, {315: Logprob(logprob=-0.4747336208820343, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.8814727663993835, rank=1, decoded_token=' the')}, {20801: Logprob(logprob=-14.885658264160156, rank=10594, decoded_token=' pent'), 3465: Logprob(logprob=-0.31119504570961, rank=1, decoded_token=' task')}, {478: Logprob(logprob=-0.6689746975898743, rank=1, decoded_token='est')}, {3465: Logprob(logprob=-1.3443454504013062, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-1.3653672933578491, rank=1, decoded_token=' to')}, {8308: Logprob(logprob=-3.6275477409362793, rank=8, decoded_token=' completed'), 330: Logprob(logprob=-1.5025477409362793, rank=1, decoded_token=' \"')}, {627: Logprob(logprob=-0.7991341352462769, rank=1, decoded_token='.\\n')}, {16533: Logprob(logprob=-8.74571418762207, rank=330, decoded_token='Answer'), 13617: Logprob(logprob=-0.7457138895988464, rank=1, decoded_token='Example')}, {25: Logprob(logprob=-0.736219048500061, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-5.012274742126465, rank=29, decoded_token=' “'), 578: Logprob(logprob=-2.574774742126465, rank=1, decoded_token=' The')}, {35835: Logprob(logprob=-4.9084882736206055, rank=18, decoded_token='completed'), 791: Logprob(logprob=-2.4709880352020264, rank=1, decoded_token='The')}, {7663: Logprob(logprob=-4.7869415283203125, rank=6, decoded_token='”\\n\\n'), 863: Logprob(logprob=-0.5994415283203125, rank=1, decoded_token='”')}, {13617: Logprob(logprob=-0.2548457384109497, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.009654378518462181, rank=1, decoded_token=' ')}, {17: Logprob(logprob=-0.011736157350242138, rank=1, decoded_token='2')}, {25: Logprob(logprob=-0.015942253172397614, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-6.879785060882568, rank=31, decoded_token=' “'), 5666: Logprob(logprob=-0.2547852396965027, rank=1, decoded_token=' Update')}, {4110: Logprob(logprob=-3.7120201587677, rank=6, decoded_token='Create'), 4387: Logprob(logprob=-2.1495201587677, rank=1, decoded_token='Update')}, {264: Logprob(logprob=-0.7378871440887451, rank=1, decoded_token=' a')}, {2082: Logprob(logprob=-8.1116304397583, rank=92, decoded_token=' code'), 3465: Logprob(logprob=-0.7366300225257874, rank=1, decoded_token=' task')}, {2098: Logprob(logprob=-5.940270900726318, rank=17, decoded_token=' ref'), 3477: Logprob(logprob=-0.3152711093425751, rank=1, decoded_token=' review')}, {76507: Logprob(logprob=-0.037638068199157715, rank=1, decoded_token='actoring')}, {3465: Logprob(logprob=-0.1042257770895958, rank=1, decoded_token=' task')}, {369: Logprob(logprob=-2.0150020122528076, rank=1, decoded_token=' for')}, {650: Logprob(logprob=-7.882807731628418, rank=255, decoded_token=' V'), 279: Logprob(logprob=-1.3203076124191284, rank=1, decoded_token=' the')}, {25041: Logprob(logprob=-8.758981704711914, rank=550, decoded_token='anya'), 6546: Logprob(logprob=-2.415231227874756, rank=1, decoded_token='CS')}, {13: Logprob(logprob=-2.7198758125305176, rank=4, decoded_token='.'), 753: Logprob(logprob=-2.1573758125305176, rank=1, decoded_token='’s')}, {1628: Logprob(logprob=-5.055873394012451, rank=22, decoded_token=' And'), 578: Logprob(logprob=-1.9308732748031616, rank=1, decoded_token=' The')}, {743: Logprob(logprob=-2.0640695095062256, rank=2, decoded_token=' set'), 2713: Logprob(logprob=-1.9390695095062256, rank=1, decoded_token=' update')}, {279: Logprob(logprob=-0.9005088806152344, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.32777857780456543, rank=1, decoded_token=' status')}, {311: Logprob(logprob=-0.701461136341095, rank=1, decoded_token=' to')}, {1054: Logprob(logprob=-2.182943344116211, rank=2, decoded_token=' “'), 304: Logprob(logprob=-1.495443344116211, rank=1, decoded_token=' in')}, {258: Logprob(logprob=-0.8141452670097351, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.26366332173347473, rank=1, decoded_token=' progress')}, {89874: Logprob(logprob=-2.47843074798584, rank=4, decoded_token='”\\n'), 863: Logprob(logprob=-0.8534306287765503, rank=1, decoded_token='”')}, {16533: Logprob(logprob=-0.06133502349257469, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.02162671647965908, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.15431392192840576, rank=1, decoded_token=' “')}, {258: Logprob(logprob=-0.1300429254770279, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.048629116266965866, rank=1, decoded_token=' progress')}, {15397: Logprob(logprob=-4.23609733581543, rank=4, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.23609726130962372, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.7214919328689575, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.011189330369234085, rank=1, decoded_token=' ')}, {18: Logprob(logprob=-0.01031437423080206, rank=1, decoded_token='3')}, {25: Logprob(logprob=-0.03739602863788605, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.6135650277137756, rank=1, decoded_token=' “')}, {7968: Logprob(logprob=-7.384041786193848, rank=78, decoded_token='Show'), 4110: Logprob(logprob=-0.8215418457984924, rank=1, decoded_token='Create')}, {757: Logprob(logprob=-1.0606498718261719, rank=2, decoded_token=' me'), 279: Logprob(logprob=-0.9981498718261719, rank=1, decoded_token=' the')}, {279: Logprob(logprob=-0.4350700080394745, rank=1, decoded_token=' the')}, {3969: Logprob(logprob=-12.134038925170898, rank=1135, decoded_token=' exec'), 2704: Logprob(logprob=-0.3527887463569641, rank=1, decoded_token=' status')}, {9663: Logprob(logprob=-0.593633234500885, rank=1, decoded_token='utors')}, {315: Logprob(logprob=-0.8525809049606323, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.5535013675689697, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.8704282641410828, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-5.152504920959473, rank=20, decoded_token=' of'), 449: Logprob(logprob=-0.6525049209594727, rank=1, decoded_token=' with')}, {9676: Logprob(logprob=-12.550848960876465, rank=5540, decoded_token=' chart'), 279: Logprob(logprob=-1.6133490800857544, rank=1, decoded_token=' the')}, {287: Logprob(logprob=-1.6783087253570557, rank=1, decoded_token='ing')}, {113068: Logprob(logprob=-3.9072160720825195, rank=8, decoded_token='”.\\n'), 279: Logprob(logprob=-1.407216191291809, rank=1, decoded_token=' the')}, {16533: Logprob(logprob=-0.0446050763130188, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.013074620626866817, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.2659088969230652, rank=1, decoded_token=' “')}, {2994: Logprob(logprob=-6.747637748718262, rank=115, decoded_token='null'), 53: Logprob(logprob=-2.0601377487182617, rank=1, decoded_token='V')}, {15397: Logprob(logprob=-1.2456005811691284, rank=2, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.8706005811691284, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.5773501396179199, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.00530478497967124, rank=1, decoded_token=' ')}, {19: Logprob(logprob=-0.00842292234301567, rank=1, decoded_token='4')}, {25: Logprob(logprob=-0.022363845258951187, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.161273792386055, rank=1, decoded_token=' “')}, {4110: Logprob(logprob=-2.079286575317383, rank=3, decoded_token='Create'), 7968: Logprob(logprob=-1.5792866945266724, rank=1, decoded_token='Show')}, {264: Logprob(logprob=-0.15873757004737854, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-0.6506558656692505, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-2.053983688354492, rank=3, decoded_token=' to'), 315: Logprob(logprob=-1.3664836883544922, rank=1, decoded_token=' of')}, {3780: Logprob(logprob=-5.3355817794799805, rank=45, decoded_token=' buy'), 2713: Logprob(logprob=-2.7105817794799805, rank=1, decoded_token=' update')}, {32656: Logprob(logprob=-6.8495988845825195, rank=74, decoded_token=' candy'), 264: Logprob(logprob=-1.0995988845825195, rank=1, decoded_token=' a')}, {11: Logprob(logprob=-3.291595220565796, rank=5, decoded_token=','), 369: Logprob(logprob=-1.041595220565796, rank=1, decoded_token=' for')}, {2704: Logprob(logprob=-3.4165704250335693, rank=6, decoded_token=' status'), 323: Logprob(logprob=-1.2290704250335693, rank=1, decoded_token=' and')}, {482: Logprob(logprob=-3.429025650024414, rank=8, decoded_token=' -'), 374: Logprob(logprob=-1.6165255308151245, rank=1, decoded_token=' is')}, {304: Logprob(logprob=-2.184178113937378, rank=2, decoded_token=' in'), 1054: Logprob(logprob=-1.121678113937378, rank=1, decoded_token=' “')}, {5208: Logprob(logprob=-0.12029757350683212, rank=1, decoded_token=' progress')}, {113068: Logprob(logprob=-1.1144096851348877, rank=1, decoded_token='”.\\n')}, {16533: Logprob(logprob=-0.01982516422867775, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.006080462131649256, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.057018738240003586, rank=1, decoded_token=' “')}, {4110: Logprob(logprob=-9.538674354553223, rank=42, decoded_token='Create'), 258: Logprob(logprob=-0.03867468610405922, rank=1, decoded_token='in')}], outputs=[CompletionOutput(index=0, text=' a', token_ids=[264], cumulative_logprob=-0.19192984700202942, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1717314192.6515906, last_token_time=1717314192.6515906, first_scheduled_time=1717314192.6585464, first_token_time=1717314192.7902024, time_in_queue=0.006955862045288086, finished_time=1717314192.800352), lora_request=None),\n",
       " RequestOutput(request_id=4, prompt=None, prompt_token_ids=[128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 4110, 264], prompt_logprobs=[None, {3947: Logprob(logprob=-6.435123443603516, rank=47, decoded_token='There'), 14924: Logprob(logprob=-1.1851236820220947, rank=1, decoded_token='Question')}, {374: Logprob(logprob=-1.4751518964767456, rank=2, decoded_token=' is'), 527: Logprob(logprob=-0.8501518964767456, rank=1, decoded_token=' are')}, {264: Logprob(logprob=-1.1288176774978638, rank=1, decoded_token=' a')}, {1715: Logprob(logprob=-9.066563606262207, rank=886, decoded_token=' request'), 2763: Logprob(logprob=-2.441563844680786, rank=1, decoded_token=' lot')}, {505: Logprob(logprob=-2.4557113647460938, rank=3, decoded_token=' from'), 369: Logprob(logprob=-1.2057112455368042, rank=1, decoded_token=' for')}, {279: Logprob(logprob=-1.100795030593872, rank=1, decoded_token=' the')}, {1217: Logprob(logprob=-4.3608503341674805, rank=5, decoded_token=' user'), 20214: Logprob(logprob=-3.7983505725860596, rank=1, decoded_token=' Ministry')}, {311: Logprob(logprob=-0.796364963054657, rank=1, decoded_token=' to')}, {1893: Logprob(logprob=-3.0459389686584473, rank=2, decoded_token=' create'), 923: Logprob(logprob=-2.5459389686584473, rank=1, decoded_token=' add')}, {264: Logprob(logprob=-0.46096619963645935, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-5.938747882843018, rank=49, decoded_token=' task'), 502: Logprob(logprob=-2.3137478828430176, rank=1, decoded_token=' new')}, {304: Logprob(logprob=-2.125389575958252, rank=1, decoded_token=' in')}, {3465: Logprob(logprob=-5.396354675292969, rank=19, decoded_token=' task'), 279: Logprob(logprob=-1.1463544368743896, rank=1, decoded_token=' the')}, {6373: Logprob(logprob=-2.1754069328308105, rank=2, decoded_token=' management'), 6783: Logprob(logprob=-1.4254070520401, rank=1, decoded_token=' manager')}, {1887: Logprob(logprob=-1.9005897045135498, rank=1, decoded_token=' system')}, {13: Logprob(logprob=-1.4818499088287354, rank=1, decoded_token='.')}, {5321: Logprob(logprob=-4.812841415405273, rank=22, decoded_token=' Please'), 578: Logprob(logprob=-1.3128414154052734, rank=1, decoded_token=' The')}, {11: Logprob(logprob=-4.180384159088135, rank=13, decoded_token=','), 1893: Logprob(logprob=-2.0553841590881348, rank=1, decoded_token=' create')}, {8819: Logprob(logprob=-9.274468421936035, rank=367, decoded_token=' extract'), 1893: Logprob(logprob=-1.7119686603546143, rank=1, decoded_token=' create')}, {279: Logprob(logprob=-0.7036926746368408, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-7.863875865936279, rank=202, decoded_token=' status'), 3465: Logprob(logprob=-1.9888757467269897, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-1.0321611166000366, rank=1, decoded_token=' of')}, {420: Logprob(logprob=-2.7303802967071533, rank=3, decoded_token=' this'), 279: Logprob(logprob=-0.48038020730018616, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.3501986265182495, rank=1, decoded_token=' task')}, {430: Logprob(logprob=-5.973194122314453, rank=32, decoded_token=' that'), 505: Logprob(logprob=-1.2856942415237427, rank=1, decoded_token=' from')}, {690: Logprob(logprob=-2.394989490509033, rank=2, decoded_token=' will'), 374: Logprob(logprob=-1.2699893712997437, rank=1, decoded_token=' is')}, {387: Logprob(logprob=-0.4832521080970764, rank=1, decoded_token=' be')}, {9277: Logprob(logprob=-6.0560383796691895, rank=65, decoded_token=' placed'), 1511: Logprob(logprob=-2.4310383796691895, rank=1, decoded_token=' used')}, {304: Logprob(logprob=-0.4673547148704529, rank=1, decoded_token=' in')}, {5546: Logprob(logprob=-5.113916873931885, rank=13, decoded_token=' Task'), 279: Logprob(logprob=-0.7389167547225952, rank=1, decoded_token=' the')}, {9744: Logprob(logprob=-2.8428988456726074, rank=4, decoded_token=' Management'), 2583: Logprob(logprob=-1.7178988456726074, rank=1, decoded_token='Status')}, {744: Logprob(logprob=-0.3768121898174286, rank=1, decoded_token=' System')}, {627: Logprob(logprob=-1.5596171617507935, rank=2, decoded_token='.\\n'), 13: Logprob(logprob=-1.3096171617507935, rank=1, decoded_token='.')}, {13617: Logprob(logprob=-6.20838737487793, rank=54, decoded_token='Example'), 791: Logprob(logprob=-2.1458871364593506, rank=1, decoded_token='The')}, {220: Logprob(logprob=-3.4441070556640625, rank=4, decoded_token=' '), 25: Logprob(logprob=-0.881607174873352, rank=1, decoded_token=':')}, {16: Logprob(logprob=-0.14433923363685608, rank=1, decoded_token='1')}, {25: Logprob(logprob=-0.7279500961303711, rank=1, decoded_token=':')}, {5666: Logprob(logprob=-8.02212142944336, rank=207, decoded_token=' Update'), 578: Logprob(logprob=-2.209620952606201, rank=1, decoded_token=' The')}, {279: Logprob(logprob=-1.2828420400619507, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.7792110443115234, rank=1, decoded_token=' status')}, {315: Logprob(logprob=-0.4747336208820343, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.8814727663993835, rank=1, decoded_token=' the')}, {20801: Logprob(logprob=-14.885658264160156, rank=10594, decoded_token=' pent'), 3465: Logprob(logprob=-0.31119504570961, rank=1, decoded_token=' task')}, {478: Logprob(logprob=-0.6689746975898743, rank=1, decoded_token='est')}, {3465: Logprob(logprob=-1.3443454504013062, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-1.3653672933578491, rank=1, decoded_token=' to')}, {8308: Logprob(logprob=-3.6275477409362793, rank=8, decoded_token=' completed'), 330: Logprob(logprob=-1.5025477409362793, rank=1, decoded_token=' \"')}, {627: Logprob(logprob=-0.7991341352462769, rank=1, decoded_token='.\\n')}, {16533: Logprob(logprob=-8.74571418762207, rank=330, decoded_token='Answer'), 13617: Logprob(logprob=-0.7457138895988464, rank=1, decoded_token='Example')}, {25: Logprob(logprob=-0.736219048500061, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-5.012274742126465, rank=29, decoded_token=' “'), 578: Logprob(logprob=-2.574774742126465, rank=1, decoded_token=' The')}, {35835: Logprob(logprob=-4.9084882736206055, rank=18, decoded_token='completed'), 791: Logprob(logprob=-2.4709880352020264, rank=1, decoded_token='The')}, {7663: Logprob(logprob=-4.7869415283203125, rank=6, decoded_token='”\\n\\n'), 863: Logprob(logprob=-0.5994415283203125, rank=1, decoded_token='”')}, {13617: Logprob(logprob=-0.2548457384109497, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.009654378518462181, rank=1, decoded_token=' ')}, {17: Logprob(logprob=-0.011736157350242138, rank=1, decoded_token='2')}, {25: Logprob(logprob=-0.015942253172397614, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-6.879785060882568, rank=31, decoded_token=' “'), 5666: Logprob(logprob=-0.2547852396965027, rank=1, decoded_token=' Update')}, {4110: Logprob(logprob=-3.7120201587677, rank=6, decoded_token='Create'), 4387: Logprob(logprob=-2.1495201587677, rank=1, decoded_token='Update')}, {264: Logprob(logprob=-0.7378871440887451, rank=1, decoded_token=' a')}, {2082: Logprob(logprob=-8.1116304397583, rank=92, decoded_token=' code'), 3465: Logprob(logprob=-0.7366300225257874, rank=1, decoded_token=' task')}, {2098: Logprob(logprob=-5.940270900726318, rank=17, decoded_token=' ref'), 3477: Logprob(logprob=-0.3152711093425751, rank=1, decoded_token=' review')}, {76507: Logprob(logprob=-0.037638068199157715, rank=1, decoded_token='actoring')}, {3465: Logprob(logprob=-0.1042257770895958, rank=1, decoded_token=' task')}, {369: Logprob(logprob=-2.0150020122528076, rank=1, decoded_token=' for')}, {650: Logprob(logprob=-7.882807731628418, rank=255, decoded_token=' V'), 279: Logprob(logprob=-1.3203076124191284, rank=1, decoded_token=' the')}, {25041: Logprob(logprob=-8.758981704711914, rank=550, decoded_token='anya'), 6546: Logprob(logprob=-2.415231227874756, rank=1, decoded_token='CS')}, {13: Logprob(logprob=-2.7198758125305176, rank=4, decoded_token='.'), 753: Logprob(logprob=-2.1573758125305176, rank=1, decoded_token='’s')}, {1628: Logprob(logprob=-5.055873394012451, rank=22, decoded_token=' And'), 578: Logprob(logprob=-1.9308732748031616, rank=1, decoded_token=' The')}, {743: Logprob(logprob=-2.0640695095062256, rank=2, decoded_token=' set'), 2713: Logprob(logprob=-1.9390695095062256, rank=1, decoded_token=' update')}, {279: Logprob(logprob=-0.9005088806152344, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.32777857780456543, rank=1, decoded_token=' status')}, {311: Logprob(logprob=-0.701461136341095, rank=1, decoded_token=' to')}, {1054: Logprob(logprob=-2.182943344116211, rank=2, decoded_token=' “'), 304: Logprob(logprob=-1.495443344116211, rank=1, decoded_token=' in')}, {258: Logprob(logprob=-0.8141452670097351, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.26366332173347473, rank=1, decoded_token=' progress')}, {89874: Logprob(logprob=-2.47843074798584, rank=4, decoded_token='”\\n'), 863: Logprob(logprob=-0.8534306287765503, rank=1, decoded_token='”')}, {16533: Logprob(logprob=-0.06133502349257469, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.02162671647965908, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.15431392192840576, rank=1, decoded_token=' “')}, {258: Logprob(logprob=-0.1300429254770279, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.048629116266965866, rank=1, decoded_token=' progress')}, {15397: Logprob(logprob=-4.23609733581543, rank=4, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.23609726130962372, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.7214919328689575, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.011189330369234085, rank=1, decoded_token=' ')}, {18: Logprob(logprob=-0.01031437423080206, rank=1, decoded_token='3')}, {25: Logprob(logprob=-0.03739602863788605, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.6135650277137756, rank=1, decoded_token=' “')}, {7968: Logprob(logprob=-7.384041786193848, rank=78, decoded_token='Show'), 4110: Logprob(logprob=-0.8215418457984924, rank=1, decoded_token='Create')}, {757: Logprob(logprob=-1.0606498718261719, rank=2, decoded_token=' me'), 279: Logprob(logprob=-0.9981498718261719, rank=1, decoded_token=' the')}, {279: Logprob(logprob=-0.4350700080394745, rank=1, decoded_token=' the')}, {3969: Logprob(logprob=-12.134038925170898, rank=1135, decoded_token=' exec'), 2704: Logprob(logprob=-0.3527887463569641, rank=1, decoded_token=' status')}, {9663: Logprob(logprob=-0.593633234500885, rank=1, decoded_token='utors')}, {315: Logprob(logprob=-0.8525809049606323, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.5535013675689697, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.8704282641410828, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-5.152504920959473, rank=20, decoded_token=' of'), 449: Logprob(logprob=-0.6525049209594727, rank=1, decoded_token=' with')}, {9676: Logprob(logprob=-12.550848960876465, rank=5540, decoded_token=' chart'), 279: Logprob(logprob=-1.6133490800857544, rank=1, decoded_token=' the')}, {287: Logprob(logprob=-1.6783087253570557, rank=1, decoded_token='ing')}, {113068: Logprob(logprob=-3.9072160720825195, rank=8, decoded_token='”.\\n'), 279: Logprob(logprob=-1.407216191291809, rank=1, decoded_token=' the')}, {16533: Logprob(logprob=-0.0446050763130188, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.013074620626866817, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.2659088969230652, rank=1, decoded_token=' “')}, {2994: Logprob(logprob=-6.747637748718262, rank=115, decoded_token='null'), 53: Logprob(logprob=-2.0601377487182617, rank=1, decoded_token='V')}, {15397: Logprob(logprob=-1.2456005811691284, rank=2, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.8706005811691284, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.5773501396179199, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.00530478497967124, rank=1, decoded_token=' ')}, {19: Logprob(logprob=-0.00842292234301567, rank=1, decoded_token='4')}, {25: Logprob(logprob=-0.022363845258951187, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.161273792386055, rank=1, decoded_token=' “')}, {4110: Logprob(logprob=-2.079286575317383, rank=3, decoded_token='Create'), 7968: Logprob(logprob=-1.5792866945266724, rank=1, decoded_token='Show')}, {264: Logprob(logprob=-0.15873757004737854, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-0.6506558656692505, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-2.053983688354492, rank=3, decoded_token=' to'), 315: Logprob(logprob=-1.3664836883544922, rank=1, decoded_token=' of')}, {3780: Logprob(logprob=-5.3355817794799805, rank=45, decoded_token=' buy'), 2713: Logprob(logprob=-2.7105817794799805, rank=1, decoded_token=' update')}, {32656: Logprob(logprob=-6.8495988845825195, rank=74, decoded_token=' candy'), 264: Logprob(logprob=-1.0995988845825195, rank=1, decoded_token=' a')}, {11: Logprob(logprob=-3.291595220565796, rank=5, decoded_token=','), 369: Logprob(logprob=-1.041595220565796, rank=1, decoded_token=' for')}, {2704: Logprob(logprob=-3.4165704250335693, rank=6, decoded_token=' status'), 323: Logprob(logprob=-1.2290704250335693, rank=1, decoded_token=' and')}, {482: Logprob(logprob=-3.429025650024414, rank=8, decoded_token=' -'), 374: Logprob(logprob=-1.6165255308151245, rank=1, decoded_token=' is')}, {304: Logprob(logprob=-2.184178113937378, rank=2, decoded_token=' in'), 1054: Logprob(logprob=-1.121678113937378, rank=1, decoded_token=' “')}, {5208: Logprob(logprob=-0.12029757350683212, rank=1, decoded_token=' progress')}, {113068: Logprob(logprob=-1.1144096851348877, rank=1, decoded_token='”.\\n')}, {16533: Logprob(logprob=-0.01982516422867775, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.006080462131649256, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.057018738240003586, rank=1, decoded_token=' “')}, {4110: Logprob(logprob=-9.538674354553223, rank=42, decoded_token='Create'), 258: Logprob(logprob=-0.03867468610405922, rank=1, decoded_token='in')}, {264: Logprob(logprob=-0.19192984700202942, rank=1, decoded_token=' a')}], outputs=[CompletionOutput(index=0, text=' task', token_ids=[3465], cumulative_logprob=-0.10620177537202835, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1717314192.6517913, last_token_time=1717314192.6517913, first_scheduled_time=1717314192.6585464, first_token_time=1717314192.7902024, time_in_queue=0.00675511360168457, finished_time=1717314192.8003616), lora_request=None),\n",
       " RequestOutput(request_id=5, prompt=None, prompt_token_ids=[128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 4110, 264, 3465], prompt_logprobs=[None, {3947: Logprob(logprob=-6.435123443603516, rank=47, decoded_token='There'), 14924: Logprob(logprob=-1.1851236820220947, rank=1, decoded_token='Question')}, {374: Logprob(logprob=-1.4751518964767456, rank=2, decoded_token=' is'), 527: Logprob(logprob=-0.8501518964767456, rank=1, decoded_token=' are')}, {264: Logprob(logprob=-1.1288176774978638, rank=1, decoded_token=' a')}, {1715: Logprob(logprob=-9.066563606262207, rank=886, decoded_token=' request'), 2763: Logprob(logprob=-2.441563844680786, rank=1, decoded_token=' lot')}, {505: Logprob(logprob=-2.4557113647460938, rank=3, decoded_token=' from'), 369: Logprob(logprob=-1.2057112455368042, rank=1, decoded_token=' for')}, {279: Logprob(logprob=-1.100795030593872, rank=1, decoded_token=' the')}, {1217: Logprob(logprob=-4.3608503341674805, rank=5, decoded_token=' user'), 20214: Logprob(logprob=-3.7983505725860596, rank=1, decoded_token=' Ministry')}, {311: Logprob(logprob=-0.796364963054657, rank=1, decoded_token=' to')}, {1893: Logprob(logprob=-3.0459389686584473, rank=2, decoded_token=' create'), 923: Logprob(logprob=-2.5459389686584473, rank=1, decoded_token=' add')}, {264: Logprob(logprob=-0.46096619963645935, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-5.938747882843018, rank=49, decoded_token=' task'), 502: Logprob(logprob=-2.3137478828430176, rank=1, decoded_token=' new')}, {304: Logprob(logprob=-2.125389575958252, rank=1, decoded_token=' in')}, {3465: Logprob(logprob=-5.396354675292969, rank=19, decoded_token=' task'), 279: Logprob(logprob=-1.1463544368743896, rank=1, decoded_token=' the')}, {6373: Logprob(logprob=-2.1754069328308105, rank=2, decoded_token=' management'), 6783: Logprob(logprob=-1.4254070520401, rank=1, decoded_token=' manager')}, {1887: Logprob(logprob=-1.9005897045135498, rank=1, decoded_token=' system')}, {13: Logprob(logprob=-1.4818499088287354, rank=1, decoded_token='.')}, {5321: Logprob(logprob=-4.812841415405273, rank=22, decoded_token=' Please'), 578: Logprob(logprob=-1.3128414154052734, rank=1, decoded_token=' The')}, {11: Logprob(logprob=-4.180384159088135, rank=13, decoded_token=','), 1893: Logprob(logprob=-2.0553841590881348, rank=1, decoded_token=' create')}, {8819: Logprob(logprob=-9.274468421936035, rank=367, decoded_token=' extract'), 1893: Logprob(logprob=-1.7119686603546143, rank=1, decoded_token=' create')}, {279: Logprob(logprob=-0.7036926746368408, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-7.863875865936279, rank=202, decoded_token=' status'), 3465: Logprob(logprob=-1.9888757467269897, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-1.0321611166000366, rank=1, decoded_token=' of')}, {420: Logprob(logprob=-2.7303802967071533, rank=3, decoded_token=' this'), 279: Logprob(logprob=-0.48038020730018616, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.3501986265182495, rank=1, decoded_token=' task')}, {430: Logprob(logprob=-5.973194122314453, rank=32, decoded_token=' that'), 505: Logprob(logprob=-1.2856942415237427, rank=1, decoded_token=' from')}, {690: Logprob(logprob=-2.394989490509033, rank=2, decoded_token=' will'), 374: Logprob(logprob=-1.2699893712997437, rank=1, decoded_token=' is')}, {387: Logprob(logprob=-0.4832521080970764, rank=1, decoded_token=' be')}, {9277: Logprob(logprob=-6.0560383796691895, rank=65, decoded_token=' placed'), 1511: Logprob(logprob=-2.4310383796691895, rank=1, decoded_token=' used')}, {304: Logprob(logprob=-0.4673547148704529, rank=1, decoded_token=' in')}, {5546: Logprob(logprob=-5.113916873931885, rank=13, decoded_token=' Task'), 279: Logprob(logprob=-0.7389167547225952, rank=1, decoded_token=' the')}, {9744: Logprob(logprob=-2.8428988456726074, rank=4, decoded_token=' Management'), 2583: Logprob(logprob=-1.7178988456726074, rank=1, decoded_token='Status')}, {744: Logprob(logprob=-0.3768121898174286, rank=1, decoded_token=' System')}, {627: Logprob(logprob=-1.5596171617507935, rank=2, decoded_token='.\\n'), 13: Logprob(logprob=-1.3096171617507935, rank=1, decoded_token='.')}, {13617: Logprob(logprob=-6.20838737487793, rank=54, decoded_token='Example'), 791: Logprob(logprob=-2.1458871364593506, rank=1, decoded_token='The')}, {220: Logprob(logprob=-3.4441070556640625, rank=4, decoded_token=' '), 25: Logprob(logprob=-0.881607174873352, rank=1, decoded_token=':')}, {16: Logprob(logprob=-0.14433923363685608, rank=1, decoded_token='1')}, {25: Logprob(logprob=-0.7279500961303711, rank=1, decoded_token=':')}, {5666: Logprob(logprob=-8.02212142944336, rank=207, decoded_token=' Update'), 578: Logprob(logprob=-2.209620952606201, rank=1, decoded_token=' The')}, {279: Logprob(logprob=-1.2828420400619507, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.7792110443115234, rank=1, decoded_token=' status')}, {315: Logprob(logprob=-0.4747336208820343, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.8814727663993835, rank=1, decoded_token=' the')}, {20801: Logprob(logprob=-14.885658264160156, rank=10594, decoded_token=' pent'), 3465: Logprob(logprob=-0.31119504570961, rank=1, decoded_token=' task')}, {478: Logprob(logprob=-0.6689746975898743, rank=1, decoded_token='est')}, {3465: Logprob(logprob=-1.3443454504013062, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-1.3653672933578491, rank=1, decoded_token=' to')}, {8308: Logprob(logprob=-3.6275477409362793, rank=8, decoded_token=' completed'), 330: Logprob(logprob=-1.5025477409362793, rank=1, decoded_token=' \"')}, {627: Logprob(logprob=-0.7991341352462769, rank=1, decoded_token='.\\n')}, {16533: Logprob(logprob=-8.74571418762207, rank=330, decoded_token='Answer'), 13617: Logprob(logprob=-0.7457138895988464, rank=1, decoded_token='Example')}, {25: Logprob(logprob=-0.736219048500061, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-5.012274742126465, rank=29, decoded_token=' “'), 578: Logprob(logprob=-2.574774742126465, rank=1, decoded_token=' The')}, {35835: Logprob(logprob=-4.9084882736206055, rank=18, decoded_token='completed'), 791: Logprob(logprob=-2.4709880352020264, rank=1, decoded_token='The')}, {7663: Logprob(logprob=-4.7869415283203125, rank=6, decoded_token='”\\n\\n'), 863: Logprob(logprob=-0.5994415283203125, rank=1, decoded_token='”')}, {13617: Logprob(logprob=-0.2548457384109497, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.009654378518462181, rank=1, decoded_token=' ')}, {17: Logprob(logprob=-0.011736157350242138, rank=1, decoded_token='2')}, {25: Logprob(logprob=-0.015942253172397614, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-6.879785060882568, rank=31, decoded_token=' “'), 5666: Logprob(logprob=-0.2547852396965027, rank=1, decoded_token=' Update')}, {4110: Logprob(logprob=-3.7120201587677, rank=6, decoded_token='Create'), 4387: Logprob(logprob=-2.1495201587677, rank=1, decoded_token='Update')}, {264: Logprob(logprob=-0.7378871440887451, rank=1, decoded_token=' a')}, {2082: Logprob(logprob=-8.1116304397583, rank=92, decoded_token=' code'), 3465: Logprob(logprob=-0.7366300225257874, rank=1, decoded_token=' task')}, {2098: Logprob(logprob=-5.940270900726318, rank=17, decoded_token=' ref'), 3477: Logprob(logprob=-0.3152711093425751, rank=1, decoded_token=' review')}, {76507: Logprob(logprob=-0.037638068199157715, rank=1, decoded_token='actoring')}, {3465: Logprob(logprob=-0.1042257770895958, rank=1, decoded_token=' task')}, {369: Logprob(logprob=-2.0150020122528076, rank=1, decoded_token=' for')}, {650: Logprob(logprob=-7.882807731628418, rank=255, decoded_token=' V'), 279: Logprob(logprob=-1.3203076124191284, rank=1, decoded_token=' the')}, {25041: Logprob(logprob=-8.758981704711914, rank=550, decoded_token='anya'), 6546: Logprob(logprob=-2.415231227874756, rank=1, decoded_token='CS')}, {13: Logprob(logprob=-2.7198758125305176, rank=4, decoded_token='.'), 753: Logprob(logprob=-2.1573758125305176, rank=1, decoded_token='’s')}, {1628: Logprob(logprob=-5.055873394012451, rank=22, decoded_token=' And'), 578: Logprob(logprob=-1.9308732748031616, rank=1, decoded_token=' The')}, {743: Logprob(logprob=-2.0640695095062256, rank=2, decoded_token=' set'), 2713: Logprob(logprob=-1.9390695095062256, rank=1, decoded_token=' update')}, {279: Logprob(logprob=-0.9005088806152344, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.32777857780456543, rank=1, decoded_token=' status')}, {311: Logprob(logprob=-0.701461136341095, rank=1, decoded_token=' to')}, {1054: Logprob(logprob=-2.182943344116211, rank=2, decoded_token=' “'), 304: Logprob(logprob=-1.495443344116211, rank=1, decoded_token=' in')}, {258: Logprob(logprob=-0.8141452670097351, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.26366332173347473, rank=1, decoded_token=' progress')}, {89874: Logprob(logprob=-2.47843074798584, rank=4, decoded_token='”\\n'), 863: Logprob(logprob=-0.8534306287765503, rank=1, decoded_token='”')}, {16533: Logprob(logprob=-0.06133502349257469, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.02162671647965908, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.15431392192840576, rank=1, decoded_token=' “')}, {258: Logprob(logprob=-0.1300429254770279, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.048629116266965866, rank=1, decoded_token=' progress')}, {15397: Logprob(logprob=-4.23609733581543, rank=4, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.23609726130962372, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.7214919328689575, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.011189330369234085, rank=1, decoded_token=' ')}, {18: Logprob(logprob=-0.01031437423080206, rank=1, decoded_token='3')}, {25: Logprob(logprob=-0.03739602863788605, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.6135650277137756, rank=1, decoded_token=' “')}, {7968: Logprob(logprob=-7.384041786193848, rank=78, decoded_token='Show'), 4110: Logprob(logprob=-0.8215418457984924, rank=1, decoded_token='Create')}, {757: Logprob(logprob=-1.0606498718261719, rank=2, decoded_token=' me'), 279: Logprob(logprob=-0.9981498718261719, rank=1, decoded_token=' the')}, {279: Logprob(logprob=-0.4350700080394745, rank=1, decoded_token=' the')}, {3969: Logprob(logprob=-12.134038925170898, rank=1135, decoded_token=' exec'), 2704: Logprob(logprob=-0.3527887463569641, rank=1, decoded_token=' status')}, {9663: Logprob(logprob=-0.593633234500885, rank=1, decoded_token='utors')}, {315: Logprob(logprob=-0.8525809049606323, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.5535013675689697, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.8704282641410828, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-5.152504920959473, rank=20, decoded_token=' of'), 449: Logprob(logprob=-0.6525049209594727, rank=1, decoded_token=' with')}, {9676: Logprob(logprob=-12.550848960876465, rank=5540, decoded_token=' chart'), 279: Logprob(logprob=-1.6133490800857544, rank=1, decoded_token=' the')}, {287: Logprob(logprob=-1.6783087253570557, rank=1, decoded_token='ing')}, {113068: Logprob(logprob=-3.9072160720825195, rank=8, decoded_token='”.\\n'), 279: Logprob(logprob=-1.407216191291809, rank=1, decoded_token=' the')}, {16533: Logprob(logprob=-0.0446050763130188, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.013074620626866817, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.2659088969230652, rank=1, decoded_token=' “')}, {2994: Logprob(logprob=-6.747637748718262, rank=115, decoded_token='null'), 53: Logprob(logprob=-2.0601377487182617, rank=1, decoded_token='V')}, {15397: Logprob(logprob=-1.2456005811691284, rank=2, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.8706005811691284, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.5773501396179199, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.00530478497967124, rank=1, decoded_token=' ')}, {19: Logprob(logprob=-0.00842292234301567, rank=1, decoded_token='4')}, {25: Logprob(logprob=-0.022363845258951187, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.161273792386055, rank=1, decoded_token=' “')}, {4110: Logprob(logprob=-2.079286575317383, rank=3, decoded_token='Create'), 7968: Logprob(logprob=-1.5792866945266724, rank=1, decoded_token='Show')}, {264: Logprob(logprob=-0.15873757004737854, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-0.6506558656692505, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-2.053983688354492, rank=3, decoded_token=' to'), 315: Logprob(logprob=-1.3664836883544922, rank=1, decoded_token=' of')}, {3780: Logprob(logprob=-5.3355817794799805, rank=45, decoded_token=' buy'), 2713: Logprob(logprob=-2.7105817794799805, rank=1, decoded_token=' update')}, {32656: Logprob(logprob=-6.8495988845825195, rank=74, decoded_token=' candy'), 264: Logprob(logprob=-1.0995988845825195, rank=1, decoded_token=' a')}, {11: Logprob(logprob=-3.291595220565796, rank=5, decoded_token=','), 369: Logprob(logprob=-1.041595220565796, rank=1, decoded_token=' for')}, {2704: Logprob(logprob=-3.4165704250335693, rank=6, decoded_token=' status'), 323: Logprob(logprob=-1.2290704250335693, rank=1, decoded_token=' and')}, {482: Logprob(logprob=-3.429025650024414, rank=8, decoded_token=' -'), 374: Logprob(logprob=-1.6165255308151245, rank=1, decoded_token=' is')}, {304: Logprob(logprob=-2.184178113937378, rank=2, decoded_token=' in'), 1054: Logprob(logprob=-1.121678113937378, rank=1, decoded_token=' “')}, {5208: Logprob(logprob=-0.12029757350683212, rank=1, decoded_token=' progress')}, {113068: Logprob(logprob=-1.1144096851348877, rank=1, decoded_token='”.\\n')}, {16533: Logprob(logprob=-0.01982516422867775, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.006080462131649256, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.057018738240003586, rank=1, decoded_token=' “')}, {4110: Logprob(logprob=-9.538674354553223, rank=42, decoded_token='Create'), 258: Logprob(logprob=-0.03867468610405922, rank=1, decoded_token='in')}, {264: Logprob(logprob=-0.19192984700202942, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-0.10620177537202835, rank=1, decoded_token=' task')}], outputs=[CompletionOutput(index=0, text=' to', token_ids=[311], cumulative_logprob=-0.09360155463218689, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1717314192.6519864, last_token_time=1717314192.6519864, first_scheduled_time=1717314192.6585464, first_token_time=1717314192.7902024, time_in_queue=0.006560087203979492, finished_time=1717314192.8003716), lora_request=None),\n",
       " RequestOutput(request_id=6, prompt=None, prompt_token_ids=[128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 4110, 264, 3465, 311], prompt_logprobs=[None, {3947: Logprob(logprob=-6.435123443603516, rank=47, decoded_token='There'), 14924: Logprob(logprob=-1.1851236820220947, rank=1, decoded_token='Question')}, {374: Logprob(logprob=-1.4751518964767456, rank=2, decoded_token=' is'), 527: Logprob(logprob=-0.8501518964767456, rank=1, decoded_token=' are')}, {264: Logprob(logprob=-1.1288176774978638, rank=1, decoded_token=' a')}, {1715: Logprob(logprob=-9.066563606262207, rank=886, decoded_token=' request'), 2763: Logprob(logprob=-2.441563844680786, rank=1, decoded_token=' lot')}, {505: Logprob(logprob=-2.4557113647460938, rank=3, decoded_token=' from'), 369: Logprob(logprob=-1.2057112455368042, rank=1, decoded_token=' for')}, {279: Logprob(logprob=-1.100795030593872, rank=1, decoded_token=' the')}, {1217: Logprob(logprob=-4.3608503341674805, rank=5, decoded_token=' user'), 20214: Logprob(logprob=-3.7983505725860596, rank=1, decoded_token=' Ministry')}, {311: Logprob(logprob=-0.796364963054657, rank=1, decoded_token=' to')}, {1893: Logprob(logprob=-3.0459389686584473, rank=2, decoded_token=' create'), 923: Logprob(logprob=-2.5459389686584473, rank=1, decoded_token=' add')}, {264: Logprob(logprob=-0.46096619963645935, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-5.938747882843018, rank=49, decoded_token=' task'), 502: Logprob(logprob=-2.3137478828430176, rank=1, decoded_token=' new')}, {304: Logprob(logprob=-2.125389575958252, rank=1, decoded_token=' in')}, {3465: Logprob(logprob=-5.396354675292969, rank=19, decoded_token=' task'), 279: Logprob(logprob=-1.1463544368743896, rank=1, decoded_token=' the')}, {6373: Logprob(logprob=-2.1754069328308105, rank=2, decoded_token=' management'), 6783: Logprob(logprob=-1.4254070520401, rank=1, decoded_token=' manager')}, {1887: Logprob(logprob=-1.9005897045135498, rank=1, decoded_token=' system')}, {13: Logprob(logprob=-1.4818499088287354, rank=1, decoded_token='.')}, {5321: Logprob(logprob=-4.812841415405273, rank=22, decoded_token=' Please'), 578: Logprob(logprob=-1.3128414154052734, rank=1, decoded_token=' The')}, {11: Logprob(logprob=-4.180384159088135, rank=13, decoded_token=','), 1893: Logprob(logprob=-2.0553841590881348, rank=1, decoded_token=' create')}, {8819: Logprob(logprob=-9.274468421936035, rank=367, decoded_token=' extract'), 1893: Logprob(logprob=-1.7119686603546143, rank=1, decoded_token=' create')}, {279: Logprob(logprob=-0.7036926746368408, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-7.863875865936279, rank=202, decoded_token=' status'), 3465: Logprob(logprob=-1.9888757467269897, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-1.0321611166000366, rank=1, decoded_token=' of')}, {420: Logprob(logprob=-2.7303802967071533, rank=3, decoded_token=' this'), 279: Logprob(logprob=-0.48038020730018616, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.3501986265182495, rank=1, decoded_token=' task')}, {430: Logprob(logprob=-5.973194122314453, rank=32, decoded_token=' that'), 505: Logprob(logprob=-1.2856942415237427, rank=1, decoded_token=' from')}, {690: Logprob(logprob=-2.394989490509033, rank=2, decoded_token=' will'), 374: Logprob(logprob=-1.2699893712997437, rank=1, decoded_token=' is')}, {387: Logprob(logprob=-0.4832521080970764, rank=1, decoded_token=' be')}, {9277: Logprob(logprob=-6.0560383796691895, rank=65, decoded_token=' placed'), 1511: Logprob(logprob=-2.4310383796691895, rank=1, decoded_token=' used')}, {304: Logprob(logprob=-0.4673547148704529, rank=1, decoded_token=' in')}, {5546: Logprob(logprob=-5.113916873931885, rank=13, decoded_token=' Task'), 279: Logprob(logprob=-0.7389167547225952, rank=1, decoded_token=' the')}, {9744: Logprob(logprob=-2.8428988456726074, rank=4, decoded_token=' Management'), 2583: Logprob(logprob=-1.7178988456726074, rank=1, decoded_token='Status')}, {744: Logprob(logprob=-0.3768121898174286, rank=1, decoded_token=' System')}, {627: Logprob(logprob=-1.5596171617507935, rank=2, decoded_token='.\\n'), 13: Logprob(logprob=-1.3096171617507935, rank=1, decoded_token='.')}, {13617: Logprob(logprob=-6.20838737487793, rank=54, decoded_token='Example'), 791: Logprob(logprob=-2.1458871364593506, rank=1, decoded_token='The')}, {220: Logprob(logprob=-3.4441070556640625, rank=4, decoded_token=' '), 25: Logprob(logprob=-0.881607174873352, rank=1, decoded_token=':')}, {16: Logprob(logprob=-0.14433923363685608, rank=1, decoded_token='1')}, {25: Logprob(logprob=-0.7279500961303711, rank=1, decoded_token=':')}, {5666: Logprob(logprob=-8.02212142944336, rank=207, decoded_token=' Update'), 578: Logprob(logprob=-2.209620952606201, rank=1, decoded_token=' The')}, {279: Logprob(logprob=-1.2828420400619507, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.7792110443115234, rank=1, decoded_token=' status')}, {315: Logprob(logprob=-0.4747336208820343, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.8814727663993835, rank=1, decoded_token=' the')}, {20801: Logprob(logprob=-14.885658264160156, rank=10594, decoded_token=' pent'), 3465: Logprob(logprob=-0.31119504570961, rank=1, decoded_token=' task')}, {478: Logprob(logprob=-0.6689746975898743, rank=1, decoded_token='est')}, {3465: Logprob(logprob=-1.3443454504013062, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-1.3653672933578491, rank=1, decoded_token=' to')}, {8308: Logprob(logprob=-3.6275477409362793, rank=8, decoded_token=' completed'), 330: Logprob(logprob=-1.5025477409362793, rank=1, decoded_token=' \"')}, {627: Logprob(logprob=-0.7991341352462769, rank=1, decoded_token='.\\n')}, {16533: Logprob(logprob=-8.74571418762207, rank=330, decoded_token='Answer'), 13617: Logprob(logprob=-0.7457138895988464, rank=1, decoded_token='Example')}, {25: Logprob(logprob=-0.736219048500061, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-5.012274742126465, rank=29, decoded_token=' “'), 578: Logprob(logprob=-2.574774742126465, rank=1, decoded_token=' The')}, {35835: Logprob(logprob=-4.9084882736206055, rank=18, decoded_token='completed'), 791: Logprob(logprob=-2.4709880352020264, rank=1, decoded_token='The')}, {7663: Logprob(logprob=-4.7869415283203125, rank=6, decoded_token='”\\n\\n'), 863: Logprob(logprob=-0.5994415283203125, rank=1, decoded_token='”')}, {13617: Logprob(logprob=-0.2548457384109497, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.009654378518462181, rank=1, decoded_token=' ')}, {17: Logprob(logprob=-0.011736157350242138, rank=1, decoded_token='2')}, {25: Logprob(logprob=-0.015942253172397614, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-6.879785060882568, rank=31, decoded_token=' “'), 5666: Logprob(logprob=-0.2547852396965027, rank=1, decoded_token=' Update')}, {4110: Logprob(logprob=-3.7120201587677, rank=6, decoded_token='Create'), 4387: Logprob(logprob=-2.1495201587677, rank=1, decoded_token='Update')}, {264: Logprob(logprob=-0.7378871440887451, rank=1, decoded_token=' a')}, {2082: Logprob(logprob=-8.1116304397583, rank=92, decoded_token=' code'), 3465: Logprob(logprob=-0.7366300225257874, rank=1, decoded_token=' task')}, {2098: Logprob(logprob=-5.940270900726318, rank=17, decoded_token=' ref'), 3477: Logprob(logprob=-0.3152711093425751, rank=1, decoded_token=' review')}, {76507: Logprob(logprob=-0.037638068199157715, rank=1, decoded_token='actoring')}, {3465: Logprob(logprob=-0.1042257770895958, rank=1, decoded_token=' task')}, {369: Logprob(logprob=-2.0150020122528076, rank=1, decoded_token=' for')}, {650: Logprob(logprob=-7.882807731628418, rank=255, decoded_token=' V'), 279: Logprob(logprob=-1.3203076124191284, rank=1, decoded_token=' the')}, {25041: Logprob(logprob=-8.758981704711914, rank=550, decoded_token='anya'), 6546: Logprob(logprob=-2.415231227874756, rank=1, decoded_token='CS')}, {13: Logprob(logprob=-2.7198758125305176, rank=4, decoded_token='.'), 753: Logprob(logprob=-2.1573758125305176, rank=1, decoded_token='’s')}, {1628: Logprob(logprob=-5.055873394012451, rank=22, decoded_token=' And'), 578: Logprob(logprob=-1.9308732748031616, rank=1, decoded_token=' The')}, {743: Logprob(logprob=-2.0640695095062256, rank=2, decoded_token=' set'), 2713: Logprob(logprob=-1.9390695095062256, rank=1, decoded_token=' update')}, {279: Logprob(logprob=-0.9005088806152344, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.32777857780456543, rank=1, decoded_token=' status')}, {311: Logprob(logprob=-0.701461136341095, rank=1, decoded_token=' to')}, {1054: Logprob(logprob=-2.182943344116211, rank=2, decoded_token=' “'), 304: Logprob(logprob=-1.495443344116211, rank=1, decoded_token=' in')}, {258: Logprob(logprob=-0.8141452670097351, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.26366332173347473, rank=1, decoded_token=' progress')}, {89874: Logprob(logprob=-2.47843074798584, rank=4, decoded_token='”\\n'), 863: Logprob(logprob=-0.8534306287765503, rank=1, decoded_token='”')}, {16533: Logprob(logprob=-0.06133502349257469, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.02162671647965908, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.15431392192840576, rank=1, decoded_token=' “')}, {258: Logprob(logprob=-0.1300429254770279, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.048629116266965866, rank=1, decoded_token=' progress')}, {15397: Logprob(logprob=-4.23609733581543, rank=4, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.23609726130962372, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.7214919328689575, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.011189330369234085, rank=1, decoded_token=' ')}, {18: Logprob(logprob=-0.01031437423080206, rank=1, decoded_token='3')}, {25: Logprob(logprob=-0.03739602863788605, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.6135650277137756, rank=1, decoded_token=' “')}, {7968: Logprob(logprob=-7.384041786193848, rank=78, decoded_token='Show'), 4110: Logprob(logprob=-0.8215418457984924, rank=1, decoded_token='Create')}, {757: Logprob(logprob=-1.0606498718261719, rank=2, decoded_token=' me'), 279: Logprob(logprob=-0.9981498718261719, rank=1, decoded_token=' the')}, {279: Logprob(logprob=-0.4350700080394745, rank=1, decoded_token=' the')}, {3969: Logprob(logprob=-12.134038925170898, rank=1135, decoded_token=' exec'), 2704: Logprob(logprob=-0.3527887463569641, rank=1, decoded_token=' status')}, {9663: Logprob(logprob=-0.593633234500885, rank=1, decoded_token='utors')}, {315: Logprob(logprob=-0.8525809049606323, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.5535013675689697, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.8704282641410828, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-5.152504920959473, rank=20, decoded_token=' of'), 449: Logprob(logprob=-0.6525049209594727, rank=1, decoded_token=' with')}, {9676: Logprob(logprob=-12.550848960876465, rank=5540, decoded_token=' chart'), 279: Logprob(logprob=-1.6133490800857544, rank=1, decoded_token=' the')}, {287: Logprob(logprob=-1.6783087253570557, rank=1, decoded_token='ing')}, {113068: Logprob(logprob=-3.9072160720825195, rank=8, decoded_token='”.\\n'), 279: Logprob(logprob=-1.407216191291809, rank=1, decoded_token=' the')}, {16533: Logprob(logprob=-0.0446050763130188, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.013074620626866817, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.2659088969230652, rank=1, decoded_token=' “')}, {2994: Logprob(logprob=-6.747637748718262, rank=115, decoded_token='null'), 53: Logprob(logprob=-2.0601377487182617, rank=1, decoded_token='V')}, {15397: Logprob(logprob=-1.2456005811691284, rank=2, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.8706005811691284, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.5773501396179199, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.00530478497967124, rank=1, decoded_token=' ')}, {19: Logprob(logprob=-0.00842292234301567, rank=1, decoded_token='4')}, {25: Logprob(logprob=-0.022363845258951187, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.161273792386055, rank=1, decoded_token=' “')}, {4110: Logprob(logprob=-2.079286575317383, rank=3, decoded_token='Create'), 7968: Logprob(logprob=-1.5792866945266724, rank=1, decoded_token='Show')}, {264: Logprob(logprob=-0.15873757004737854, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-0.6506558656692505, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-2.053983688354492, rank=3, decoded_token=' to'), 315: Logprob(logprob=-1.3664836883544922, rank=1, decoded_token=' of')}, {3780: Logprob(logprob=-5.3355817794799805, rank=45, decoded_token=' buy'), 2713: Logprob(logprob=-2.7105817794799805, rank=1, decoded_token=' update')}, {32656: Logprob(logprob=-6.8495988845825195, rank=74, decoded_token=' candy'), 264: Logprob(logprob=-1.0995988845825195, rank=1, decoded_token=' a')}, {11: Logprob(logprob=-3.291595220565796, rank=5, decoded_token=','), 369: Logprob(logprob=-1.041595220565796, rank=1, decoded_token=' for')}, {2704: Logprob(logprob=-3.4165704250335693, rank=6, decoded_token=' status'), 323: Logprob(logprob=-1.2290704250335693, rank=1, decoded_token=' and')}, {482: Logprob(logprob=-3.429025650024414, rank=8, decoded_token=' -'), 374: Logprob(logprob=-1.6165255308151245, rank=1, decoded_token=' is')}, {304: Logprob(logprob=-2.184178113937378, rank=2, decoded_token=' in'), 1054: Logprob(logprob=-1.121678113937378, rank=1, decoded_token=' “')}, {5208: Logprob(logprob=-0.12029757350683212, rank=1, decoded_token=' progress')}, {113068: Logprob(logprob=-1.1144096851348877, rank=1, decoded_token='”.\\n')}, {16533: Logprob(logprob=-0.01982516422867775, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.006080462131649256, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.057018738240003586, rank=1, decoded_token=' “')}, {4110: Logprob(logprob=-9.538674354553223, rank=42, decoded_token='Create'), 258: Logprob(logprob=-0.03867468610405922, rank=1, decoded_token='in')}, {264: Logprob(logprob=-0.19192984700202942, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-0.10620177537202835, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-0.09360155463218689, rank=1, decoded_token=' to')}], outputs=[CompletionOutput(index=0, text=' buy', token_ids=[3780], cumulative_logprob=-0.016560828313231468, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1717314192.6521883, last_token_time=1717314192.6521883, first_scheduled_time=1717314192.6585464, first_token_time=1717314192.7902024, time_in_queue=0.006358146667480469, finished_time=1717314192.800381), lora_request=None),\n",
       " RequestOutput(request_id=7, prompt=None, prompt_token_ids=[128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 64], prompt_logprobs=[None, {3947: Logprob(logprob=-6.435123443603516, rank=47, decoded_token='There'), 14924: Logprob(logprob=-1.1851236820220947, rank=1, decoded_token='Question')}, {374: Logprob(logprob=-1.4751518964767456, rank=2, decoded_token=' is'), 527: Logprob(logprob=-0.8501518964767456, rank=1, decoded_token=' are')}, {264: Logprob(logprob=-1.1288176774978638, rank=1, decoded_token=' a')}, {1715: Logprob(logprob=-9.066563606262207, rank=886, decoded_token=' request'), 2763: Logprob(logprob=-2.441563844680786, rank=1, decoded_token=' lot')}, {505: Logprob(logprob=-2.4557113647460938, rank=3, decoded_token=' from'), 369: Logprob(logprob=-1.2057112455368042, rank=1, decoded_token=' for')}, {279: Logprob(logprob=-1.100795030593872, rank=1, decoded_token=' the')}, {1217: Logprob(logprob=-4.3608503341674805, rank=5, decoded_token=' user'), 20214: Logprob(logprob=-3.7983505725860596, rank=1, decoded_token=' Ministry')}, {311: Logprob(logprob=-0.796364963054657, rank=1, decoded_token=' to')}, {1893: Logprob(logprob=-3.0459389686584473, rank=2, decoded_token=' create'), 923: Logprob(logprob=-2.5459389686584473, rank=1, decoded_token=' add')}, {264: Logprob(logprob=-0.46096619963645935, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-5.938747882843018, rank=49, decoded_token=' task'), 502: Logprob(logprob=-2.3137478828430176, rank=1, decoded_token=' new')}, {304: Logprob(logprob=-2.125389575958252, rank=1, decoded_token=' in')}, {3465: Logprob(logprob=-5.396354675292969, rank=19, decoded_token=' task'), 279: Logprob(logprob=-1.1463544368743896, rank=1, decoded_token=' the')}, {6373: Logprob(logprob=-2.1754069328308105, rank=2, decoded_token=' management'), 6783: Logprob(logprob=-1.4254070520401, rank=1, decoded_token=' manager')}, {1887: Logprob(logprob=-1.9005897045135498, rank=1, decoded_token=' system')}, {13: Logprob(logprob=-1.4818499088287354, rank=1, decoded_token='.')}, {5321: Logprob(logprob=-4.812841415405273, rank=22, decoded_token=' Please'), 578: Logprob(logprob=-1.3128414154052734, rank=1, decoded_token=' The')}, {11: Logprob(logprob=-4.180384159088135, rank=13, decoded_token=','), 1893: Logprob(logprob=-2.0553841590881348, rank=1, decoded_token=' create')}, {8819: Logprob(logprob=-9.274468421936035, rank=367, decoded_token=' extract'), 1893: Logprob(logprob=-1.7119686603546143, rank=1, decoded_token=' create')}, {279: Logprob(logprob=-0.7036926746368408, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-7.863875865936279, rank=202, decoded_token=' status'), 3465: Logprob(logprob=-1.9888757467269897, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-1.0321611166000366, rank=1, decoded_token=' of')}, {420: Logprob(logprob=-2.7303802967071533, rank=3, decoded_token=' this'), 279: Logprob(logprob=-0.48038020730018616, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.3501986265182495, rank=1, decoded_token=' task')}, {430: Logprob(logprob=-5.973194122314453, rank=32, decoded_token=' that'), 505: Logprob(logprob=-1.2856942415237427, rank=1, decoded_token=' from')}, {690: Logprob(logprob=-2.394989490509033, rank=2, decoded_token=' will'), 374: Logprob(logprob=-1.2699893712997437, rank=1, decoded_token=' is')}, {387: Logprob(logprob=-0.4832521080970764, rank=1, decoded_token=' be')}, {9277: Logprob(logprob=-6.0560383796691895, rank=65, decoded_token=' placed'), 1511: Logprob(logprob=-2.4310383796691895, rank=1, decoded_token=' used')}, {304: Logprob(logprob=-0.4673547148704529, rank=1, decoded_token=' in')}, {5546: Logprob(logprob=-5.113916873931885, rank=13, decoded_token=' Task'), 279: Logprob(logprob=-0.7389167547225952, rank=1, decoded_token=' the')}, {9744: Logprob(logprob=-2.8428988456726074, rank=4, decoded_token=' Management'), 2583: Logprob(logprob=-1.7178988456726074, rank=1, decoded_token='Status')}, {744: Logprob(logprob=-0.3768121898174286, rank=1, decoded_token=' System')}, {627: Logprob(logprob=-1.5596171617507935, rank=2, decoded_token='.\\n'), 13: Logprob(logprob=-1.3096171617507935, rank=1, decoded_token='.')}, {13617: Logprob(logprob=-6.20838737487793, rank=54, decoded_token='Example'), 791: Logprob(logprob=-2.1458871364593506, rank=1, decoded_token='The')}, {220: Logprob(logprob=-3.4441070556640625, rank=4, decoded_token=' '), 25: Logprob(logprob=-0.881607174873352, rank=1, decoded_token=':')}, {16: Logprob(logprob=-0.14433923363685608, rank=1, decoded_token='1')}, {25: Logprob(logprob=-0.7279500961303711, rank=1, decoded_token=':')}, {5666: Logprob(logprob=-8.02212142944336, rank=207, decoded_token=' Update'), 578: Logprob(logprob=-2.209620952606201, rank=1, decoded_token=' The')}, {279: Logprob(logprob=-1.2828420400619507, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.7792110443115234, rank=1, decoded_token=' status')}, {315: Logprob(logprob=-0.4747336208820343, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.8814727663993835, rank=1, decoded_token=' the')}, {20801: Logprob(logprob=-14.885658264160156, rank=10594, decoded_token=' pent'), 3465: Logprob(logprob=-0.31119504570961, rank=1, decoded_token=' task')}, {478: Logprob(logprob=-0.6689746975898743, rank=1, decoded_token='est')}, {3465: Logprob(logprob=-1.3443454504013062, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-1.3653672933578491, rank=1, decoded_token=' to')}, {8308: Logprob(logprob=-3.6275477409362793, rank=8, decoded_token=' completed'), 330: Logprob(logprob=-1.5025477409362793, rank=1, decoded_token=' \"')}, {627: Logprob(logprob=-0.7991341352462769, rank=1, decoded_token='.\\n')}, {16533: Logprob(logprob=-8.74571418762207, rank=330, decoded_token='Answer'), 13617: Logprob(logprob=-0.7457138895988464, rank=1, decoded_token='Example')}, {25: Logprob(logprob=-0.736219048500061, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-5.012274742126465, rank=29, decoded_token=' “'), 578: Logprob(logprob=-2.574774742126465, rank=1, decoded_token=' The')}, {35835: Logprob(logprob=-4.9084882736206055, rank=18, decoded_token='completed'), 791: Logprob(logprob=-2.4709880352020264, rank=1, decoded_token='The')}, {7663: Logprob(logprob=-4.7869415283203125, rank=6, decoded_token='”\\n\\n'), 863: Logprob(logprob=-0.5994415283203125, rank=1, decoded_token='”')}, {13617: Logprob(logprob=-0.2548457384109497, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.009654378518462181, rank=1, decoded_token=' ')}, {17: Logprob(logprob=-0.011736157350242138, rank=1, decoded_token='2')}, {25: Logprob(logprob=-0.015942253172397614, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-6.879785060882568, rank=31, decoded_token=' “'), 5666: Logprob(logprob=-0.2547852396965027, rank=1, decoded_token=' Update')}, {4110: Logprob(logprob=-3.7120201587677, rank=6, decoded_token='Create'), 4387: Logprob(logprob=-2.1495201587677, rank=1, decoded_token='Update')}, {264: Logprob(logprob=-0.7378871440887451, rank=1, decoded_token=' a')}, {2082: Logprob(logprob=-8.1116304397583, rank=92, decoded_token=' code'), 3465: Logprob(logprob=-0.7366300225257874, rank=1, decoded_token=' task')}, {2098: Logprob(logprob=-5.940270900726318, rank=17, decoded_token=' ref'), 3477: Logprob(logprob=-0.3152711093425751, rank=1, decoded_token=' review')}, {76507: Logprob(logprob=-0.037638068199157715, rank=1, decoded_token='actoring')}, {3465: Logprob(logprob=-0.1042257770895958, rank=1, decoded_token=' task')}, {369: Logprob(logprob=-2.0150020122528076, rank=1, decoded_token=' for')}, {650: Logprob(logprob=-7.882807731628418, rank=255, decoded_token=' V'), 279: Logprob(logprob=-1.3203076124191284, rank=1, decoded_token=' the')}, {25041: Logprob(logprob=-8.758981704711914, rank=550, decoded_token='anya'), 6546: Logprob(logprob=-2.415231227874756, rank=1, decoded_token='CS')}, {13: Logprob(logprob=-2.7198758125305176, rank=4, decoded_token='.'), 753: Logprob(logprob=-2.1573758125305176, rank=1, decoded_token='’s')}, {1628: Logprob(logprob=-5.055873394012451, rank=22, decoded_token=' And'), 578: Logprob(logprob=-1.9308732748031616, rank=1, decoded_token=' The')}, {743: Logprob(logprob=-2.0640695095062256, rank=2, decoded_token=' set'), 2713: Logprob(logprob=-1.9390695095062256, rank=1, decoded_token=' update')}, {279: Logprob(logprob=-0.9005088806152344, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.32777857780456543, rank=1, decoded_token=' status')}, {311: Logprob(logprob=-0.701461136341095, rank=1, decoded_token=' to')}, {1054: Logprob(logprob=-2.182943344116211, rank=2, decoded_token=' “'), 304: Logprob(logprob=-1.495443344116211, rank=1, decoded_token=' in')}, {258: Logprob(logprob=-0.8141452670097351, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.26366332173347473, rank=1, decoded_token=' progress')}, {89874: Logprob(logprob=-2.47843074798584, rank=4, decoded_token='”\\n'), 863: Logprob(logprob=-0.8534306287765503, rank=1, decoded_token='”')}, {16533: Logprob(logprob=-0.06133502349257469, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.02162671647965908, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.15431392192840576, rank=1, decoded_token=' “')}, {258: Logprob(logprob=-0.1300429254770279, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.048629116266965866, rank=1, decoded_token=' progress')}, {15397: Logprob(logprob=-4.23609733581543, rank=4, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.23609726130962372, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.7214919328689575, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.011189330369234085, rank=1, decoded_token=' ')}, {18: Logprob(logprob=-0.01031437423080206, rank=1, decoded_token='3')}, {25: Logprob(logprob=-0.03739602863788605, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.6135650277137756, rank=1, decoded_token=' “')}, {7968: Logprob(logprob=-7.384041786193848, rank=78, decoded_token='Show'), 4110: Logprob(logprob=-0.8215418457984924, rank=1, decoded_token='Create')}, {757: Logprob(logprob=-1.0606498718261719, rank=2, decoded_token=' me'), 279: Logprob(logprob=-0.9981498718261719, rank=1, decoded_token=' the')}, {279: Logprob(logprob=-0.4350700080394745, rank=1, decoded_token=' the')}, {3969: Logprob(logprob=-12.134038925170898, rank=1135, decoded_token=' exec'), 2704: Logprob(logprob=-0.3527887463569641, rank=1, decoded_token=' status')}, {9663: Logprob(logprob=-0.593633234500885, rank=1, decoded_token='utors')}, {315: Logprob(logprob=-0.8525809049606323, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.5535013675689697, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.8704282641410828, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-5.152504920959473, rank=20, decoded_token=' of'), 449: Logprob(logprob=-0.6525049209594727, rank=1, decoded_token=' with')}, {9676: Logprob(logprob=-12.550848960876465, rank=5540, decoded_token=' chart'), 279: Logprob(logprob=-1.6133490800857544, rank=1, decoded_token=' the')}, {287: Logprob(logprob=-1.6783087253570557, rank=1, decoded_token='ing')}, {113068: Logprob(logprob=-3.9072160720825195, rank=8, decoded_token='”.\\n'), 279: Logprob(logprob=-1.407216191291809, rank=1, decoded_token=' the')}, {16533: Logprob(logprob=-0.0446050763130188, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.013074620626866817, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.2659088969230652, rank=1, decoded_token=' “')}, {2994: Logprob(logprob=-6.747637748718262, rank=115, decoded_token='null'), 53: Logprob(logprob=-2.0601377487182617, rank=1, decoded_token='V')}, {15397: Logprob(logprob=-1.2456005811691284, rank=2, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.8706005811691284, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.5773501396179199, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.00530478497967124, rank=1, decoded_token=' ')}, {19: Logprob(logprob=-0.00842292234301567, rank=1, decoded_token='4')}, {25: Logprob(logprob=-0.022363845258951187, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.161273792386055, rank=1, decoded_token=' “')}, {4110: Logprob(logprob=-2.079286575317383, rank=3, decoded_token='Create'), 7968: Logprob(logprob=-1.5792866945266724, rank=1, decoded_token='Show')}, {264: Logprob(logprob=-0.15873757004737854, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-0.6506558656692505, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-2.053983688354492, rank=3, decoded_token=' to'), 315: Logprob(logprob=-1.3664836883544922, rank=1, decoded_token=' of')}, {3780: Logprob(logprob=-5.3355817794799805, rank=45, decoded_token=' buy'), 2713: Logprob(logprob=-2.7105817794799805, rank=1, decoded_token=' update')}, {32656: Logprob(logprob=-6.8495988845825195, rank=74, decoded_token=' candy'), 264: Logprob(logprob=-1.0995988845825195, rank=1, decoded_token=' a')}, {11: Logprob(logprob=-3.291595220565796, rank=5, decoded_token=','), 369: Logprob(logprob=-1.041595220565796, rank=1, decoded_token=' for')}, {2704: Logprob(logprob=-3.4165704250335693, rank=6, decoded_token=' status'), 323: Logprob(logprob=-1.2290704250335693, rank=1, decoded_token=' and')}, {482: Logprob(logprob=-3.429025650024414, rank=8, decoded_token=' -'), 374: Logprob(logprob=-1.6165255308151245, rank=1, decoded_token=' is')}, {304: Logprob(logprob=-2.184178113937378, rank=2, decoded_token=' in'), 1054: Logprob(logprob=-1.121678113937378, rank=1, decoded_token=' “')}, {5208: Logprob(logprob=-0.12029757350683212, rank=1, decoded_token=' progress')}, {113068: Logprob(logprob=-1.1144096851348877, rank=1, decoded_token='”.\\n')}, {16533: Logprob(logprob=-0.01982516422867775, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.006080462131649256, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.057018738240003586, rank=1, decoded_token=' “')}, {64: Logprob(logprob=-9.976174354553223, rank=64, decoded_token='a'), 258: Logprob(logprob=-0.03867468610405922, rank=1, decoded_token='in')}], outputs=[CompletionOutput(index=0, text=' task', token_ids=[3465], cumulative_logprob=-1.596139907836914, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1717314192.652391, last_token_time=1717314192.652391, first_scheduled_time=1717314192.6585464, first_token_time=1717314192.7902024, time_in_queue=0.006155490875244141, finished_time=1717314192.80039), lora_request=None),\n",
       " RequestOutput(request_id=8, prompt=None, prompt_token_ids=[128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 64, 3465], prompt_logprobs=[None, {3947: Logprob(logprob=-6.435123443603516, rank=47, decoded_token='There'), 14924: Logprob(logprob=-1.1851236820220947, rank=1, decoded_token='Question')}, {374: Logprob(logprob=-1.4751518964767456, rank=2, decoded_token=' is'), 527: Logprob(logprob=-0.8501518964767456, rank=1, decoded_token=' are')}, {264: Logprob(logprob=-1.1288176774978638, rank=1, decoded_token=' a')}, {1715: Logprob(logprob=-9.066563606262207, rank=886, decoded_token=' request'), 2763: Logprob(logprob=-2.441563844680786, rank=1, decoded_token=' lot')}, {505: Logprob(logprob=-2.4557113647460938, rank=3, decoded_token=' from'), 369: Logprob(logprob=-1.2057112455368042, rank=1, decoded_token=' for')}, {279: Logprob(logprob=-1.100795030593872, rank=1, decoded_token=' the')}, {1217: Logprob(logprob=-4.3608503341674805, rank=5, decoded_token=' user'), 20214: Logprob(logprob=-3.7983505725860596, rank=1, decoded_token=' Ministry')}, {311: Logprob(logprob=-0.796364963054657, rank=1, decoded_token=' to')}, {1893: Logprob(logprob=-3.0459389686584473, rank=2, decoded_token=' create'), 923: Logprob(logprob=-2.5459389686584473, rank=1, decoded_token=' add')}, {264: Logprob(logprob=-0.46096619963645935, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-5.938747882843018, rank=49, decoded_token=' task'), 502: Logprob(logprob=-2.3137478828430176, rank=1, decoded_token=' new')}, {304: Logprob(logprob=-2.125389575958252, rank=1, decoded_token=' in')}, {3465: Logprob(logprob=-5.396354675292969, rank=19, decoded_token=' task'), 279: Logprob(logprob=-1.1463544368743896, rank=1, decoded_token=' the')}, {6373: Logprob(logprob=-2.1754069328308105, rank=2, decoded_token=' management'), 6783: Logprob(logprob=-1.4254070520401, rank=1, decoded_token=' manager')}, {1887: Logprob(logprob=-1.9005897045135498, rank=1, decoded_token=' system')}, {13: Logprob(logprob=-1.4818499088287354, rank=1, decoded_token='.')}, {5321: Logprob(logprob=-4.812841415405273, rank=22, decoded_token=' Please'), 578: Logprob(logprob=-1.3128414154052734, rank=1, decoded_token=' The')}, {11: Logprob(logprob=-4.180384159088135, rank=13, decoded_token=','), 1893: Logprob(logprob=-2.0553841590881348, rank=1, decoded_token=' create')}, {8819: Logprob(logprob=-9.274468421936035, rank=367, decoded_token=' extract'), 1893: Logprob(logprob=-1.7119686603546143, rank=1, decoded_token=' create')}, {279: Logprob(logprob=-0.7036926746368408, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-7.863875865936279, rank=202, decoded_token=' status'), 3465: Logprob(logprob=-1.9888757467269897, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-1.0321611166000366, rank=1, decoded_token=' of')}, {420: Logprob(logprob=-2.7303802967071533, rank=3, decoded_token=' this'), 279: Logprob(logprob=-0.48038020730018616, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.3501986265182495, rank=1, decoded_token=' task')}, {430: Logprob(logprob=-5.973194122314453, rank=32, decoded_token=' that'), 505: Logprob(logprob=-1.2856942415237427, rank=1, decoded_token=' from')}, {690: Logprob(logprob=-2.394989490509033, rank=2, decoded_token=' will'), 374: Logprob(logprob=-1.2699893712997437, rank=1, decoded_token=' is')}, {387: Logprob(logprob=-0.4832521080970764, rank=1, decoded_token=' be')}, {9277: Logprob(logprob=-6.0560383796691895, rank=65, decoded_token=' placed'), 1511: Logprob(logprob=-2.4310383796691895, rank=1, decoded_token=' used')}, {304: Logprob(logprob=-0.4673547148704529, rank=1, decoded_token=' in')}, {5546: Logprob(logprob=-5.113916873931885, rank=13, decoded_token=' Task'), 279: Logprob(logprob=-0.7389167547225952, rank=1, decoded_token=' the')}, {9744: Logprob(logprob=-2.8428988456726074, rank=4, decoded_token=' Management'), 2583: Logprob(logprob=-1.7178988456726074, rank=1, decoded_token='Status')}, {744: Logprob(logprob=-0.3768121898174286, rank=1, decoded_token=' System')}, {627: Logprob(logprob=-1.5596171617507935, rank=2, decoded_token='.\\n'), 13: Logprob(logprob=-1.3096171617507935, rank=1, decoded_token='.')}, {13617: Logprob(logprob=-6.20838737487793, rank=54, decoded_token='Example'), 791: Logprob(logprob=-2.1458871364593506, rank=1, decoded_token='The')}, {220: Logprob(logprob=-3.4441070556640625, rank=4, decoded_token=' '), 25: Logprob(logprob=-0.881607174873352, rank=1, decoded_token=':')}, {16: Logprob(logprob=-0.14433923363685608, rank=1, decoded_token='1')}, {25: Logprob(logprob=-0.7279500961303711, rank=1, decoded_token=':')}, {5666: Logprob(logprob=-8.02212142944336, rank=207, decoded_token=' Update'), 578: Logprob(logprob=-2.209620952606201, rank=1, decoded_token=' The')}, {279: Logprob(logprob=-1.2828420400619507, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.7792110443115234, rank=1, decoded_token=' status')}, {315: Logprob(logprob=-0.4747336208820343, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.8814727663993835, rank=1, decoded_token=' the')}, {20801: Logprob(logprob=-14.885658264160156, rank=10594, decoded_token=' pent'), 3465: Logprob(logprob=-0.31119504570961, rank=1, decoded_token=' task')}, {478: Logprob(logprob=-0.6689746975898743, rank=1, decoded_token='est')}, {3465: Logprob(logprob=-1.3443454504013062, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-1.3653672933578491, rank=1, decoded_token=' to')}, {8308: Logprob(logprob=-3.6275477409362793, rank=8, decoded_token=' completed'), 330: Logprob(logprob=-1.5025477409362793, rank=1, decoded_token=' \"')}, {627: Logprob(logprob=-0.7991341352462769, rank=1, decoded_token='.\\n')}, {16533: Logprob(logprob=-8.74571418762207, rank=330, decoded_token='Answer'), 13617: Logprob(logprob=-0.7457138895988464, rank=1, decoded_token='Example')}, {25: Logprob(logprob=-0.736219048500061, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-5.012274742126465, rank=29, decoded_token=' “'), 578: Logprob(logprob=-2.574774742126465, rank=1, decoded_token=' The')}, {35835: Logprob(logprob=-4.9084882736206055, rank=18, decoded_token='completed'), 791: Logprob(logprob=-2.4709880352020264, rank=1, decoded_token='The')}, {7663: Logprob(logprob=-4.7869415283203125, rank=6, decoded_token='”\\n\\n'), 863: Logprob(logprob=-0.5994415283203125, rank=1, decoded_token='”')}, {13617: Logprob(logprob=-0.2548457384109497, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.009654378518462181, rank=1, decoded_token=' ')}, {17: Logprob(logprob=-0.011736157350242138, rank=1, decoded_token='2')}, {25: Logprob(logprob=-0.015942253172397614, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-6.879785060882568, rank=31, decoded_token=' “'), 5666: Logprob(logprob=-0.2547852396965027, rank=1, decoded_token=' Update')}, {4110: Logprob(logprob=-3.7120201587677, rank=6, decoded_token='Create'), 4387: Logprob(logprob=-2.1495201587677, rank=1, decoded_token='Update')}, {264: Logprob(logprob=-0.7378871440887451, rank=1, decoded_token=' a')}, {2082: Logprob(logprob=-8.1116304397583, rank=92, decoded_token=' code'), 3465: Logprob(logprob=-0.7366300225257874, rank=1, decoded_token=' task')}, {2098: Logprob(logprob=-5.940270900726318, rank=17, decoded_token=' ref'), 3477: Logprob(logprob=-0.3152711093425751, rank=1, decoded_token=' review')}, {76507: Logprob(logprob=-0.037638068199157715, rank=1, decoded_token='actoring')}, {3465: Logprob(logprob=-0.1042257770895958, rank=1, decoded_token=' task')}, {369: Logprob(logprob=-2.0150020122528076, rank=1, decoded_token=' for')}, {650: Logprob(logprob=-7.882807731628418, rank=255, decoded_token=' V'), 279: Logprob(logprob=-1.3203076124191284, rank=1, decoded_token=' the')}, {25041: Logprob(logprob=-8.758981704711914, rank=550, decoded_token='anya'), 6546: Logprob(logprob=-2.415231227874756, rank=1, decoded_token='CS')}, {13: Logprob(logprob=-2.7198758125305176, rank=4, decoded_token='.'), 753: Logprob(logprob=-2.1573758125305176, rank=1, decoded_token='’s')}, {1628: Logprob(logprob=-5.055873394012451, rank=22, decoded_token=' And'), 578: Logprob(logprob=-1.9308732748031616, rank=1, decoded_token=' The')}, {743: Logprob(logprob=-2.0640695095062256, rank=2, decoded_token=' set'), 2713: Logprob(logprob=-1.9390695095062256, rank=1, decoded_token=' update')}, {279: Logprob(logprob=-0.9005088806152344, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.32777857780456543, rank=1, decoded_token=' status')}, {311: Logprob(logprob=-0.701461136341095, rank=1, decoded_token=' to')}, {1054: Logprob(logprob=-2.182943344116211, rank=2, decoded_token=' “'), 304: Logprob(logprob=-1.495443344116211, rank=1, decoded_token=' in')}, {258: Logprob(logprob=-0.8141452670097351, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.26366332173347473, rank=1, decoded_token=' progress')}, {89874: Logprob(logprob=-2.47843074798584, rank=4, decoded_token='”\\n'), 863: Logprob(logprob=-0.8534306287765503, rank=1, decoded_token='”')}, {16533: Logprob(logprob=-0.06133502349257469, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.02162671647965908, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.15431392192840576, rank=1, decoded_token=' “')}, {258: Logprob(logprob=-0.1300429254770279, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.048629116266965866, rank=1, decoded_token=' progress')}, {15397: Logprob(logprob=-4.23609733581543, rank=4, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.23609726130962372, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.7214919328689575, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.011189330369234085, rank=1, decoded_token=' ')}, {18: Logprob(logprob=-0.01031437423080206, rank=1, decoded_token='3')}, {25: Logprob(logprob=-0.03739602863788605, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.6135650277137756, rank=1, decoded_token=' “')}, {7968: Logprob(logprob=-7.384041786193848, rank=78, decoded_token='Show'), 4110: Logprob(logprob=-0.8215418457984924, rank=1, decoded_token='Create')}, {757: Logprob(logprob=-1.0606498718261719, rank=2, decoded_token=' me'), 279: Logprob(logprob=-0.9981498718261719, rank=1, decoded_token=' the')}, {279: Logprob(logprob=-0.4350700080394745, rank=1, decoded_token=' the')}, {3969: Logprob(logprob=-12.134038925170898, rank=1135, decoded_token=' exec'), 2704: Logprob(logprob=-0.3527887463569641, rank=1, decoded_token=' status')}, {9663: Logprob(logprob=-0.593633234500885, rank=1, decoded_token='utors')}, {315: Logprob(logprob=-0.8525809049606323, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.5535013675689697, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.8704282641410828, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-5.152504920959473, rank=20, decoded_token=' of'), 449: Logprob(logprob=-0.6525049209594727, rank=1, decoded_token=' with')}, {9676: Logprob(logprob=-12.550848960876465, rank=5540, decoded_token=' chart'), 279: Logprob(logprob=-1.6133490800857544, rank=1, decoded_token=' the')}, {287: Logprob(logprob=-1.6783087253570557, rank=1, decoded_token='ing')}, {113068: Logprob(logprob=-3.9072160720825195, rank=8, decoded_token='”.\\n'), 279: Logprob(logprob=-1.407216191291809, rank=1, decoded_token=' the')}, {16533: Logprob(logprob=-0.0446050763130188, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.013074620626866817, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.2659088969230652, rank=1, decoded_token=' “')}, {2994: Logprob(logprob=-6.747637748718262, rank=115, decoded_token='null'), 53: Logprob(logprob=-2.0601377487182617, rank=1, decoded_token='V')}, {15397: Logprob(logprob=-1.2456005811691284, rank=2, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.8706005811691284, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.5773501396179199, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.00530478497967124, rank=1, decoded_token=' ')}, {19: Logprob(logprob=-0.00842292234301567, rank=1, decoded_token='4')}, {25: Logprob(logprob=-0.022363845258951187, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.161273792386055, rank=1, decoded_token=' “')}, {4110: Logprob(logprob=-2.079286575317383, rank=3, decoded_token='Create'), 7968: Logprob(logprob=-1.5792866945266724, rank=1, decoded_token='Show')}, {264: Logprob(logprob=-0.15873757004737854, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-0.6506558656692505, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-2.053983688354492, rank=3, decoded_token=' to'), 315: Logprob(logprob=-1.3664836883544922, rank=1, decoded_token=' of')}, {3780: Logprob(logprob=-5.3355817794799805, rank=45, decoded_token=' buy'), 2713: Logprob(logprob=-2.7105817794799805, rank=1, decoded_token=' update')}, {32656: Logprob(logprob=-6.8495988845825195, rank=74, decoded_token=' candy'), 264: Logprob(logprob=-1.0995988845825195, rank=1, decoded_token=' a')}, {11: Logprob(logprob=-3.291595220565796, rank=5, decoded_token=','), 369: Logprob(logprob=-1.041595220565796, rank=1, decoded_token=' for')}, {2704: Logprob(logprob=-3.4165704250335693, rank=6, decoded_token=' status'), 323: Logprob(logprob=-1.2290704250335693, rank=1, decoded_token=' and')}, {482: Logprob(logprob=-3.429025650024414, rank=8, decoded_token=' -'), 374: Logprob(logprob=-1.6165255308151245, rank=1, decoded_token=' is')}, {304: Logprob(logprob=-2.184178113937378, rank=2, decoded_token=' in'), 1054: Logprob(logprob=-1.121678113937378, rank=1, decoded_token=' “')}, {5208: Logprob(logprob=-0.12029757350683212, rank=1, decoded_token=' progress')}, {113068: Logprob(logprob=-1.1144096851348877, rank=1, decoded_token='”.\\n')}, {16533: Logprob(logprob=-0.01982516422867775, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.006080462131649256, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.057018738240003586, rank=1, decoded_token=' “')}, {64: Logprob(logprob=-9.976174354553223, rank=64, decoded_token='a'), 258: Logprob(logprob=-0.03867468610405922, rank=1, decoded_token='in')}, {3465: Logprob(logprob=-1.596139907836914, rank=1, decoded_token=' task')}], outputs=[CompletionOutput(index=0, text=' has', token_ids=[706], cumulative_logprob=-3.6453609466552734, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1717314192.6525917, last_token_time=1717314192.6525917, first_scheduled_time=1717314192.6585464, first_token_time=1717314192.7902024, time_in_queue=0.005954742431640625, finished_time=1717314192.8003988), lora_request=None),\n",
       " RequestOutput(request_id=9, prompt=None, prompt_token_ids=[128000, 3947, 374, 264, 1715, 505, 279, 1217, 311, 1893, 264, 3465, 304, 3465, 6373, 1887, 13, 5321, 11, 8819, 279, 2704, 315, 420, 3465, 430, 690, 387, 9277, 304, 5546, 9744, 744, 627, 13617, 220, 16, 25, 5666, 279, 2704, 315, 279, 20801, 478, 3465, 311, 8308, 627, 16533, 25, 1054, 35835, 7663, 13617, 220, 17, 25, 1054, 4110, 264, 2082, 2098, 76507, 3465, 369, 650, 25041, 13, 1628, 743, 279, 2704, 311, 1054, 258, 5208, 89874, 16533, 25, 1054, 258, 5208, 15397, 13617, 220, 18, 25, 1054, 7968, 757, 279, 3969, 9663, 315, 279, 3465, 315, 9676, 287, 113068, 16533, 25, 1054, 2994, 15397, 13617, 220, 19, 25, 1054, 4110, 264, 3465, 311, 3780, 32656, 11, 2704, 482, 304, 5208, 113068, 16533, 25, 1054, 64, 3465, 311], prompt_logprobs=[None, {3947: Logprob(logprob=-6.435123443603516, rank=47, decoded_token='There'), 14924: Logprob(logprob=-1.1851236820220947, rank=1, decoded_token='Question')}, {374: Logprob(logprob=-1.4751518964767456, rank=2, decoded_token=' is'), 527: Logprob(logprob=-0.8501518964767456, rank=1, decoded_token=' are')}, {264: Logprob(logprob=-1.1288176774978638, rank=1, decoded_token=' a')}, {1715: Logprob(logprob=-9.066563606262207, rank=886, decoded_token=' request'), 2763: Logprob(logprob=-2.441563844680786, rank=1, decoded_token=' lot')}, {505: Logprob(logprob=-2.4557113647460938, rank=3, decoded_token=' from'), 369: Logprob(logprob=-1.2057112455368042, rank=1, decoded_token=' for')}, {279: Logprob(logprob=-1.100795030593872, rank=1, decoded_token=' the')}, {1217: Logprob(logprob=-4.3608503341674805, rank=5, decoded_token=' user'), 20214: Logprob(logprob=-3.7983505725860596, rank=1, decoded_token=' Ministry')}, {311: Logprob(logprob=-0.796364963054657, rank=1, decoded_token=' to')}, {1893: Logprob(logprob=-3.0459389686584473, rank=2, decoded_token=' create'), 923: Logprob(logprob=-2.5459389686584473, rank=1, decoded_token=' add')}, {264: Logprob(logprob=-0.46096619963645935, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-5.938747882843018, rank=49, decoded_token=' task'), 502: Logprob(logprob=-2.3137478828430176, rank=1, decoded_token=' new')}, {304: Logprob(logprob=-2.125389575958252, rank=1, decoded_token=' in')}, {3465: Logprob(logprob=-5.396354675292969, rank=19, decoded_token=' task'), 279: Logprob(logprob=-1.1463544368743896, rank=1, decoded_token=' the')}, {6373: Logprob(logprob=-2.1754069328308105, rank=2, decoded_token=' management'), 6783: Logprob(logprob=-1.4254070520401, rank=1, decoded_token=' manager')}, {1887: Logprob(logprob=-1.9005897045135498, rank=1, decoded_token=' system')}, {13: Logprob(logprob=-1.4818499088287354, rank=1, decoded_token='.')}, {5321: Logprob(logprob=-4.812841415405273, rank=22, decoded_token=' Please'), 578: Logprob(logprob=-1.3128414154052734, rank=1, decoded_token=' The')}, {11: Logprob(logprob=-4.180384159088135, rank=13, decoded_token=','), 1893: Logprob(logprob=-2.0553841590881348, rank=1, decoded_token=' create')}, {8819: Logprob(logprob=-9.274468421936035, rank=367, decoded_token=' extract'), 1893: Logprob(logprob=-1.7119686603546143, rank=1, decoded_token=' create')}, {279: Logprob(logprob=-0.7036926746368408, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-7.863875865936279, rank=202, decoded_token=' status'), 3465: Logprob(logprob=-1.9888757467269897, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-1.0321611166000366, rank=1, decoded_token=' of')}, {420: Logprob(logprob=-2.7303802967071533, rank=3, decoded_token=' this'), 279: Logprob(logprob=-0.48038020730018616, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.3501986265182495, rank=1, decoded_token=' task')}, {430: Logprob(logprob=-5.973194122314453, rank=32, decoded_token=' that'), 505: Logprob(logprob=-1.2856942415237427, rank=1, decoded_token=' from')}, {690: Logprob(logprob=-2.394989490509033, rank=2, decoded_token=' will'), 374: Logprob(logprob=-1.2699893712997437, rank=1, decoded_token=' is')}, {387: Logprob(logprob=-0.4832521080970764, rank=1, decoded_token=' be')}, {9277: Logprob(logprob=-6.0560383796691895, rank=65, decoded_token=' placed'), 1511: Logprob(logprob=-2.4310383796691895, rank=1, decoded_token=' used')}, {304: Logprob(logprob=-0.4673547148704529, rank=1, decoded_token=' in')}, {5546: Logprob(logprob=-5.113916873931885, rank=13, decoded_token=' Task'), 279: Logprob(logprob=-0.7389167547225952, rank=1, decoded_token=' the')}, {9744: Logprob(logprob=-2.8428988456726074, rank=4, decoded_token=' Management'), 2583: Logprob(logprob=-1.7178988456726074, rank=1, decoded_token='Status')}, {744: Logprob(logprob=-0.3768121898174286, rank=1, decoded_token=' System')}, {627: Logprob(logprob=-1.5596171617507935, rank=2, decoded_token='.\\n'), 13: Logprob(logprob=-1.3096171617507935, rank=1, decoded_token='.')}, {13617: Logprob(logprob=-6.20838737487793, rank=54, decoded_token='Example'), 791: Logprob(logprob=-2.1458871364593506, rank=1, decoded_token='The')}, {220: Logprob(logprob=-3.4441070556640625, rank=4, decoded_token=' '), 25: Logprob(logprob=-0.881607174873352, rank=1, decoded_token=':')}, {16: Logprob(logprob=-0.14433923363685608, rank=1, decoded_token='1')}, {25: Logprob(logprob=-0.7279500961303711, rank=1, decoded_token=':')}, {5666: Logprob(logprob=-8.02212142944336, rank=207, decoded_token=' Update'), 578: Logprob(logprob=-2.209620952606201, rank=1, decoded_token=' The')}, {279: Logprob(logprob=-1.2828420400619507, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.7792110443115234, rank=1, decoded_token=' status')}, {315: Logprob(logprob=-0.4747336208820343, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.8814727663993835, rank=1, decoded_token=' the')}, {20801: Logprob(logprob=-14.885658264160156, rank=10594, decoded_token=' pent'), 3465: Logprob(logprob=-0.31119504570961, rank=1, decoded_token=' task')}, {478: Logprob(logprob=-0.6689746975898743, rank=1, decoded_token='est')}, {3465: Logprob(logprob=-1.3443454504013062, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-1.3653672933578491, rank=1, decoded_token=' to')}, {8308: Logprob(logprob=-3.6275477409362793, rank=8, decoded_token=' completed'), 330: Logprob(logprob=-1.5025477409362793, rank=1, decoded_token=' \"')}, {627: Logprob(logprob=-0.7991341352462769, rank=1, decoded_token='.\\n')}, {16533: Logprob(logprob=-8.74571418762207, rank=330, decoded_token='Answer'), 13617: Logprob(logprob=-0.7457138895988464, rank=1, decoded_token='Example')}, {25: Logprob(logprob=-0.736219048500061, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-5.012274742126465, rank=29, decoded_token=' “'), 578: Logprob(logprob=-2.574774742126465, rank=1, decoded_token=' The')}, {35835: Logprob(logprob=-4.9084882736206055, rank=18, decoded_token='completed'), 791: Logprob(logprob=-2.4709880352020264, rank=1, decoded_token='The')}, {7663: Logprob(logprob=-4.7869415283203125, rank=6, decoded_token='”\\n\\n'), 863: Logprob(logprob=-0.5994415283203125, rank=1, decoded_token='”')}, {13617: Logprob(logprob=-0.2548457384109497, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.009654378518462181, rank=1, decoded_token=' ')}, {17: Logprob(logprob=-0.011736157350242138, rank=1, decoded_token='2')}, {25: Logprob(logprob=-0.015942253172397614, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-6.879785060882568, rank=31, decoded_token=' “'), 5666: Logprob(logprob=-0.2547852396965027, rank=1, decoded_token=' Update')}, {4110: Logprob(logprob=-3.7120201587677, rank=6, decoded_token='Create'), 4387: Logprob(logprob=-2.1495201587677, rank=1, decoded_token='Update')}, {264: Logprob(logprob=-0.7378871440887451, rank=1, decoded_token=' a')}, {2082: Logprob(logprob=-8.1116304397583, rank=92, decoded_token=' code'), 3465: Logprob(logprob=-0.7366300225257874, rank=1, decoded_token=' task')}, {2098: Logprob(logprob=-5.940270900726318, rank=17, decoded_token=' ref'), 3477: Logprob(logprob=-0.3152711093425751, rank=1, decoded_token=' review')}, {76507: Logprob(logprob=-0.037638068199157715, rank=1, decoded_token='actoring')}, {3465: Logprob(logprob=-0.1042257770895958, rank=1, decoded_token=' task')}, {369: Logprob(logprob=-2.0150020122528076, rank=1, decoded_token=' for')}, {650: Logprob(logprob=-7.882807731628418, rank=255, decoded_token=' V'), 279: Logprob(logprob=-1.3203076124191284, rank=1, decoded_token=' the')}, {25041: Logprob(logprob=-8.758981704711914, rank=550, decoded_token='anya'), 6546: Logprob(logprob=-2.415231227874756, rank=1, decoded_token='CS')}, {13: Logprob(logprob=-2.7198758125305176, rank=4, decoded_token='.'), 753: Logprob(logprob=-2.1573758125305176, rank=1, decoded_token='’s')}, {1628: Logprob(logprob=-5.055873394012451, rank=22, decoded_token=' And'), 578: Logprob(logprob=-1.9308732748031616, rank=1, decoded_token=' The')}, {743: Logprob(logprob=-2.0640695095062256, rank=2, decoded_token=' set'), 2713: Logprob(logprob=-1.9390695095062256, rank=1, decoded_token=' update')}, {279: Logprob(logprob=-0.9005088806152344, rank=1, decoded_token=' the')}, {2704: Logprob(logprob=-0.32777857780456543, rank=1, decoded_token=' status')}, {311: Logprob(logprob=-0.701461136341095, rank=1, decoded_token=' to')}, {1054: Logprob(logprob=-2.182943344116211, rank=2, decoded_token=' “'), 304: Logprob(logprob=-1.495443344116211, rank=1, decoded_token=' in')}, {258: Logprob(logprob=-0.8141452670097351, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.26366332173347473, rank=1, decoded_token=' progress')}, {89874: Logprob(logprob=-2.47843074798584, rank=4, decoded_token='”\\n'), 863: Logprob(logprob=-0.8534306287765503, rank=1, decoded_token='”')}, {16533: Logprob(logprob=-0.06133502349257469, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.02162671647965908, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.15431392192840576, rank=1, decoded_token=' “')}, {258: Logprob(logprob=-0.1300429254770279, rank=1, decoded_token='in')}, {5208: Logprob(logprob=-0.048629116266965866, rank=1, decoded_token=' progress')}, {15397: Logprob(logprob=-4.23609733581543, rank=4, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.23609726130962372, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.7214919328689575, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.011189330369234085, rank=1, decoded_token=' ')}, {18: Logprob(logprob=-0.01031437423080206, rank=1, decoded_token='3')}, {25: Logprob(logprob=-0.03739602863788605, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.6135650277137756, rank=1, decoded_token=' “')}, {7968: Logprob(logprob=-7.384041786193848, rank=78, decoded_token='Show'), 4110: Logprob(logprob=-0.8215418457984924, rank=1, decoded_token='Create')}, {757: Logprob(logprob=-1.0606498718261719, rank=2, decoded_token=' me'), 279: Logprob(logprob=-0.9981498718261719, rank=1, decoded_token=' the')}, {279: Logprob(logprob=-0.4350700080394745, rank=1, decoded_token=' the')}, {3969: Logprob(logprob=-12.134038925170898, rank=1135, decoded_token=' exec'), 2704: Logprob(logprob=-0.3527887463569641, rank=1, decoded_token=' status')}, {9663: Logprob(logprob=-0.593633234500885, rank=1, decoded_token='utors')}, {315: Logprob(logprob=-0.8525809049606323, rank=1, decoded_token=' of')}, {279: Logprob(logprob=-0.5535013675689697, rank=1, decoded_token=' the')}, {3465: Logprob(logprob=-0.8704282641410828, rank=1, decoded_token=' task')}, {315: Logprob(logprob=-5.152504920959473, rank=20, decoded_token=' of'), 449: Logprob(logprob=-0.6525049209594727, rank=1, decoded_token=' with')}, {9676: Logprob(logprob=-12.550848960876465, rank=5540, decoded_token=' chart'), 279: Logprob(logprob=-1.6133490800857544, rank=1, decoded_token=' the')}, {287: Logprob(logprob=-1.6783087253570557, rank=1, decoded_token='ing')}, {113068: Logprob(logprob=-3.9072160720825195, rank=8, decoded_token='”.\\n'), 279: Logprob(logprob=-1.407216191291809, rank=1, decoded_token=' the')}, {16533: Logprob(logprob=-0.0446050763130188, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.013074620626866817, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.2659088969230652, rank=1, decoded_token=' “')}, {2994: Logprob(logprob=-6.747637748718262, rank=115, decoded_token='null'), 53: Logprob(logprob=-2.0601377487182617, rank=1, decoded_token='V')}, {15397: Logprob(logprob=-1.2456005811691284, rank=2, decoded_token='”.\\n\\n'), 7663: Logprob(logprob=-0.8706005811691284, rank=1, decoded_token='”\\n\\n')}, {13617: Logprob(logprob=-0.5773501396179199, rank=1, decoded_token='Example')}, {220: Logprob(logprob=-0.00530478497967124, rank=1, decoded_token=' ')}, {19: Logprob(logprob=-0.00842292234301567, rank=1, decoded_token='4')}, {25: Logprob(logprob=-0.022363845258951187, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.161273792386055, rank=1, decoded_token=' “')}, {4110: Logprob(logprob=-2.079286575317383, rank=3, decoded_token='Create'), 7968: Logprob(logprob=-1.5792866945266724, rank=1, decoded_token='Show')}, {264: Logprob(logprob=-0.15873757004737854, rank=1, decoded_token=' a')}, {3465: Logprob(logprob=-0.6506558656692505, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-2.053983688354492, rank=3, decoded_token=' to'), 315: Logprob(logprob=-1.3664836883544922, rank=1, decoded_token=' of')}, {3780: Logprob(logprob=-5.3355817794799805, rank=45, decoded_token=' buy'), 2713: Logprob(logprob=-2.7105817794799805, rank=1, decoded_token=' update')}, {32656: Logprob(logprob=-6.8495988845825195, rank=74, decoded_token=' candy'), 264: Logprob(logprob=-1.0995988845825195, rank=1, decoded_token=' a')}, {11: Logprob(logprob=-3.291595220565796, rank=5, decoded_token=','), 369: Logprob(logprob=-1.041595220565796, rank=1, decoded_token=' for')}, {2704: Logprob(logprob=-3.4165704250335693, rank=6, decoded_token=' status'), 323: Logprob(logprob=-1.2290704250335693, rank=1, decoded_token=' and')}, {482: Logprob(logprob=-3.429025650024414, rank=8, decoded_token=' -'), 374: Logprob(logprob=-1.6165255308151245, rank=1, decoded_token=' is')}, {304: Logprob(logprob=-2.184178113937378, rank=2, decoded_token=' in'), 1054: Logprob(logprob=-1.121678113937378, rank=1, decoded_token=' “')}, {5208: Logprob(logprob=-0.12029757350683212, rank=1, decoded_token=' progress')}, {113068: Logprob(logprob=-1.1144096851348877, rank=1, decoded_token='”.\\n')}, {16533: Logprob(logprob=-0.01982516422867775, rank=1, decoded_token='Answer')}, {25: Logprob(logprob=-0.006080462131649256, rank=1, decoded_token=':')}, {1054: Logprob(logprob=-0.057018738240003586, rank=1, decoded_token=' “')}, {64: Logprob(logprob=-9.976174354553223, rank=64, decoded_token='a'), 258: Logprob(logprob=-0.03867468610405922, rank=1, decoded_token='in')}, {3465: Logprob(logprob=-1.596139907836914, rank=1, decoded_token=' task')}, {311: Logprob(logprob=-0.5203608274459839, rank=1, decoded_token=' to')}], outputs=[CompletionOutput(index=0, text=' buy', token_ids=[3780], cumulative_logprob=-0.010155788622796535, logprobs=None, finish_reason=length, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1717314192.652787, last_token_time=1717314192.652787, first_scheduled_time=1717314192.6585464, first_token_time=1717314192.7902024, time_in_queue=0.005759477615356445, finished_time=1717314192.8004105), lora_request=None)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4a5ec3d-bcc5-4f8a-a21d-201b88133b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance_system = GuidanceBeta(llm, mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c251854-47ec-4f73-aee1-1f9567891f79",
   "metadata": {},
   "source": [
    "Сейчас на сабстринге включены принты, чтобы следить за временем каждого этапа алогоритма.\n",
    "Если хочешь выключить, то передай в инициализацию GuidanceBeta аргумент `mode=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0120e96b-f9ef-419f-9215-b493282a5ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get candidates: last 2 tokens + all substring candidates 0.0001735687255859375\n",
      "[': \" ', ': \" в', ': \" в ', ': \" в п', ': \" в пр', ': \" в про', ': \" в проц', ': \" в проце', ': \" в процес', ': \" з', ': \" за', ': \" зад', ': \" зада', ': \" задач', ': \" задачу', ': \" задачу ', ': \" задачу к', ': \" к', ': \" ко', ': \" кон', ': \" конф', ': \" конфе', ': \" конфет', ': \" конфет,', ': \" конфет, ', ': \" ку', ': \" куп', ': \" купи', ': \" купит', ': \" купить', ': \" купить ', ': \" купить к', ': \" п', ': \" пр', ': \" про', ': \" проц', ': \" проце', ': \" процес', ': \" процесс', ': \" процессе', ': \" с', ': \" ст', ': \" ста', ': \" стат', ': \" стату', ': \" статус', ': \" статус ', ': \" статус в', ': \",', ': \", ', ': \", с', ': \", ст', ': \", ста', ': \", стат', ': \", стату', ': \", статус', ': \", статус ', ': \"С', ': \"Со', ': \"Соз', ': \"Созд', ': \"Созда', ': \"Создай', ': \"Создай ', ': \"Создай з', ': \"Создай за', ': \"а', ': \"ад', ': \"ада', ': \"адач', ': \"адачу', ': \"адачу ', ': \"адачу к', ': \"адачу ку', ': \"адачу куп', ': \"ай', ': \"ай ', ': \"ай з', ': \"ай за', ': \"ай зад', ': \"ай зада', ': \"ай задач', ': \"ай задачу', ': \"ат', ': \"ату', ': \"атус', ': \"атус ', ': \"атус в', ': \"атус в ', ': \"атус в п', ': \"атус в пр', ': \"ач', ': \"ачу', ': \"ачу ', ': \"ачу к', ': \"ачу ку', ': \"ачу куп', ': \"ачу купи', ': \"ачу купит', ': \"в', ': \"в ', ': \"в п', ': \"в пр', ': \"в про', ': \"в проц', ': \"в проце', ': \"в процес', ': \"в процесс', ': \"д', ': \"да', ': \"дай', ': \"дай ', ': \"дай з', ': \"дай за', ': \"дай зад', ': \"дай зада', ': \"дай задач', ': \"дач', ': \"дачу', ': \"дачу ', ': \"дачу к', ': \"дачу ку', ': \"дачу куп', ': \"дачу купи', ': \"е', ': \"ес', ': \"есс', ': \"ессе', ': \"ет', ': \"ет,', ': \"ет, ', ': \"ет, с', ': \"ет, ст', ': \"ет, ста', ': \"ет, стат', ': \"ет, стату', ': \"з', ': \"за', ': \"зад', ': \"зада', ': \"задач', ': \"задачу', ': \"задачу ', ': \"задачу к', ': \"задачу ку', ': \"зд', ': \"зда', ': \"здай', ': \"здай ', ': \"здай з', ': \"здай за', ': \"здай зад', ': \"здай зада', ': \"и', ': \"ит', ': \"ить', ': \"ить ', ': \"ить к', ': \"ить ко', ': \"ить кон', ': \"ить конф', ': \"ить конфе', ': \"й', ': \"й ', ': \"й з', ': \"й за', ': \"й зад', ': \"й зада', ': \"й задач', ': \"й задачу', ': \"й задачу ', ': \"к', ': \"ко', ': \"кон', ': \"конф', ': \"конфе', ': \"конфет', ': \"конфет,', ': \"конфет, ', ': \"конфет, с', ': \"ку', ': \"куп', ': \"купи', ': \"купит', ': \"купить', ': \"купить ', ': \"купить к', ': \"купить ко', ': \"н', ': \"нф', ': \"нфе', ': \"нфет', ': \"нфет,', ': \"нфет, ', ': \"нфет, с', ': \"нфет, ст', ': \"нфет, ста', ': \"о', ': \"оз', ': \"озд', ': \"озда', ': \"оздай', ': \"оздай ', ': \"оздай з', ': \"оздай за', ': \"оздай зад', ': \"он', ': \"онф', ': \"онфе', ': \"онфет', ': \"онфет,', ': \"онфет, ', ': \"онфет, с', ': \"онфет, ст', ': \"оц', ': \"оце', ': \"оцес', ': \"оцесс', ': \"оцессе', ': \"п', ': \"пи', ': \"пит', ': \"пить', ': \"пить ', ': \"пить к', ': \"пить ко', ': \"пить кон', ': \"пить конф', ': \"пр', ': \"про', ': \"проц', ': \"проце', ': \"процес', ': \"процесс', ': \"процессе', ': \"р', ': \"ро', ': \"роц', ': \"роце', ': \"роцес', ': \"роцесс', ': \"роцессе', ': \"с', ': \"с ', ': \"с в', ': \"с в ', ': \"с в п', ': \"с в пр', ': \"с в про', ': \"с в проц', ': \"с в проце', ': \"се', ': \"сс', ': \"ссе', ': \"ст', ': \"ста', ': \"стат', ': \"стату', ': \"статус', ': \"статус ', ': \"статус в', ': \"статус в ', ': \"т', ': \"т,', ': \"т, ', ': \"т, с', ': \"т, ст', ': \"т, ста', ': \"т, стат', ': \"т, стату', ': \"т, статус', ': \"та', ': \"тат', ': \"тату', ': \"татус', ': \"татус ', ': \"татус в', ': \"татус в ', ': \"татус в п', ': \"ту', ': \"тус', ': \"тус ', ': \"тус в', ': \"тус в ', ': \"тус в п', ': \"тус в пр', ': \"тус в про', ': \"ть', ': \"ть ', ': \"ть к', ': \"ть ко', ': \"ть кон', ': \"ть конф', ': \"ть конфе', ': \"ть конфет', ': \"у', ': \"у ', ': \"у к', ': \"у ку', ': \"у куп', ': \"у купи', ': \"у купит', ': \"у купить', ': \"у купить ', ': \"уп', ': \"упи', ': \"упит', ': \"упить', ': \"упить ', ': \"упить к', ': \"упить ко', ': \"упить кон', ': \"ус', ': \"ус ', ': \"ус в', ': \"ус в ', ': \"ус в п', ': \"ус в пр', ': \"ус в про', ': \"ус в проц', ': \"ф', ': \"фе', ': \"фет', ': \"фет,', ': \"фет, ', ': \"фет, с', ': \"фет, ст', ': \"фет, ста', ': \"фет, стат', ': \"ц', ': \"це', ': \"цес', ': \"цесс', ': \"цессе', ': \"ч', ': \"чу', ': \"чу ', ': \"чу к', ': \"чу ку', ': \"чу куп', ': \"чу купи', ': \"чу купит', ': \"чу купить', ': \"ь', ': \"ь ', ': \"ь к', ': \"ь ко', ': \"ь кон', ': \"ь конф', ': \"ь конфе', ': \"ь конфет', ': \"ь конфет,']\n",
      "build tree for first tokens: 0.6633615493774414\n",
      "log prob nodes: \n",
      "85\n",
      ": \" \n",
      ": \" в\n",
      ": \" з\n",
      ": \" за\n",
      ": \" задачу\n",
      ": \" зада\n",
      ": \" к\n",
      ": \" ко\n",
      ": \" кон\n",
      ": \" конф\n",
      ": \" ку\n",
      ": \" куп\n",
      ": \" п\n",
      ": \" пр\n",
      ": \" про\n",
      ": \" проце\n",
      ": \" процес\n",
      ": \" процесс\n",
      ": \" процессе\n",
      ": \" с\n",
      ": \" стату\n",
      ": \" ста\n",
      ": \" стат\n",
      ": \" статус\n",
      ": \"С\n",
      ": \"а\n",
      ": \"адачу\n",
      ": \"ада\n",
      ": \"ай\n",
      ": \"атус\n",
      ": \"ату\n",
      ": \"ачу\n",
      ": \"в\n",
      ": \"дай\n",
      ": \"да\n",
      ": \"е\n",
      ": \"ес\n",
      ": \"ессе\n",
      ": \"ет,\n",
      ": \"з\n",
      ": \"за\n",
      ": \"здай\n",
      ": \"и\n",
      ": \"ит\n",
      ": \"ить\n",
      ": \"й\n",
      ": \"к\n",
      ": \"ко\n",
      ": \"конф\n",
      ": \"купи\n",
      ": \"куп\n",
      ": \"нф\n",
      ": \"о\n",
      ": \"оз\n",
      ": \"озд\n",
      ": \"онф\n",
      ": \"п\n",
      ": \"пи\n",
      ": \"пр\n",
      ": \"р\n",
      ": \"ро\n",
      ": \"с\n",
      ": \"се\n",
      ": \"ст\n",
      ": \"ста\n",
      ": \"т\n",
      ": \"та\n",
      ": \"ту\n",
      ": \"ть\n",
      ": \"у\n",
      ": \"уп\n",
      ": \"ус\n",
      ": \"ф\n",
      ": \"цессе\n",
      ": \"це\n",
      ": \"цес\n",
      ": \"ч\n",
      ": \"чу\n",
      ": \"ь\n",
      ": \", \n",
      ": \", с\n",
      ": \", стату\n",
      ": \", ста\n",
      ": \", стат\n",
      ": \", статус \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 32.22it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.24it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.39it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.13it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.33it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.41it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.40it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.51it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.44it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.34it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.93it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.33it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.91it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 36.95it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.36it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.25it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.51it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 36.68it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.33it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.57it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.84it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.01it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.14it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.23it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.41it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 36.38it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.18it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.17it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.40it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.75it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.40it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.95it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.31it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.73it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.05it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.49it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.27it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute log_probs call 1.1458938121795654\n",
      "get top k nodes call: 0.001451730728149414\n",
      "get expanded candidates starts with top k first tokens: 0.12157893180847168\n",
      "add children sequences before found branch into working list: 3.552436828613281e-05\n",
      "log prob nodes: \n",
      "9\n",
      ": \"в\n",
      ": \"в \n",
      ": \"в п\n",
      ": \"в пр\n",
      ": \"в про\n",
      ": \"в проце\n",
      ": \"в процес\n",
      ": \"в процесс\n",
      ": \"в процессе\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.72it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.69it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 37.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute log_probs call 0.08724117279052734\n",
      "get top k nodes call: 0.0007109642028808594\n",
      "add children sequences before found branch into working list: 1.1920928955078125e-06\n",
      "log prob nodes: \n",
      "1\n",
      ": \"в процессе\n",
      "\n",
      "get top k nodes call: 7.462501525878906e-05\n",
      "['в процессе']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1325838565826416"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "prompt = '''There is a request from the user to create a task in task management system. Please, extract the status of this task that will be placed in Task Management System.\n",
    "Example 1: Обнови статус задачи по проведению пентеста на выполнено.\n",
    "Answer: \"выполнено\"\n",
    "\n",
    "Example 2: \"Создай Ване задачу по рефакторингу кода. И поставь статус - в процессе\"\n",
    "Answer: \"в процессе\"\n",
    "\n",
    "Example 3: \"Покажи мне исполнителей задачи по построению графиков\"\n",
    "Answer: \"null\"\n",
    "\n",
    "Example 4: \"Создай задачу купить конфет, статус в процессе\"\n",
    "Answer: \"'''\n",
    "\n",
    "\n",
    "context = \"Создай задачу купить конфет, статус в процессе\"\n",
    "\n",
    "\n",
    "res = guidance_system.substring(prompt, context, 1)\n",
    "print(res)\n",
    "\n",
    "time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b228c29a-4d7c-4772-bf6c-6befadc427bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BLOOM has ', 'BLOOM has 1']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c327edf-56cf-4936-855f-f9e25e457bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: tensor([   30,   426,  1623,  1937,   706,   220, 10967,  7239,  5137]), -9.728892429207917\n",
      "? BLOOM has 176 billion parameters\n",
      "Nodes: tensor([   30,   426,  1623,  1937,   706,   220, 10967,  7239]), -9.645392401551362\n",
      "? BLOOM has 176 billion\n"
     ]
    }
   ],
   "source": [
    "for node in res[1]:\n",
    "    print(node)\n",
    "    print(guidance_system.tokenizer.decode(node.token_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c29f88d-257a-454f-aad5-6b0a8a8c66cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 86/86 [00:00<00:00, 697.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33488011360168457\n",
      "\n",
      "\n",
      "['good day!', 'good day! ', 'good ', 'ood day! ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "prompt = \"The weather is amazing! It is so \"\n",
    "context = \"good day! bad day, I hate it\"\n",
    "\n",
    "s = time.time()\n",
    "res = guidance_system.substring(prompt, context, 4)\n",
    "print(time.time() - s)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82b17fba-fd52-4aa9-bac6-44c76acd97a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What usually has 4 wheels? car', 'What usually has 4 wheels? horse', 'I have been in country in South Asia called Bangladesh', 'I have been in country in South Asia called Bangcheese']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processed prompts: 100%|██████████| 4/4 [00:00<00:00, 117.99it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m choices_list2 \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcar\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mladesh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheese\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      4\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 5\u001b[0m output1 \u001b[38;5;241m=\u001b[39m \u001b[43mguidance_system\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchoices_list1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken for select() with choices_list1:\u001b[39m\u001b[38;5;124m\"\u001b[39m, end_time \u001b[38;5;241m-\u001b[39m start_time, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 107\u001b[0m, in \u001b[0;36mGuidanceBeta.select\u001b[0;34m(self, input_batches, choices_list, return_full_text)\u001b[0m\n\u001b[1;32m    105\u001b[0m log_prob_sequence \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(skip_logits \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(outputs[candidate_idx]\u001b[38;5;241m.\u001b[39mprompt_logprobs)):\n\u001b[0;32m--> 107\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids_slice\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcandidate_idx\u001b[49m\u001b[43m]\u001b[49m[token_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    108\u001b[0m     log_prob_sequence\u001b[38;5;241m.\u001b[39mappend(outputs[candidate_idx]\u001b[38;5;241m.\u001b[39mprompt_logprobs[token_idx][token])\n\u001b[1;32m    110\u001b[0m log_prob_of_candidate \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mtensor(log_prob_sequence), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": [
    "texts = [\"What usually has 4 wheels? \", \"I have been in country in South Asia called Bang\"]\n",
    "choices_list1 = [[\"car\", \"horse\"], [\"ladesh\", \"cheese\"]]\n",
    "choices_list2 = [[\"horse\", \"car\"], [\"ladesh\", \"cheese\"]]\n",
    "start_time = time.time()\n",
    "output1 = guidance_system.select(texts, choices_list1)\n",
    "end_time = time.time()\n",
    "print(\"Time taken for select() with choices_list1:\", end_time - start_time, \"seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "output2 = guidance_system.select(texts, choices_list2)\n",
    "end_time = time.time()\n",
    "print(\"Time taken for select() with choices_list2:\", end_time - start_time, \"seconds\")\n",
    "\n",
    "print(output1)\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4fa946f-97d5-482b-b6c1-c9a42437ca5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for gen(): 0.9958069324493408 seconds\n",
      "['s. I have owned three BMWs in my life, and I would own another one if I']\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "gen_res = guidance_system.gen(\"I am a big fan of BMW\", max_length=30, min_length=10)\n",
    "end_time = time.time()\n",
    "print(\"Time taken for gen():\", end_time - start_time, \"seconds\")\n",
    "print(gen_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67246964-5459-45c5-b8c6-73d1ae20a9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = \"How many programming languages does BLOOM support? \"\n",
    "choices_list = [[\"text\", \"46 languages\"]]\n",
    "guidance_system.select(texts, choices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b7d215d-f815-4744-8f30-9cb66ab1621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> I am a big fan of BMW's and have owned one for 15 years. I have had the pleasure of driving the new M3 and M5 and they are a blast. I am looking for a used M3 for sale, but I am having a hard time finding one that I like. I am looking for one that is less than 5 years old, and has a manual transmission. I have been to several dealerships, and have looked at several\n",
      "\n",
      "\n",
      "Time taken for gen(): 4.105570316314697 seconds\n",
      "[\"'s and have owned one for 15 years. I have had the pleasure of driving the new M3 and M5 and they are a blast. I am looking for a used M3 for sale, but I am having a hard time finding one that I like. I am looking for one that is less than 5 years old, and has a manual transmission. I have been to several dealerships, and have looked at several\"]\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "streamer = TextStreamer(guidance_system.tokenizer)\n",
    "\n",
    "start_time = time.time()\n",
    "gen_res = guidance_system.gen(\"I am a big fan of BMW\",\n",
    "                              streamer=streamer,\n",
    "                              stop_keywords=\"BMW\",\n",
    "                              max_length=100)\n",
    "end_time = time.time()\n",
    "print()\n",
    "print()\n",
    "print(\"Time taken for gen():\", end_time - start_time, \"seconds\")\n",
    "print(gen_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f667bad-1b95-40a2-ac4c-d6cccf62f77b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
